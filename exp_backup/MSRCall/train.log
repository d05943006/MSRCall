signal shape:torch.Size([256, 2048, 1])
label shape:torch.Size([256, 512])
training: epoch 0, step 200, loss 478.974486, time: 3.358
training: epoch 0, step 400, loss 377.965655, time: 3.397
training: epoch 0, step 600, loss 339.654813, time: 3.404
training: epoch 0, step 800, loss 317.654072, time: 3.408
training: epoch 0, step 1000, loss 302.406590, time: 3.403
training: epoch 0, step 1200, loss 289.140060, time: 3.400
training: epoch 0, step 1400, loss 277.810948, time: 3.408
training: epoch 0, step 1600, loss 268.324706, time: 3.411
training: epoch 0, step 1800, loss 260.471617, time: 3.413
training: epoch 0, step 2000, loss 253.350648, time: 3.413
training: epoch 0, step 2200, loss 246.645512, time: 3.405
training: epoch 0, step 2400, loss 240.334375, time: 3.403
training: epoch 0, step 2600, loss 234.450737, time: 3.401
training: epoch 0, step 2800, loss 229.251148, time: 3.403
training: epoch 0, step 3000, loss 224.165813, time: 3.404
training: epoch 0, step 3200, loss 219.674924, time: 3.405
training: epoch 0, step 3400, loss 215.115221, time: 3.405
training: epoch 0, step 3600, loss 210.876912, time: 3.397
training: epoch 0, step 3800, loss 206.952603, time: 3.410
training: epoch 0, step 4000, loss 203.165532, time: 3.408
training: epoch 0, step 4200, loss 199.626858, time: 3.413
training: epoch 0, step 4400, loss 196.022268, time: 3.412
training: epoch 0, step 4600, loss 192.568528, time: 3.411
training: epoch 0, step 4800, loss 189.269337, time: 3.405
training: epoch 0, step 5000, loss 186.167629, time: 3.409
training: epoch 0, step 5200, loss 183.139897, time: 3.401
training: epoch 0, step 5400, loss 180.311734, time: 3.407
training: epoch 0, step 5600, loss 177.498054, time: 3.398
training: epoch 0, step 5800, loss 174.861992, time: 3.401
training: epoch 0, step 6000, loss 172.384195, time: 3.412
training: epoch 0, step 6200, loss 169.970818, time: 3.406
training: epoch 0, step 6400, loss 167.555644, time: 3.402
training: epoch 0, step 6600, loss 165.278018, time: 3.409
training: epoch 0, step 6800, loss 163.053416, time: 3.400
training: epoch 0, step 7000, loss 160.946177, time: 3.403
training: epoch 0, step 7200, loss 158.896604, time: 3.402
training: epoch 0, step 7400, loss 156.903199, time: 3.403
training: epoch 0, step 7600, loss 154.947962, time: 3.400
training: epoch 0, step 7800, loss 153.044913, time: 3.403
training: epoch 0, step 7849, loss 152.626535, time: 0.833
validate: epoch 0, loss 85.402299, charcter error 15.888 time: 3.964
    - [Info] The checkpoint file has been updated.
training: epoch 1, step 200, loss 79.353275, time: 3.357
training: epoch 1, step 400, loss 80.722344, time: 3.391
training: epoch 1, step 600, loss 79.193548, time: 3.407
training: epoch 1, step 800, loss 78.767138, time: 3.399
training: epoch 1, step 1000, loss 78.244173, time: 3.395
training: epoch 1, step 1200, loss 77.721184, time: 3.400
training: epoch 1, step 1400, loss 77.637869, time: 3.403
training: epoch 1, step 1600, loss 77.106681, time: 3.394
training: epoch 1, step 1800, loss 76.512002, time: 3.402
training: epoch 1, step 2000, loss 76.160104, time: 3.403
training: epoch 1, step 2200, loss 75.789368, time: 3.400
training: epoch 1, step 2400, loss 75.438516, time: 3.404
training: epoch 1, step 2600, loss 74.905542, time: 3.394
training: epoch 1, step 2800, loss 74.448238, time: 3.393
training: epoch 1, step 3000, loss 74.103430, time: 3.399
training: epoch 1, step 3200, loss 73.664094, time: 3.403
training: epoch 1, step 3400, loss 73.288960, time: 3.410
training: epoch 1, step 3600, loss 72.900581, time: 3.402
training: epoch 1, step 3800, loss 72.527090, time: 3.402
training: epoch 1, step 4000, loss 72.164148, time: 3.396
training: epoch 1, step 4200, loss 71.795945, time: 3.398
training: epoch 1, step 4400, loss 71.437164, time: 3.390
training: epoch 1, step 4600, loss 71.130225, time: 3.397
training: epoch 1, step 4800, loss 70.829535, time: 3.395
training: epoch 1, step 5000, loss 70.563102, time: 3.396
training: epoch 1, step 5200, loss 70.262534, time: 3.393
training: epoch 1, step 5400, loss 70.022272, time: 3.400
training: epoch 1, step 5600, loss 69.682559, time: 3.401
training: epoch 1, step 5800, loss 69.414016, time: 3.394
training: epoch 1, step 6000, loss 69.126187, time: 3.407
training: epoch 1, step 6200, loss 68.841549, time: 3.403
training: epoch 1, step 6400, loss 68.516008, time: 3.399
training: epoch 1, step 6600, loss 68.294687, time: 3.405
training: epoch 1, step 6800, loss 67.988416, time: 3.402
training: epoch 1, step 7000, loss 67.767734, time: 3.409
training: epoch 1, step 7200, loss 67.534377, time: 3.404
training: epoch 1, step 7400, loss 67.328367, time: 3.403
training: epoch 1, step 7600, loss 67.079116, time: 3.406
training: epoch 1, step 7800, loss 66.835161, time: 3.414
training: epoch 1, step 7849, loss 66.772231, time: 0.836
validate: epoch 1, loss 61.313086, charcter error 11.121 time: 4.015
    - [Info] The checkpoint file has been updated.
training: epoch 2, step 200, loss 58.111263, time: 3.364
training: epoch 2, step 400, loss 57.969536, time: 3.408
training: epoch 2, step 600, loss 57.781026, time: 3.401
training: epoch 2, step 800, loss 57.273396, time: 3.411
training: epoch 2, step 1000, loss 57.125629, time: 3.404
training: epoch 2, step 1200, loss 57.067984, time: 3.407
training: epoch 2, step 1400, loss 56.746937, time: 3.410
training: epoch 2, step 1600, loss 56.694779, time: 3.413
training: epoch 2, step 1800, loss 56.611666, time: 3.414
training: epoch 2, step 2000, loss 56.630617, time: 3.413
training: epoch 2, step 2200, loss 56.486430, time: 3.413
training: epoch 2, step 2400, loss 56.482341, time: 3.413
training: epoch 2, step 2600, loss 56.464646, time: 3.413
training: epoch 2, step 2800, loss 56.492738, time: 3.413
training: epoch 2, step 3000, loss 56.484616, time: 3.413
training: epoch 2, step 3200, loss 56.416158, time: 3.413
training: epoch 2, step 3400, loss 56.260696, time: 3.413
training: epoch 2, step 3600, loss 56.136582, time: 3.413
training: epoch 2, step 3800, loss 56.004309, time: 3.413
training: epoch 2, step 4000, loss 56.001399, time: 3.409
training: epoch 2, step 4200, loss 55.899671, time: 3.407
training: epoch 2, step 4400, loss 55.862849, time: 3.405
training: epoch 2, step 4600, loss 55.761453, time: 3.414
training: epoch 2, step 4800, loss 55.725454, time: 3.410
training: epoch 2, step 5000, loss 55.676064, time: 3.411
training: epoch 2, step 5200, loss 55.583448, time: 3.413
training: epoch 2, step 5400, loss 55.449819, time: 3.410
training: epoch 2, step 5600, loss 55.354263, time: 3.410
training: epoch 2, step 5800, loss 55.316574, time: 3.410
training: epoch 2, step 6000, loss 55.275303, time: 3.407
training: epoch 2, step 6200, loss 55.232902, time: 3.410
training: epoch 2, step 6400, loss 55.185844, time: 3.411
training: epoch 2, step 6600, loss 55.087573, time: 3.413
training: epoch 2, step 6800, loss 55.013888, time: 3.408
training: epoch 2, step 7000, loss 54.923756, time: 3.409
training: epoch 2, step 7200, loss 54.842209, time: 3.411
training: epoch 2, step 7400, loss 54.787602, time: 3.409
training: epoch 2, step 7600, loss 54.715274, time: 3.408
training: epoch 2, step 7800, loss 54.622974, time: 3.410
training: epoch 2, step 7849, loss 54.603585, time: 0.836
validate: epoch 2, loss 54.096441, charcter error 9.807 time: 3.999
    - [Info] The checkpoint file has been updated.
training: epoch 3, step 200, loss 52.370226, time: 3.358
training: epoch 3, step 400, loss 51.783743, time: 3.391
training: epoch 3, step 600, loss 51.653057, time: 3.391
training: epoch 3, step 800, loss 51.762512, time: 3.401
training: epoch 3, step 1000, loss 51.775804, time: 3.405
training: epoch 3, step 1200, loss 51.669760, time: 3.405
training: epoch 3, step 1400, loss 51.612339, time: 3.403
training: epoch 3, step 1600, loss 51.562389, time: 3.403
training: epoch 3, step 1800, loss 51.603102, time: 3.402
training: epoch 3, step 2000, loss 51.570999, time: 3.411
training: epoch 3, step 2200, loss 51.662454, time: 3.412
training: epoch 3, step 2400, loss 51.508961, time: 3.409
training: epoch 3, step 2600, loss 51.490746, time: 3.411
training: epoch 3, step 2800, loss 51.520102, time: 3.413
training: epoch 3, step 3000, loss 51.467226, time: 3.411
training: epoch 3, step 3200, loss 51.386650, time: 3.412
training: epoch 3, step 3400, loss 51.410211, time: 3.407
training: epoch 3, step 3600, loss 51.308307, time: 3.404
training: epoch 3, step 3800, loss 51.302276, time: 3.431
training: epoch 3, step 4000, loss 51.186425, time: 3.466
training: epoch 3, step 4200, loss 51.118939, time: 3.889
training: epoch 3, step 4400, loss 51.092623, time: 4.038
training: epoch 3, step 4600, loss 51.038386, time: 4.089
training: epoch 3, step 4800, loss 50.915329, time: 3.908
training: epoch 3, step 5000, loss 50.840239, time: 3.667
training: epoch 3, step 5200, loss 50.811720, time: 3.990
training: epoch 3, step 5400, loss 50.747601, time: 4.068
training: epoch 3, step 5600, loss 50.737821, time: 4.090
training: epoch 3, step 5800, loss 50.677289, time: 4.039
training: epoch 3, step 6000, loss 50.673060, time: 4.126
training: epoch 3, step 6200, loss 50.628198, time: 4.058
training: epoch 3, step 6400, loss 50.562522, time: 4.060
training: epoch 3, step 6600, loss 50.538899, time: 4.065
training: epoch 3, step 6800, loss 50.488162, time: 4.090
training: epoch 3, step 7000, loss 50.510456, time: 4.080
training: epoch 3, step 7200, loss 50.460037, time: 4.098
training: epoch 3, step 7400, loss 50.408391, time: 4.069
training: epoch 3, step 7600, loss 50.454996, time: 4.053
training: epoch 3, step 7800, loss 50.446637, time: 4.070
training: epoch 3, step 7849, loss 50.456446, time: 0.990
validate: epoch 3, loss 49.433539, charcter error 9.026 time: 5.931
    - [Info] The checkpoint file has been updated.
training: epoch 4, step 200, loss 49.377947, time: 4.047
training: epoch 4, step 400, loss 49.685509, time: 4.079
training: epoch 4, step 600, loss 49.298112, time: 4.029
training: epoch 4, step 800, loss 48.835576, time: 4.034
training: epoch 4, step 1000, loss 48.947550, time: 4.026
training: epoch 4, step 1200, loss 48.942199, time: 4.043
training: epoch 4, step 1400, loss 49.000189, time: 4.054
training: epoch 4, step 1600, loss 49.007586, time: 4.103
training: epoch 4, step 1800, loss 48.966975, time: 4.061
training: epoch 4, step 2000, loss 49.090462, time: 4.127
training: epoch 4, step 2200, loss 49.116276, time: 4.196
training: epoch 4, step 2400, loss 49.017483, time: 4.201
training: epoch 4, step 2600, loss 48.987548, time: 4.165
training: epoch 4, step 2800, loss 48.843051, time: 4.196
training: epoch 4, step 3000, loss 48.852956, time: 4.169
training: epoch 4, step 3200, loss 48.687301, time: 4.236
training: epoch 4, step 3400, loss 48.612227, time: 4.189
training: epoch 4, step 3600, loss 48.551743, time: 4.128
training: epoch 4, step 3800, loss 48.457391, time: 4.191
training: epoch 4, step 4000, loss 48.385821, time: 4.201
training: epoch 4, step 4200, loss 48.399767, time: 4.121
training: epoch 4, step 4400, loss 48.453438, time: 4.179
training: epoch 4, step 4600, loss 48.426020, time: 4.125
training: epoch 4, step 4800, loss 48.402201, time: 4.114
training: epoch 4, step 5000, loss 48.340228, time: 4.122
training: epoch 4, step 5200, loss 48.296528, time: 4.136
training: epoch 4, step 5400, loss 48.301123, time: 4.081
training: epoch 4, step 5600, loss 48.313471, time: 4.080
training: epoch 4, step 5800, loss 48.279024, time: 4.071
training: epoch 4, step 6000, loss 48.266654, time: 4.071
training: epoch 4, step 6200, loss 48.315813, time: 4.086
training: epoch 4, step 6400, loss 48.333128, time: 4.003
training: epoch 4, step 6600, loss 48.282808, time: 4.059
training: epoch 4, step 6800, loss 48.257168, time: 4.031
training: epoch 4, step 7000, loss 48.253346, time: 4.028
training: epoch 4, step 7200, loss 48.245200, time: 4.011
training: epoch 4, step 7400, loss 48.258422, time: 3.922
training: epoch 4, step 7600, loss 48.224295, time: 3.646
training: epoch 4, step 7800, loss 48.237787, time: 3.891
training: epoch 4, step 7849, loss 48.236605, time: 0.939
validate: epoch 4, loss 47.362756, charcter error 8.601 time: 4.047
    - [Info] The checkpoint file has been updated.
training: epoch 5, step 200, loss 46.503750, time: 3.863
training: epoch 5, step 400, loss 46.555996, time: 3.772
training: epoch 5, step 600, loss 46.628184, time: 3.807
training: epoch 5, step 800, loss 46.738532, time: 3.771
training: epoch 5, step 1000, loss 46.941054, time: 3.757
training: epoch 5, step 1200, loss 46.935687, time: 3.640
training: epoch 5, step 1400, loss 46.933314, time: 3.541
training: epoch 5, step 1600, loss 46.963992, time: 3.534
training: epoch 5, step 1800, loss 46.754165, time: 3.508
training: epoch 5, step 2000, loss 46.652846, time: 3.470
training: epoch 5, step 2200, loss 46.671047, time: 3.444
training: epoch 5, step 2400, loss 46.675475, time: 3.443
training: epoch 5, step 2600, loss 46.759306, time: 3.431
training: epoch 5, step 2800, loss 46.824655, time: 3.419
training: epoch 5, step 3000, loss 46.886336, time: 3.416
training: epoch 5, step 3200, loss 46.879488, time: 3.433
training: epoch 5, step 3400, loss 46.855343, time: 3.440
training: epoch 5, step 3600, loss 47.084930, time: 3.472
training: epoch 5, step 3800, loss 47.085846, time: 3.415
training: epoch 5, step 4000, loss 47.052949, time: 3.473
training: epoch 5, step 4200, loss 47.033582, time: 3.472
training: epoch 5, step 4400, loss 46.959330, time: 3.534
training: epoch 5, step 4600, loss 46.908486, time: 3.544
training: epoch 5, step 4800, loss 46.896500, time: 3.554
training: epoch 5, step 5000, loss 46.867243, time: 3.545
training: epoch 5, step 5200, loss 46.855123, time: 3.561
training: epoch 5, step 5400, loss 46.875850, time: 3.534
training: epoch 5, step 5600, loss 46.847866, time: 3.554
training: epoch 5, step 5800, loss 46.824737, time: 3.611
training: epoch 5, step 6000, loss 46.808312, time: 3.651
training: epoch 5, step 6200, loss 46.809476, time: 3.572
training: epoch 5, step 6400, loss 46.782205, time: 3.584
training: epoch 5, step 6600, loss 46.798152, time: 3.603
training: epoch 5, step 6800, loss 46.813532, time: 3.656
training: epoch 5, step 7000, loss 46.796164, time: 3.631
training: epoch 5, step 7200, loss 46.778176, time: 3.638
training: epoch 5, step 7400, loss 46.716595, time: 3.567
training: epoch 5, step 7600, loss 46.664543, time: 3.626
training: epoch 5, step 7800, loss 46.635240, time: 3.659
training: epoch 5, step 7849, loss 46.616941, time: 0.882
validate: epoch 5, loss 45.900045, charcter error 8.309 time: 4.033
    - [Info] The checkpoint file has been updated.
training: epoch 6, step 200, loss 43.373094, time: 3.567
training: epoch 6, step 400, loss 44.743046, time: 3.409
training: epoch 6, step 600, loss 45.454019, time: 3.422
training: epoch 6, step 800, loss 45.419091, time: 3.437
training: epoch 6, step 1000, loss 45.596821, time: 3.468
training: epoch 6, step 1200, loss 45.672955, time: 3.462
training: epoch 6, step 1400, loss 45.701876, time: 3.460
training: epoch 6, step 1600, loss 45.704609, time: 3.465
training: epoch 6, step 1800, loss 45.789002, time: 3.475
training: epoch 6, step 2000, loss 45.732630, time: 3.475
training: epoch 6, step 2200, loss 45.746972, time: 3.466
training: epoch 6, step 2400, loss 45.897418, time: 3.466
training: epoch 6, step 2600, loss 45.847222, time: 3.464
training: epoch 6, step 2800, loss 45.784385, time: 3.465
training: epoch 6, step 3000, loss 45.763491, time: 3.497
training: epoch 6, step 3200, loss 45.688730, time: 3.470
training: epoch 6, step 3400, loss 45.613731, time: 3.503
training: epoch 6, step 3600, loss 45.634423, time: 3.470
training: epoch 6, step 3800, loss 45.633548, time: 3.441
training: epoch 6, step 4000, loss 45.639353, time: 3.458
training: epoch 6, step 4200, loss 45.662793, time: 3.458
training: epoch 6, step 4400, loss 45.693955, time: 3.444
training: epoch 6, step 4600, loss 45.764172, time: 3.473
training: epoch 6, step 4800, loss 45.717360, time: 3.448
training: epoch 6, step 5000, loss 45.688973, time: 3.498
training: epoch 6, step 5200, loss 45.702874, time: 3.481
training: epoch 6, step 5400, loss 45.657725, time: 3.478
training: epoch 6, step 5600, loss 45.645885, time: 3.487
training: epoch 6, step 5800, loss 45.666940, time: 3.500
training: epoch 6, step 6000, loss 45.652783, time: 3.467
training: epoch 6, step 6200, loss 45.649723, time: 3.459
training: epoch 6, step 6400, loss 45.622065, time: 3.489
training: epoch 6, step 6600, loss 45.584100, time: 3.489
training: epoch 6, step 6800, loss 45.610488, time: 3.458
training: epoch 6, step 7000, loss 45.544142, time: 3.443
training: epoch 6, step 7200, loss 45.518397, time: 3.427
training: epoch 6, step 7400, loss 45.492661, time: 3.420
training: epoch 6, step 7600, loss 45.574821, time: 3.415
training: epoch 6, step 7800, loss 45.581012, time: 3.415
training: epoch 6, step 7849, loss 45.597595, time: 0.840
validate: epoch 6, loss 45.996147, charcter error 8.305 time: 4.037
    - [Info] The checkpoint file has been updated.
training: epoch 7, step 200, loss 45.424130, time: 3.364
training: epoch 7, step 400, loss 45.752748, time: 3.402
training: epoch 7, step 600, loss 45.327535, time: 3.409
training: epoch 7, step 800, loss 45.177072, time: 3.410
training: epoch 7, step 1000, loss 45.176425, time: 3.408
training: epoch 7, step 1200, loss 45.094403, time: 3.413
training: epoch 7, step 1400, loss 44.987591, time: 3.412
training: epoch 7, step 1600, loss 44.848331, time: 3.406
training: epoch 7, step 1800, loss 44.820862, time: 3.407
training: epoch 7, step 2000, loss 44.929760, time: 3.413
training: epoch 7, step 2200, loss 44.947261, time: 3.413
training: epoch 7, step 2400, loss 45.009548, time: 3.413
training: epoch 7, step 2600, loss 45.079496, time: 3.410
training: epoch 7, step 2800, loss 44.990260, time: 3.413
training: epoch 7, step 3000, loss 44.935995, time: 3.413
training: epoch 7, step 3200, loss 44.870169, time: 3.412
training: epoch 7, step 3400, loss 44.936517, time: 3.408
training: epoch 7, step 3600, loss 44.989464, time: 3.413
training: epoch 7, step 3800, loss 44.937887, time: 3.414
training: epoch 7, step 4000, loss 44.925659, time: 3.412
training: epoch 7, step 4200, loss 44.997346, time: 3.411
training: epoch 7, step 4400, loss 45.054144, time: 3.413
training: epoch 7, step 4600, loss 45.054023, time: 3.412
training: epoch 7, step 4800, loss 45.048217, time: 3.415
training: epoch 7, step 5000, loss 45.076925, time: 3.411
training: epoch 7, step 5200, loss 45.051916, time: 3.412
training: epoch 7, step 5400, loss 45.060675, time: 3.409
training: epoch 7, step 5600, loss 45.042303, time: 3.412
training: epoch 7, step 5800, loss 45.069702, time: 3.413
training: epoch 7, step 6000, loss 45.016000, time: 3.412
training: epoch 7, step 6200, loss 44.976391, time: 3.413
training: epoch 7, step 6400, loss 44.941220, time: 3.410
training: epoch 7, step 6600, loss 44.909825, time: 3.413
training: epoch 7, step 6800, loss 44.972236, time: 3.413
training: epoch 7, step 7000, loss 44.951294, time: 3.413
training: epoch 7, step 7200, loss 44.922400, time: 3.410
training: epoch 7, step 7400, loss 44.916688, time: 3.413
training: epoch 7, step 7600, loss 44.891068, time: 3.413
training: epoch 7, step 7800, loss 44.873687, time: 3.411
training: epoch 7, step 7849, loss 44.863183, time: 0.834
validate: epoch 7, loss 44.614116, charcter error 8.036 time: 4.009
    - [Info] The checkpoint file has been updated.
training: epoch 8, step 200, loss 43.930580, time: 3.368
training: epoch 8, step 400, loss 43.607877, time: 3.412
training: epoch 8, step 600, loss 43.444349, time: 3.417
training: epoch 8, step 800, loss 43.387757, time: 3.416
training: epoch 8, step 1000, loss 43.359729, time: 3.415
training: epoch 8, step 1200, loss 43.467687, time: 3.413
training: epoch 8, step 1400, loss 43.556462, time: 3.413
training: epoch 8, step 1600, loss 43.582891, time: 3.413
training: epoch 8, step 1800, loss 43.645155, time: 3.413
training: epoch 8, step 2000, loss 43.813682, time: 3.413
training: epoch 8, step 2200, loss 43.896408, time: 3.413
training: epoch 8, step 2400, loss 43.900730, time: 3.417
training: epoch 8, step 2600, loss 43.856373, time: 3.417
training: epoch 8, step 2800, loss 43.901449, time: 3.413
training: epoch 8, step 3000, loss 43.869480, time: 3.413
training: epoch 8, step 3200, loss 43.802403, time: 3.413
training: epoch 8, step 3400, loss 43.748826, time: 3.413
training: epoch 8, step 3600, loss 43.728671, time: 3.413
training: epoch 8, step 3800, loss 43.690806, time: 3.417
training: epoch 8, step 4000, loss 43.722235, time: 3.417
training: epoch 8, step 4200, loss 43.681673, time: 3.416
training: epoch 8, step 4400, loss 43.762714, time: 3.413
training: epoch 8, step 4600, loss 43.753689, time: 3.413
training: epoch 8, step 4800, loss 43.763505, time: 3.413
training: epoch 8, step 5000, loss 43.721209, time: 3.413
training: epoch 8, step 5200, loss 43.721487, time: 3.413
training: epoch 8, step 5400, loss 43.727095, time: 3.413
training: epoch 8, step 5600, loss 43.740421, time: 3.413
training: epoch 8, step 5800, loss 43.686543, time: 3.413
training: epoch 8, step 6000, loss 43.649966, time: 3.413
training: epoch 8, step 6200, loss 43.602625, time: 3.413
training: epoch 8, step 6400, loss 43.664467, time: 3.414
training: epoch 8, step 6600, loss 43.783591, time: 3.415
training: epoch 8, step 6800, loss 43.808884, time: 3.417
training: epoch 8, step 7000, loss 43.845733, time: 3.413
training: epoch 8, step 7200, loss 43.837194, time: 3.413
training: epoch 8, step 7400, loss 43.907720, time: 3.417
training: epoch 8, step 7600, loss 43.919017, time: 3.413
training: epoch 8, step 7800, loss 43.968876, time: 3.415
training: epoch 8, step 7849, loss 43.970938, time: 0.836
validate: epoch 8, loss 44.923889, charcter error 8.087 time: 4.004
training: epoch 9, step 200, loss 44.353942, time: 3.366
training: epoch 9, step 400, loss 44.302017, time: 3.410
training: epoch 9, step 600, loss 44.320010, time: 3.413
training: epoch 9, step 800, loss 44.445117, time: 3.420
training: epoch 9, step 1000, loss 44.211036, time: 3.413
training: epoch 9, step 1200, loss 44.038556, time: 3.413
training: epoch 9, step 1400, loss 43.980141, time: 3.420
training: epoch 9, step 1600, loss 43.821758, time: 3.414
training: epoch 9, step 1800, loss 43.856050, time: 3.413
training: epoch 9, step 2000, loss 43.769594, time: 3.413
training: epoch 9, step 2200, loss 43.766793, time: 3.413
training: epoch 9, step 2400, loss 43.890929, time: 3.413
training: epoch 9, step 2600, loss 43.867419, time: 3.413
training: epoch 9, step 2800, loss 43.920102, time: 3.413
training: epoch 9, step 3000, loss 44.010233, time: 3.413
training: epoch 9, step 3200, loss 44.147212, time: 3.413
training: epoch 9, step 3400, loss 44.198869, time: 3.413
training: epoch 9, step 3600, loss 44.197018, time: 3.420
training: epoch 9, step 3800, loss 44.244224, time: 3.413
training: epoch 9, step 4000, loss 44.209083, time: 3.414
training: epoch 9, step 4200, loss 44.191073, time: 3.413
training: epoch 9, step 4400, loss 44.143655, time: 3.413
training: epoch 9, step 4600, loss 44.093372, time: 3.414
training: epoch 9, step 4800, loss 44.086138, time: 3.413
training: epoch 9, step 5000, loss 44.068853, time: 3.413
training: epoch 9, step 5200, loss 44.055839, time: 3.413
training: epoch 9, step 5400, loss 44.003225, time: 3.413
training: epoch 9, step 5600, loss 43.979110, time: 3.413
training: epoch 9, step 5800, loss 44.019322, time: 3.413
training: epoch 9, step 6000, loss 44.057940, time: 3.413
training: epoch 9, step 6200, loss 43.994418, time: 3.416
training: epoch 9, step 6400, loss 43.963234, time: 3.413
training: epoch 9, step 6600, loss 43.934107, time: 3.417
training: epoch 9, step 6800, loss 43.920658, time: 3.413
training: epoch 9, step 7000, loss 43.899366, time: 3.413
training: epoch 9, step 7200, loss 43.929735, time: 3.414
training: epoch 9, step 7400, loss 43.946311, time: 3.413
training: epoch 9, step 7600, loss 43.916495, time: 3.414
training: epoch 9, step 7800, loss 43.916486, time: 3.413
training: epoch 9, step 7849, loss 43.901643, time: 0.836
validate: epoch 9, loss 43.958098, charcter error 7.865 time: 3.999
    - [Info] The checkpoint file has been updated.
training: epoch 10, step 200, loss 43.706720, time: 3.365
training: epoch 10, step 400, loss 42.870848, time: 3.404
training: epoch 10, step 600, loss 42.478886, time: 3.412
training: epoch 10, step 800, loss 42.549274, time: 3.413
training: epoch 10, step 1000, loss 42.442000, time: 3.412
training: epoch 10, step 1200, loss 42.476097, time: 3.411
training: epoch 10, step 1400, loss 42.550411, time: 3.411
training: epoch 10, step 1600, loss 42.591452, time: 3.410
training: epoch 10, step 1800, loss 42.627105, time: 3.412
training: epoch 10, step 2000, loss 42.811782, time: 3.407
training: epoch 10, step 2200, loss 42.834502, time: 3.410
training: epoch 10, step 2400, loss 42.829831, time: 3.413
training: epoch 10, step 2600, loss 42.757055, time: 3.414
training: epoch 10, step 2800, loss 42.762445, time: 3.413
training: epoch 10, step 3000, loss 42.772340, time: 3.413
training: epoch 10, step 3200, loss 42.749270, time: 3.413
training: epoch 10, step 3400, loss 42.667911, time: 3.412
training: epoch 10, step 3600, loss 42.659418, time: 3.414
training: epoch 10, step 3800, loss 42.587380, time: 3.414
training: epoch 10, step 4000, loss 42.585691, time: 3.413
training: epoch 10, step 4200, loss 42.539558, time: 3.412
training: epoch 10, step 4400, loss 42.531456, time: 3.412
training: epoch 10, step 4600, loss 42.492768, time: 3.411
training: epoch 10, step 4800, loss 42.514064, time: 3.413
training: epoch 10, step 5000, loss 42.564114, time: 3.412
training: epoch 10, step 5200, loss 42.570483, time: 3.410
training: epoch 10, step 5400, loss 42.684750, time: 3.411
training: epoch 10, step 5600, loss 42.710582, time: 3.413
training: epoch 10, step 5800, loss 42.761605, time: 3.410
training: epoch 10, step 6000, loss 42.770788, time: 3.413
training: epoch 10, step 6200, loss 42.753925, time: 3.413
training: epoch 10, step 6400, loss 42.763783, time: 3.412
training: epoch 10, step 6600, loss 42.770164, time: 3.410
training: epoch 10, step 6800, loss 42.832918, time: 3.410
training: epoch 10, step 7000, loss 42.886476, time: 3.412
training: epoch 10, step 7200, loss 42.931629, time: 3.413
training: epoch 10, step 7400, loss 42.904340, time: 3.413
training: epoch 10, step 7600, loss 42.905274, time: 3.412
training: epoch 10, step 7800, loss 42.870383, time: 3.406
training: epoch 10, step 7849, loss 42.875487, time: 0.836
validate: epoch 10, loss 43.338773, charcter error 7.778 time: 4.015
    - [Info] The checkpoint file has been updated.
training: epoch 11, step 200, loss 42.743839, time: 3.368
training: epoch 11, step 400, loss 42.633555, time: 3.410
training: epoch 11, step 600, loss 42.360822, time: 3.410
training: epoch 11, step 800, loss 42.262971, time: 3.413
training: epoch 11, step 1000, loss 42.300216, time: 3.413
training: epoch 11, step 1200, loss 42.366659, time: 3.413
training: epoch 11, step 1400, loss 42.384031, time: 3.412
training: epoch 11, step 1600, loss 42.438176, time: 3.412
training: epoch 11, step 1800, loss 42.415622, time: 3.414
training: epoch 11, step 2000, loss 42.375979, time: 3.413
training: epoch 11, step 2200, loss 42.532786, time: 3.412
training: epoch 11, step 2400, loss 42.553312, time: 3.413
training: epoch 11, step 2600, loss 42.509781, time: 3.413
training: epoch 11, step 2800, loss 42.491763, time: 3.413
training: epoch 11, step 3000, loss 42.388477, time: 3.412
training: epoch 11, step 3200, loss 42.372622, time: 3.411
training: epoch 11, step 3400, loss 42.377925, time: 3.413
training: epoch 11, step 3600, loss 42.348657, time: 3.414
training: epoch 11, step 3800, loss 42.345518, time: 3.413
training: epoch 11, step 4000, loss 42.238984, time: 3.413
training: epoch 11, step 4200, loss 42.229522, time: 3.413
training: epoch 11, step 4400, loss 42.225726, time: 3.413
training: epoch 11, step 4600, loss 42.198307, time: 3.413
training: epoch 11, step 4800, loss 42.192970, time: 3.413
training: epoch 11, step 5000, loss 42.195031, time: 3.413
training: epoch 11, step 5200, loss 42.157785, time: 3.413
training: epoch 11, step 5400, loss 42.153890, time: 3.413
training: epoch 11, step 5600, loss 42.155196, time: 3.411
training: epoch 11, step 5800, loss 42.133211, time: 3.411
training: epoch 11, step 6000, loss 42.141430, time: 3.412
training: epoch 11, step 6200, loss 42.123727, time: 3.413
training: epoch 11, step 6400, loss 42.133509, time: 3.411
training: epoch 11, step 6600, loss 42.121094, time: 3.407
training: epoch 11, step 6800, loss 42.099656, time: 3.409
training: epoch 11, step 7000, loss 42.090211, time: 3.410
training: epoch 11, step 7200, loss 42.104788, time: 3.404
training: epoch 11, step 7400, loss 42.086250, time: 3.406
training: epoch 11, step 7600, loss 42.056382, time: 3.410
training: epoch 11, step 7800, loss 42.030098, time: 3.413
training: epoch 11, step 7849, loss 42.032024, time: 0.839
validate: epoch 11, loss 42.333199, charcter error 7.616 time: 4.029
    - [Info] The checkpoint file has been updated.
training: epoch 12, step 200, loss 41.167814, time: 3.367
training: epoch 12, step 400, loss 40.933401, time: 3.405
training: epoch 12, step 600, loss 40.838887, time: 3.413
training: epoch 12, step 800, loss 40.769122, time: 3.413
training: epoch 12, step 1000, loss 40.860161, time: 3.413
training: epoch 12, step 1200, loss 41.009911, time: 3.413
training: epoch 12, step 1400, loss 40.893562, time: 3.415
training: epoch 12, step 1600, loss 40.985070, time: 3.415
training: epoch 12, step 1800, loss 40.977280, time: 3.413
training: epoch 12, step 2000, loss 40.875548, time: 3.413
training: epoch 12, step 2200, loss 40.832365, time: 3.413
training: epoch 12, step 2400, loss 40.902027, time: 3.413
training: epoch 12, step 2600, loss 40.896204, time: 3.413
training: epoch 12, step 2800, loss 40.907692, time: 3.413
training: epoch 12, step 3000, loss 40.898213, time: 3.413
training: epoch 12, step 3200, loss 40.922865, time: 3.413
training: epoch 12, step 3400, loss 40.948266, time: 3.413
training: epoch 12, step 3600, loss 40.901051, time: 3.413
training: epoch 12, step 3800, loss 40.882956, time: 3.413
training: epoch 12, step 4000, loss 40.851004, time: 3.413
training: epoch 12, step 4200, loss 40.933374, time: 3.413
training: epoch 12, step 4400, loss 40.861805, time: 3.413
training: epoch 12, step 4600, loss 40.876708, time: 3.413
training: epoch 12, step 4800, loss 40.884443, time: 3.413
training: epoch 12, step 5000, loss 40.889312, time: 3.413
training: epoch 12, step 5200, loss 40.876060, time: 3.413
training: epoch 12, step 5400, loss 40.901601, time: 3.413
training: epoch 12, step 5600, loss 40.896636, time: 3.413
training: epoch 12, step 5800, loss 40.919040, time: 3.413
training: epoch 12, step 6000, loss 40.911883, time: 3.413
training: epoch 12, step 6200, loss 40.913854, time: 3.411
training: epoch 12, step 6400, loss 40.912197, time: 3.414
training: epoch 12, step 6600, loss 40.887769, time: 3.413
training: epoch 12, step 6800, loss 40.864059, time: 3.413
training: epoch 12, step 7000, loss 40.856433, time: 3.413
training: epoch 12, step 7200, loss 40.875935, time: 3.415
training: epoch 12, step 7400, loss 40.875312, time: 3.413
training: epoch 12, step 7600, loss 40.876135, time: 3.413
training: epoch 12, step 7800, loss 40.890887, time: 3.413
training: epoch 12, step 7849, loss 40.901912, time: 0.836
validate: epoch 12, loss 41.247395, charcter error 7.467 time: 4.013
    - [Info] The checkpoint file has been updated.
training: epoch 13, step 200, loss 40.454403, time: 3.354
training: epoch 13, step 400, loss 40.549699, time: 3.398
training: epoch 13, step 600, loss 40.947698, time: 3.405
training: epoch 13, step 800, loss 40.950799, time: 3.404
training: epoch 13, step 1000, loss 40.741243, time: 3.402
training: epoch 13, step 1200, loss 40.446287, time: 3.400
training: epoch 13, step 1400, loss 40.189865, time: 3.400
training: epoch 13, step 1600, loss 40.246272, time: 3.401
training: epoch 13, step 1800, loss 40.252289, time: 3.406
training: epoch 13, step 2000, loss 40.250051, time: 3.408
training: epoch 13, step 2200, loss 40.191185, time: 3.406
training: epoch 13, step 2400, loss 40.122201, time: 3.407
training: epoch 13, step 2600, loss 40.140539, time: 3.410
training: epoch 13, step 2800, loss 40.157515, time: 3.405
training: epoch 13, step 3000, loss 40.199583, time: 3.411
training: epoch 13, step 3200, loss 40.273854, time: 3.410
training: epoch 13, step 3400, loss 40.210732, time: 3.411
training: epoch 13, step 3600, loss 40.139107, time: 3.405
training: epoch 13, step 3800, loss 40.181018, time: 3.407
training: epoch 13, step 4000, loss 40.218581, time: 3.409
training: epoch 13, step 4200, loss 40.192389, time: 3.401
training: epoch 13, step 4400, loss 40.163425, time: 3.400
training: epoch 13, step 4600, loss 40.172755, time: 3.410
training: epoch 13, step 4800, loss 40.142102, time: 3.408
training: epoch 13, step 5000, loss 40.212033, time: 3.407
training: epoch 13, step 5200, loss 40.246068, time: 3.405
training: epoch 13, step 5400, loss 40.246563, time: 3.410
training: epoch 13, step 5600, loss 40.228327, time: 3.406
training: epoch 13, step 5800, loss 40.267686, time: 3.407
training: epoch 13, step 6000, loss 40.293621, time: 3.412
training: epoch 13, step 6200, loss 40.266104, time: 3.413
training: epoch 13, step 6400, loss 40.235782, time: 3.410
training: epoch 13, step 6600, loss 40.270916, time: 3.405
training: epoch 13, step 6800, loss 40.273403, time: 3.410
training: epoch 13, step 7000, loss 40.269009, time: 3.410
training: epoch 13, step 7200, loss 40.307119, time: 3.409
training: epoch 13, step 7400, loss 40.293881, time: 3.404
training: epoch 13, step 7600, loss 40.301158, time: 3.408
training: epoch 13, step 7800, loss 40.280065, time: 3.409
training: epoch 13, step 7849, loss 40.284789, time: 0.835
validate: epoch 13, loss 41.003844, charcter error 7.405 time: 4.012
    - [Info] The checkpoint file has been updated.
training: epoch 14, step 200, loss 39.812973, time: 3.364
training: epoch 14, step 400, loss 39.241766, time: 3.401
training: epoch 14, step 600, loss 39.408075, time: 3.412
training: epoch 14, step 800, loss 39.351114, time: 3.413
training: epoch 14, step 1000, loss 39.572203, time: 3.413
training: epoch 14, step 1200, loss 39.531710, time: 3.409
training: epoch 14, step 1400, loss 39.634775, time: 3.408
training: epoch 14, step 1600, loss 39.624293, time: 3.413
training: epoch 14, step 1800, loss 39.639656, time: 3.413
training: epoch 14, step 2000, loss 39.660116, time: 3.413
training: epoch 14, step 2200, loss 39.736392, time: 3.413
training: epoch 14, step 2400, loss 39.701979, time: 3.413
training: epoch 14, step 2600, loss 39.645679, time: 3.413
training: epoch 14, step 2800, loss 39.677657, time: 3.411
training: epoch 14, step 3000, loss 39.724879, time: 3.412
training: epoch 14, step 3200, loss 39.779483, time: 3.411
training: epoch 14, step 3400, loss 39.782038, time: 3.409
training: epoch 14, step 3600, loss 39.854556, time: 3.425
training: epoch 14, step 3800, loss 39.879727, time: 3.551
training: epoch 14, step 4000, loss 39.855195, time: 3.532
training: epoch 14, step 4200, loss 39.877508, time: 3.564
training: epoch 14, step 4400, loss 39.877352, time: 3.556
training: epoch 14, step 4600, loss 39.854862, time: 3.539
training: epoch 14, step 4800, loss 39.884391, time: 3.551
training: epoch 14, step 5000, loss 39.826326, time: 3.516
training: epoch 14, step 5200, loss 39.852472, time: 3.536
training: epoch 14, step 5400, loss 39.845407, time: 3.537
training: epoch 14, step 5600, loss 39.862548, time: 3.528
training: epoch 14, step 5800, loss 39.827732, time: 3.521
training: epoch 14, step 6000, loss 39.824686, time: 3.619
training: epoch 14, step 6200, loss 39.840559, time: 3.532
training: epoch 14, step 6400, loss 39.830949, time: 3.469
training: epoch 14, step 6600, loss 39.825184, time: 3.453
training: epoch 14, step 6800, loss 39.848040, time: 3.433
training: epoch 14, step 7000, loss 39.822913, time: 3.424
training: epoch 14, step 7200, loss 39.810359, time: 3.425
training: epoch 14, step 7400, loss 39.808999, time: 3.420
training: epoch 14, step 7600, loss 39.811805, time: 3.417
training: epoch 14, step 7800, loss 39.783735, time: 3.414
training: epoch 14, step 7849, loss 39.791792, time: 0.836
validate: epoch 14, loss 40.881869, charcter error 7.399 time: 4.032
    - [Info] The checkpoint file has been updated.
training: epoch 15, step 200, loss 39.719286, time: 3.375
training: epoch 15, step 400, loss 39.169929, time: 3.413
training: epoch 15, step 600, loss 38.810660, time: 3.416
training: epoch 15, step 800, loss 38.926112, time: 3.413
training: epoch 15, step 1000, loss 38.765663, time: 3.413
training: epoch 15, step 1200, loss 38.689056, time: 3.413
training: epoch 15, step 1400, loss 38.806508, time: 3.413
training: epoch 15, step 1600, loss 38.885254, time: 3.413
training: epoch 15, step 1800, loss 38.992551, time: 3.412
training: epoch 15, step 2000, loss 38.966229, time: 3.411
training: epoch 15, step 2200, loss 39.101244, time: 3.409
training: epoch 15, step 2400, loss 39.068595, time: 3.407
training: epoch 15, step 2600, loss 39.139470, time: 3.413
training: epoch 15, step 2800, loss 39.200699, time: 3.413
training: epoch 15, step 3000, loss 39.268406, time: 3.413
training: epoch 15, step 3200, loss 39.339779, time: 3.413
training: epoch 15, step 3400, loss 39.390269, time: 3.412
training: epoch 15, step 3600, loss 39.350608, time: 3.411
training: epoch 15, step 3800, loss 39.366212, time: 3.409
training: epoch 15, step 4000, loss 39.338650, time: 3.414
training: epoch 15, step 4200, loss 39.428999, time: 3.413
training: epoch 15, step 4400, loss 39.524009, time: 3.413
training: epoch 15, step 4600, loss 39.789657, time: 3.412
training: epoch 15, step 4800, loss 39.859281, time: 3.407
training: epoch 15, step 5000, loss 39.905911, time: 3.410
training: epoch 15, step 5200, loss 39.871324, time: 3.413
training: epoch 15, step 5400, loss 39.913545, time: 3.411
training: epoch 15, step 5600, loss 39.924683, time: 3.412
training: epoch 15, step 5800, loss 39.965948, time: 3.413
training: epoch 15, step 6000, loss 39.964006, time: 3.412
training: epoch 15, step 6200, loss 39.888617, time: 3.410
training: epoch 15, step 6400, loss 39.882691, time: 3.414
training: epoch 15, step 6600, loss 39.890714, time: 3.420
training: epoch 15, step 6800, loss 39.866039, time: 3.413
training: epoch 15, step 7000, loss 39.834285, time: 3.413
training: epoch 15, step 7200, loss 39.818112, time: 3.538
training: epoch 15, step 7400, loss 39.807314, time: 3.485
training: epoch 15, step 7600, loss 39.871577, time: 3.502
training: epoch 15, step 7800, loss 39.866391, time: 3.492
training: epoch 15, step 7849, loss 39.843047, time: 0.859
validate: epoch 15, loss 40.223668, charcter error 7.282 time: 4.031
    - [Info] The checkpoint file has been updated.
training: epoch 16, step 200, loss 40.217978, time: 3.499
training: epoch 16, step 400, loss 39.459200, time: 3.489
training: epoch 16, step 600, loss 39.052726, time: 3.474
training: epoch 16, step 800, loss 39.234312, time: 3.496
training: epoch 16, step 1000, loss 39.264660, time: 3.535
training: epoch 16, step 1200, loss 39.195154, time: 3.507
training: epoch 16, step 1400, loss 38.983063, time: 3.503
training: epoch 16, step 1600, loss 38.958904, time: 3.498
training: epoch 16, step 1800, loss 38.899851, time: 3.513
training: epoch 16, step 2000, loss 38.959461, time: 3.475
training: epoch 16, step 2200, loss 38.949288, time: 3.406
training: epoch 16, step 2400, loss 38.929349, time: 3.410
training: epoch 16, step 2600, loss 38.959942, time: 3.410
training: epoch 16, step 2800, loss 38.976884, time: 3.442
training: epoch 16, step 3000, loss 38.973352, time: 3.483
training: epoch 16, step 3200, loss 38.947681, time: 3.473
training: epoch 16, step 3400, loss 38.974391, time: 3.479
training: epoch 16, step 3600, loss 38.950653, time: 3.475
training: epoch 16, step 3800, loss 38.973910, time: 3.473
training: epoch 16, step 4000, loss 38.925441, time: 3.451
training: epoch 16, step 4200, loss 38.893920, time: 3.453
training: epoch 16, step 4400, loss 39.013771, time: 3.458
training: epoch 16, step 4600, loss 38.988621, time: 3.475
training: epoch 16, step 4800, loss 39.068993, time: 3.462
training: epoch 16, step 5000, loss 39.067204, time: 3.462
training: epoch 16, step 5200, loss 39.060731, time: 3.482
training: epoch 16, step 5400, loss 39.049111, time: 3.458
training: epoch 16, step 5600, loss 39.090170, time: 3.451
training: epoch 16, step 5800, loss 39.079569, time: 3.447
training: epoch 16, step 6000, loss 39.100406, time: 3.460
training: epoch 16, step 6200, loss 39.094076, time: 3.447
training: epoch 16, step 6400, loss 39.096165, time: 3.451
training: epoch 16, step 6600, loss 39.084139, time: 3.462
training: epoch 16, step 6800, loss 39.047557, time: 3.474
training: epoch 16, step 7000, loss 39.008094, time: 3.475
training: epoch 16, step 7200, loss 39.002086, time: 3.494
training: epoch 16, step 7400, loss 38.968685, time: 3.493
training: epoch 16, step 7600, loss 38.997546, time: 3.490
training: epoch 16, step 7800, loss 39.026543, time: 3.461
training: epoch 16, step 7849, loss 39.015100, time: 0.849
validate: epoch 16, loss 39.590004, charcter error 7.196 time: 4.029
    - [Info] The checkpoint file has been updated.
training: epoch 17, step 200, loss 38.474498, time: 3.511
training: epoch 17, step 400, loss 38.167774, time: 3.468
training: epoch 17, step 600, loss 37.915139, time: 3.453
training: epoch 17, step 800, loss 37.965519, time: 3.452
training: epoch 17, step 1000, loss 38.017456, time: 3.434
training: epoch 17, step 1200, loss 38.046297, time: 3.427
training: epoch 17, step 1400, loss 38.175727, time: 3.420
training: epoch 17, step 1600, loss 38.215628, time: 3.418
training: epoch 17, step 1800, loss 38.269560, time: 3.419
training: epoch 17, step 2000, loss 38.434495, time: 3.413
training: epoch 17, step 2200, loss 38.453726, time: 3.413
training: epoch 17, step 2400, loss 38.360916, time: 3.413
training: epoch 17, step 2600, loss 38.406868, time: 3.410
training: epoch 17, step 2800, loss 38.415429, time: 3.410
training: epoch 17, step 3000, loss 38.361948, time: 3.410
training: epoch 17, step 3200, loss 38.429813, time: 3.406
training: epoch 17, step 3400, loss 38.459282, time: 3.407
training: epoch 17, step 3600, loss 38.466311, time: 3.407
training: epoch 17, step 3800, loss 38.488199, time: 3.413
training: epoch 17, step 4000, loss 38.502695, time: 3.412
training: epoch 17, step 4200, loss 38.521121, time: 3.409
training: epoch 17, step 4400, loss 38.496889, time: 3.411
training: epoch 17, step 4600, loss 38.462385, time: 3.413
training: epoch 17, step 4800, loss 38.465674, time: 3.409
training: epoch 17, step 5000, loss 38.500560, time: 3.411
training: epoch 17, step 5200, loss 38.528130, time: 3.413
training: epoch 17, step 5400, loss 38.487504, time: 3.410
training: epoch 17, step 5600, loss 38.479724, time: 3.413
training: epoch 17, step 5800, loss 38.450799, time: 3.413
training: epoch 17, step 6000, loss 38.476600, time: 3.413
training: epoch 17, step 6200, loss 38.468893, time: 3.413
training: epoch 17, step 6400, loss 38.481007, time: 3.413
training: epoch 17, step 6600, loss 38.510821, time: 3.413
training: epoch 17, step 6800, loss 38.559025, time: 3.413
training: epoch 17, step 7000, loss 38.531256, time: 3.413
training: epoch 17, step 7200, loss 38.550857, time: 3.414
training: epoch 17, step 7400, loss 38.536844, time: 3.413
training: epoch 17, step 7600, loss 38.529816, time: 3.413
training: epoch 17, step 7800, loss 38.518585, time: 3.413
training: epoch 17, step 7849, loss 38.525581, time: 0.836
validate: epoch 17, loss 39.523120, charcter error 7.199 time: 4.012
training: epoch 18, step 200, loss 37.424759, time: 3.365
training: epoch 18, step 400, loss 38.413658, time: 3.406
training: epoch 18, step 600, loss 38.752592, time: 3.413
training: epoch 18, step 800, loss 38.467901, time: 3.413
training: epoch 18, step 1000, loss 38.450147, time: 3.413
training: epoch 18, step 1200, loss 38.485151, time: 3.413
training: epoch 18, step 1400, loss 38.754201, time: 3.413
training: epoch 18, step 1600, loss 38.645712, time: 3.410
training: epoch 18, step 1800, loss 38.789994, time: 3.410
training: epoch 18, step 2000, loss 38.803212, time: 3.413
training: epoch 18, step 2200, loss 38.780260, time: 3.413
training: epoch 18, step 2400, loss 38.736620, time: 3.413
training: epoch 18, step 2600, loss 38.753997, time: 3.413
training: epoch 18, step 2800, loss 38.637991, time: 3.413
training: epoch 18, step 3000, loss 38.527003, time: 3.413
training: epoch 18, step 3200, loss 38.469016, time: 3.413
training: epoch 18, step 3400, loss 38.382419, time: 3.413
training: epoch 18, step 3600, loss 38.354251, time: 3.413
training: epoch 18, step 3800, loss 38.390856, time: 3.414
training: epoch 18, step 4000, loss 38.434428, time: 3.413
training: epoch 18, step 4200, loss 38.382688, time: 3.413
training: epoch 18, step 4400, loss 38.383150, time: 3.413
training: epoch 18, step 4600, loss 38.395045, time: 3.413
training: epoch 18, step 4800, loss 38.386520, time: 3.413
training: epoch 18, step 5000, loss 38.370892, time: 3.413
training: epoch 18, step 5200, loss 38.328404, time: 3.413
training: epoch 18, step 5400, loss 38.314020, time: 3.413
training: epoch 18, step 5600, loss 38.296104, time: 3.413
training: epoch 18, step 5800, loss 38.312652, time: 3.413
training: epoch 18, step 6000, loss 38.320323, time: 3.413
training: epoch 18, step 6200, loss 38.294104, time: 3.413
training: epoch 18, step 6400, loss 38.316964, time: 3.413
training: epoch 18, step 6600, loss 38.295958, time: 3.413
training: epoch 18, step 6800, loss 38.319450, time: 3.413
training: epoch 18, step 7000, loss 38.294451, time: 3.413
training: epoch 18, step 7200, loss 38.267517, time: 3.413
training: epoch 18, step 7400, loss 38.268691, time: 3.413
training: epoch 18, step 7600, loss 38.285545, time: 3.413
training: epoch 18, step 7800, loss 38.270302, time: 3.413
training: epoch 18, step 7849, loss 38.261452, time: 0.836
validate: epoch 18, loss 38.934516, charcter error 7.066 time: 4.016
    - [Info] The checkpoint file has been updated.
training: epoch 19, step 200, loss 38.156556, time: 3.370
training: epoch 19, step 400, loss 38.158786, time: 3.411
training: epoch 19, step 600, loss 37.705703, time: 3.413
training: epoch 19, step 800, loss 38.159635, time: 3.413
training: epoch 19, step 1000, loss 37.955479, time: 3.414
training: epoch 19, step 1200, loss 38.047980, time: 3.414
training: epoch 19, step 1400, loss 38.099695, time: 3.413
training: epoch 19, step 1600, loss 38.031801, time: 3.413
training: epoch 19, step 1800, loss 38.161129, time: 3.413
training: epoch 19, step 2000, loss 38.138463, time: 3.413
training: epoch 19, step 2200, loss 38.077144, time: 3.413
training: epoch 19, step 2400, loss 37.957314, time: 3.414
training: epoch 19, step 2600, loss 37.899976, time: 3.413
training: epoch 19, step 2800, loss 37.889203, time: 3.413
training: epoch 19, step 3000, loss 37.953896, time: 3.413
training: epoch 19, step 3200, loss 37.965714, time: 3.413
training: epoch 19, step 3400, loss 37.940553, time: 3.413
training: epoch 19, step 3600, loss 37.980630, time: 3.413
training: epoch 19, step 3800, loss 38.025691, time: 3.413
training: epoch 19, step 4000, loss 38.009153, time: 3.413
training: epoch 19, step 4200, loss 37.992411, time: 3.413
training: epoch 19, step 4400, loss 37.994677, time: 3.413
training: epoch 19, step 4600, loss 37.967144, time: 3.413
training: epoch 19, step 4800, loss 37.947896, time: 3.413
training: epoch 19, step 5000, loss 37.972245, time: 3.413
training: epoch 19, step 5200, loss 37.964622, time: 3.414
training: epoch 19, step 5400, loss 37.948463, time: 3.413
training: epoch 19, step 5600, loss 37.970174, time: 3.413
training: epoch 19, step 5800, loss 37.965137, time: 3.413
training: epoch 19, step 6000, loss 37.976023, time: 3.413
training: epoch 19, step 6200, loss 38.009064, time: 3.413
training: epoch 19, step 6400, loss 37.976332, time: 3.413
training: epoch 19, step 6600, loss 37.949902, time: 3.413
training: epoch 19, step 6800, loss 37.895517, time: 3.413
training: epoch 19, step 7000, loss 37.903468, time: 3.413
training: epoch 19, step 7200, loss 37.896631, time: 3.413
training: epoch 19, step 7400, loss 37.904120, time: 3.409
training: epoch 19, step 7600, loss 37.947933, time: 3.413
training: epoch 19, step 7800, loss 37.949783, time: 3.417
training: epoch 19, step 7849, loss 37.939588, time: 0.836
validate: epoch 19, loss 38.787217, charcter error 7.037 time: 4.013
    - [Info] The checkpoint file has been updated.
training: epoch 20, step 200, loss 37.640020, time: 3.373
training: epoch 20, step 400, loss 38.239105, time: 3.413
training: epoch 20, step 600, loss 38.342381, time: 3.413
training: epoch 20, step 800, loss 38.261585, time: 3.414
training: epoch 20, step 1000, loss 37.968797, time: 3.413
training: epoch 20, step 1200, loss 37.698116, time: 3.413
training: epoch 20, step 1400, loss 37.527311, time: 3.413
training: epoch 20, step 1600, loss 37.692344, time: 3.413
training: epoch 20, step 1800, loss 37.704262, time: 3.413
training: epoch 20, step 2000, loss 37.760351, time: 3.413
training: epoch 20, step 2200, loss 37.782628, time: 3.413
training: epoch 20, step 2400, loss 37.743538, time: 3.407
training: epoch 20, step 2600, loss 37.767992, time: 3.406
training: epoch 20, step 2800, loss 37.786979, time: 3.410
training: epoch 20, step 3000, loss 37.916654, time: 3.408
training: epoch 20, step 3200, loss 37.905274, time: 3.408
training: epoch 20, step 3400, loss 37.896212, time: 3.413
training: epoch 20, step 3600, loss 37.858134, time: 3.406
training: epoch 20, step 3800, loss 37.852225, time: 3.410
training: epoch 20, step 4000, loss 37.877499, time: 3.412
training: epoch 20, step 4200, loss 37.881348, time: 3.414
training: epoch 20, step 4400, loss 37.942765, time: 3.409
training: epoch 20, step 4600, loss 37.925193, time: 3.405
training: epoch 20, step 4800, loss 37.885779, time: 3.408
training: epoch 20, step 5000, loss 37.846315, time: 3.411
training: epoch 20, step 5200, loss 37.893479, time: 3.412
training: epoch 20, step 5400, loss 37.861585, time: 3.406
training: epoch 20, step 5600, loss 37.901564, time: 3.407
training: epoch 20, step 5800, loss 37.970522, time: 3.401
training: epoch 20, step 6000, loss 37.994247, time: 3.397
training: epoch 20, step 6200, loss 38.013606, time: 3.400
training: epoch 20, step 6400, loss 37.995705, time: 3.399
training: epoch 20, step 6600, loss 37.958249, time: 3.402
training: epoch 20, step 6800, loss 37.938173, time: 3.400
training: epoch 20, step 7000, loss 37.976513, time: 3.403
training: epoch 20, step 7200, loss 37.976060, time: 3.405
training: epoch 20, step 7400, loss 37.970425, time: 3.401
training: epoch 20, step 7600, loss 37.952771, time: 3.403
training: epoch 20, step 7800, loss 37.951273, time: 3.403
training: epoch 20, step 7849, loss 37.944943, time: 0.833
validate: epoch 20, loss 38.814160, charcter error 7.047 time: 4.018
training: epoch 21, step 200, loss 35.974750, time: 3.353
training: epoch 21, step 400, loss 36.232055, time: 3.396
training: epoch 21, step 600, loss 36.502352, time: 3.399
training: epoch 21, step 800, loss 36.784344, time: 3.400
training: epoch 21, step 1000, loss 36.703603, time: 3.399
training: epoch 21, step 1200, loss 36.864638, time: 3.404
training: epoch 21, step 1400, loss 36.761392, time: 3.409
training: epoch 21, step 1600, loss 36.964364, time: 3.404
training: epoch 21, step 1800, loss 36.901011, time: 3.398
training: epoch 21, step 2000, loss 36.942833, time: 3.401
training: epoch 21, step 2200, loss 37.040485, time: 3.399
training: epoch 21, step 2400, loss 37.038389, time: 3.405
training: epoch 21, step 2600, loss 37.126003, time: 3.400
training: epoch 21, step 2800, loss 37.145064, time: 3.398
training: epoch 21, step 3000, loss 37.152797, time: 3.403
training: epoch 21, step 3200, loss 37.160995, time: 3.401
training: epoch 21, step 3400, loss 37.244647, time: 3.403
training: epoch 21, step 3600, loss 37.284288, time: 3.409
training: epoch 21, step 3800, loss 37.313520, time: 3.398
training: epoch 21, step 4000, loss 37.365541, time: 3.405
training: epoch 21, step 4200, loss 37.426950, time: 3.401
training: epoch 21, step 4400, loss 37.485283, time: 3.406
training: epoch 21, step 4600, loss 37.538243, time: 3.402
training: epoch 21, step 4800, loss 37.562560, time: 3.393
training: epoch 21, step 5000, loss 37.575241, time: 3.400
training: epoch 21, step 5200, loss 37.639102, time: 3.398
training: epoch 21, step 5400, loss 37.663948, time: 3.393
training: epoch 21, step 5600, loss 37.699857, time: 3.398
training: epoch 21, step 5800, loss 37.682346, time: 3.390
training: epoch 21, step 6000, loss 37.700122, time: 3.391
training: epoch 21, step 6200, loss 37.684380, time: 3.388
training: epoch 21, step 6400, loss 37.654635, time: 3.390
training: epoch 21, step 6600, loss 37.636549, time: 3.392
training: epoch 21, step 6800, loss 37.602227, time: 3.392
training: epoch 21, step 7000, loss 37.595652, time: 3.401
training: epoch 21, step 7200, loss 37.593327, time: 3.395
training: epoch 21, step 7400, loss 37.598806, time: 3.394
training: epoch 21, step 7600, loss 37.573091, time: 3.396
training: epoch 21, step 7800, loss 37.591355, time: 3.399
training: epoch 21, step 7849, loss 37.587377, time: 0.833
validate: epoch 21, loss 38.465008, charcter error 7.001 time: 4.007
    - [Info] The checkpoint file has been updated.
training: epoch 22, step 200, loss 36.586122, time: 3.353
training: epoch 22, step 400, loss 36.918043, time: 3.392
training: epoch 22, step 600, loss 36.927167, time: 3.387
training: epoch 22, step 800, loss 36.913762, time: 3.402
training: epoch 22, step 1000, loss 37.053963, time: 3.399
training: epoch 22, step 1200, loss 37.114802, time: 3.391
training: epoch 22, step 1400, loss 37.101682, time: 3.388
training: epoch 22, step 1600, loss 37.225066, time: 3.390
training: epoch 22, step 1800, loss 37.222484, time: 3.402
training: epoch 22, step 2000, loss 37.237060, time: 3.387
training: epoch 22, step 2200, loss 37.199392, time: 3.388
training: epoch 22, step 2400, loss 37.256544, time: 3.384
training: epoch 22, step 2600, loss 37.320888, time: 3.395
training: epoch 22, step 2800, loss 37.356857, time: 3.393
training: epoch 22, step 3000, loss 37.337156, time: 3.393
training: epoch 22, step 3200, loss 37.361166, time: 3.389
training: epoch 22, step 3400, loss 37.309027, time: 3.398
training: epoch 22, step 3600, loss 37.273339, time: 3.388
training: epoch 22, step 3800, loss 37.234107, time: 3.397
training: epoch 22, step 4000, loss 37.258288, time: 3.389
training: epoch 22, step 4200, loss 37.240815, time: 3.388
training: epoch 22, step 4400, loss 37.216907, time: 3.390
training: epoch 22, step 4600, loss 37.238232, time: 3.390
training: epoch 22, step 4800, loss 37.262554, time: 3.401
training: epoch 22, step 5000, loss 37.276031, time: 3.392
training: epoch 22, step 5200, loss 37.273267, time: 3.390
training: epoch 22, step 5400, loss 37.313471, time: 3.392
training: epoch 22, step 5600, loss 37.377129, time: 3.386
training: epoch 22, step 5800, loss 37.397954, time: 3.398
training: epoch 22, step 6000, loss 37.396530, time: 3.383
training: epoch 22, step 6200, loss 37.397807, time: 3.387
training: epoch 22, step 6400, loss 37.416890, time: 3.390
training: epoch 22, step 6600, loss 37.411074, time: 3.394
training: epoch 22, step 6800, loss 37.432872, time: 3.391
training: epoch 22, step 7000, loss 37.481563, time: 3.391
training: epoch 22, step 7200, loss 37.480468, time: 3.395
training: epoch 22, step 7400, loss 37.456085, time: 3.392
training: epoch 22, step 7600, loss 37.464406, time: 3.389
training: epoch 22, step 7800, loss 37.453083, time: 3.393
training: epoch 22, step 7849, loss 37.443424, time: 0.831
validate: epoch 22, loss 38.665335, charcter error 7.016 time: 4.020
training: epoch 23, step 200, loss 42.782292, time: 3.344
training: epoch 23, step 400, loss 40.385237, time: 3.388
training: epoch 23, step 600, loss 39.406465, time: 3.393
training: epoch 23, step 800, loss 38.963051, time: 3.393
training: epoch 23, step 1000, loss 38.647127, time: 3.395
training: epoch 23, step 1200, loss 38.249808, time: 3.397
training: epoch 23, step 1400, loss 38.156341, time: 3.396
training: epoch 23, step 1600, loss 37.978012, time: 3.403
training: epoch 23, step 1800, loss 37.778543, time: 3.397
training: epoch 23, step 2000, loss 37.736481, time: 3.399
training: epoch 23, step 2200, loss 37.650722, time: 3.395
training: epoch 23, step 2400, loss 37.570406, time: 3.397
training: epoch 23, step 2600, loss 37.514650, time: 3.392
training: epoch 23, step 2800, loss 37.478814, time: 3.391
training: epoch 23, step 3000, loss 37.548222, time: 3.387
training: epoch 23, step 3200, loss 37.489689, time: 3.388
training: epoch 23, step 3400, loss 37.485444, time: 3.391
training: epoch 23, step 3600, loss 37.446101, time: 3.393
training: epoch 23, step 3800, loss 37.449916, time: 3.387
training: epoch 23, step 4000, loss 37.464700, time: 3.391
training: epoch 23, step 4200, loss 37.441996, time: 3.395
training: epoch 23, step 4400, loss 37.444592, time: 3.395
training: epoch 23, step 4600, loss 37.471001, time: 3.395
training: epoch 23, step 4800, loss 37.467352, time: 3.395
training: epoch 23, step 5000, loss 37.505092, time: 3.397
training: epoch 23, step 5200, loss 37.579510, time: 3.394
training: epoch 23, step 5400, loss 37.609029, time: 3.395
training: epoch 23, step 5600, loss 37.590106, time: 3.395
training: epoch 23, step 5800, loss 37.563709, time: 3.393
training: epoch 23, step 6000, loss 37.552663, time: 3.396
training: epoch 23, step 6200, loss 37.531213, time: 3.392
training: epoch 23, step 6400, loss 37.494946, time: 3.396
training: epoch 23, step 6600, loss 37.497712, time: 3.391
training: epoch 23, step 6800, loss 37.486987, time: 3.396
training: epoch 23, step 7000, loss 37.458840, time: 3.395
training: epoch 23, step 7200, loss 37.439513, time: 3.387
training: epoch 23, step 7400, loss 37.431569, time: 3.388
training: epoch 23, step 7600, loss 37.427084, time: 3.392
training: epoch 23, step 7800, loss 37.416857, time: 3.391
training: epoch 23, step 7849, loss 37.419011, time: 0.830
validate: epoch 23, loss 38.245695, charcter error 6.976 time: 4.014
    - [Info] The checkpoint file has been updated.
training: epoch 24, step 200, loss 36.681979, time: 3.351
training: epoch 24, step 400, loss 36.710536, time: 3.387
training: epoch 24, step 600, loss 36.786370, time: 3.390
training: epoch 24, step 800, loss 36.473348, time: 3.393
training: epoch 24, step 1000, loss 36.384922, time: 3.391
training: epoch 24, step 1200, loss 36.587832, time: 3.398
training: epoch 24, step 1400, loss 36.738154, time: 3.401
training: epoch 24, step 1600, loss 36.768392, time: 3.396
training: epoch 24, step 1800, loss 36.788771, time: 3.389
training: epoch 24, step 2000, loss 36.879221, time: 3.395
training: epoch 24, step 2200, loss 36.798463, time: 3.390
training: epoch 24, step 2400, loss 36.806667, time: 3.393
training: epoch 24, step 2600, loss 36.841785, time: 3.384
training: epoch 24, step 2800, loss 36.896936, time: 3.388
training: epoch 24, step 3000, loss 36.978523, time: 3.389
training: epoch 24, step 3200, loss 36.942783, time: 3.395
training: epoch 24, step 3400, loss 36.914659, time: 3.405
training: epoch 24, step 3600, loss 36.999435, time: 3.390
training: epoch 24, step 3800, loss 37.127332, time: 3.388
training: epoch 24, step 4000, loss 37.241449, time: 3.396
training: epoch 24, step 4200, loss 37.253686, time: 3.390
training: epoch 24, step 4400, loss 37.247521, time: 3.396
training: epoch 24, step 4600, loss 37.278854, time: 3.390
training: epoch 24, step 4800, loss 37.292352, time: 3.388
training: epoch 24, step 5000, loss 37.338118, time: 3.396
training: epoch 24, step 5200, loss 37.305727, time: 3.393
training: epoch 24, step 5400, loss 37.319273, time: 3.391
training: epoch 24, step 5600, loss 37.283227, time: 3.389
training: epoch 24, step 5800, loss 37.323840, time: 3.390
training: epoch 24, step 6000, loss 37.348089, time: 3.396
training: epoch 24, step 6200, loss 37.378093, time: 3.393
training: epoch 24, step 6400, loss 37.411487, time: 3.386
training: epoch 24, step 6600, loss 37.380672, time: 3.389
training: epoch 24, step 6800, loss 37.364338, time: 3.388
training: epoch 24, step 7000, loss 37.350100, time: 3.397
training: epoch 24, step 7200, loss 37.318305, time: 3.464
training: epoch 24, step 7400, loss 37.323447, time: 3.510
training: epoch 24, step 7600, loss 37.327031, time: 3.527
training: epoch 24, step 7800, loss 37.329911, time: 3.550
training: epoch 24, step 7849, loss 37.327726, time: 0.859
validate: epoch 24, loss 38.133292, charcter error 6.946 time: 4.038
    - [Info] The checkpoint file has been updated.
training: epoch 25, step 200, loss 37.482341, time: 3.538
training: epoch 25, step 400, loss 37.414165, time: 3.539
training: epoch 25, step 600, loss 36.922227, time: 3.522
training: epoch 25, step 800, loss 36.533648, time: 3.518
training: epoch 25, step 1000, loss 36.509347, time: 3.509
training: epoch 25, step 1200, loss 36.516821, time: 3.493
training: epoch 25, step 1400, loss 36.780359, time: 3.620
training: epoch 25, step 1600, loss 36.778371, time: 3.512
training: epoch 25, step 1800, loss 36.760341, time: 3.442
training: epoch 25, step 2000, loss 36.833187, time: 3.422
training: epoch 25, step 2200, loss 36.905302, time: 3.417
training: epoch 25, step 2400, loss 36.884725, time: 3.411
training: epoch 25, step 2600, loss 36.892755, time: 3.413
training: epoch 25, step 2800, loss 36.908614, time: 3.408
training: epoch 25, step 3000, loss 36.912792, time: 3.398
training: epoch 25, step 3200, loss 36.923852, time: 3.395
training: epoch 25, step 3400, loss 36.938318, time: 3.391
training: epoch 25, step 3600, loss 36.932301, time: 3.393
training: epoch 25, step 3800, loss 36.945180, time: 3.394
training: epoch 25, step 4000, loss 37.022425, time: 3.390
training: epoch 25, step 4200, loss 36.977767, time: 3.393
training: epoch 25, step 4400, loss 37.000746, time: 3.393
training: epoch 25, step 4600, loss 36.981518, time: 3.391
training: epoch 25, step 4800, loss 36.968687, time: 3.394
training: epoch 25, step 5000, loss 36.953649, time: 3.394
training: epoch 25, step 5200, loss 36.959306, time: 3.394
training: epoch 25, step 5400, loss 36.972330, time: 3.393
training: epoch 25, step 5600, loss 36.964672, time: 3.394
training: epoch 25, step 5800, loss 37.024042, time: 3.390
training: epoch 25, step 6000, loss 37.027388, time: 3.392
training: epoch 25, step 6200, loss 36.985949, time: 3.389
training: epoch 25, step 6400, loss 36.981282, time: 3.391
training: epoch 25, step 6600, loss 36.972842, time: 3.387
training: epoch 25, step 6800, loss 36.927848, time: 3.388
training: epoch 25, step 7000, loss 36.935505, time: 3.397
training: epoch 25, step 7200, loss 36.916182, time: 3.387
training: epoch 25, step 7400, loss 36.901450, time: 3.388
training: epoch 25, step 7600, loss 36.910546, time: 3.397
training: epoch 25, step 7800, loss 36.921935, time: 3.393
training: epoch 25, step 7849, loss 36.916173, time: 0.832
validate: epoch 25, loss 38.095579, charcter error 6.937 time: 4.031
    - [Info] The checkpoint file has been updated.
training: epoch 26, step 200, loss 37.003586, time: 3.347
training: epoch 26, step 400, loss 36.217769, time: 3.380
training: epoch 26, step 600, loss 36.753218, time: 3.385
training: epoch 26, step 800, loss 36.596762, time: 3.383
training: epoch 26, step 1000, loss 36.592316, time: 3.390
training: epoch 26, step 1200, loss 36.515485, time: 3.398
training: epoch 26, step 1400, loss 36.505009, time: 3.390
training: epoch 26, step 1600, loss 36.629045, time: 3.386
training: epoch 26, step 1800, loss 36.705395, time: 3.385
training: epoch 26, step 2000, loss 36.747529, time: 3.397
training: epoch 26, step 2200, loss 36.678814, time: 3.399
training: epoch 26, step 2400, loss 36.729686, time: 3.421
training: epoch 26, step 2600, loss 36.813012, time: 3.433
training: epoch 26, step 2800, loss 36.927154, time: 3.429
training: epoch 26, step 3000, loss 36.979709, time: 3.482
training: epoch 26, step 3200, loss 37.032243, time: 3.476
training: epoch 26, step 3400, loss 36.953095, time: 3.501
training: epoch 26, step 3600, loss 36.989018, time: 3.485
training: epoch 26, step 3800, loss 36.907032, time: 3.444
training: epoch 26, step 4000, loss 36.917943, time: 3.459
training: epoch 26, step 4200, loss 36.917358, time: 3.469
training: epoch 26, step 4400, loss 36.937311, time: 3.502
training: epoch 26, step 4600, loss 36.955977, time: 3.494
training: epoch 26, step 4800, loss 36.946051, time: 3.520
training: epoch 26, step 5000, loss 36.942777, time: 3.486
training: epoch 26, step 5200, loss 36.923705, time: 3.486
training: epoch 26, step 5400, loss 36.851397, time: 3.485
training: epoch 26, step 5600, loss 36.956337, time: 3.398
training: epoch 26, step 5800, loss 37.036375, time: 3.390
training: epoch 26, step 6000, loss 37.020449, time: 3.442
training: epoch 26, step 6200, loss 37.004546, time: 3.476
training: epoch 26, step 6400, loss 37.005474, time: 3.462
training: epoch 26, step 6600, loss 36.998561, time: 3.476
training: epoch 26, step 6800, loss 36.970573, time: 3.498
training: epoch 26, step 7000, loss 36.945661, time: 3.460
training: epoch 26, step 7200, loss 36.966591, time: 3.463
training: epoch 26, step 7400, loss 36.943110, time: 3.458
training: epoch 26, step 7600, loss 36.963624, time: 3.451
training: epoch 26, step 7800, loss 36.982459, time: 3.452
training: epoch 26, step 7849, loss 36.966382, time: 0.852
validate: epoch 26, loss 38.208836, charcter error 6.963 time: 4.028
training: epoch 27, step 200, loss 36.557124, time: 3.442
training: epoch 27, step 400, loss 36.803850, time: 3.485
training: epoch 27, step 600, loss 36.528540, time: 3.474
training: epoch 27, step 800, loss 36.559837, time: 3.454
training: epoch 27, step 1000, loss 36.723010, time: 3.452
training: epoch 27, step 1200, loss 36.597905, time: 3.450
training: epoch 27, step 1400, loss 36.577130, time: 3.456
training: epoch 27, step 1600, loss 36.510075, time: 3.447
training: epoch 27, step 1800, loss 36.509702, time: 3.442
training: epoch 27, step 2000, loss 36.496521, time: 3.450
training: epoch 27, step 2200, loss 36.535412, time: 3.468
training: epoch 27, step 2400, loss 36.628648, time: 3.454
training: epoch 27, step 2600, loss 36.704419, time: 3.480
training: epoch 27, step 2800, loss 36.690069, time: 3.479
training: epoch 27, step 3000, loss 36.652246, time: 3.469
training: epoch 27, step 3200, loss 36.590617, time: 3.447
training: epoch 27, step 3400, loss 36.579310, time: 3.445
training: epoch 27, step 3600, loss 36.598106, time: 3.504
training: epoch 27, step 3800, loss 36.725350, time: 3.436
training: epoch 27, step 4000, loss 36.689809, time: 3.433
training: epoch 27, step 4200, loss 36.621525, time: 3.424
training: epoch 27, step 4400, loss 36.623265, time: 3.412
training: epoch 27, step 4600, loss 36.627723, time: 3.408
training: epoch 27, step 4800, loss 36.620551, time: 3.402
training: epoch 27, step 5000, loss 36.628086, time: 3.407
training: epoch 27, step 5200, loss 36.598134, time: 3.399
training: epoch 27, step 5400, loss 36.570177, time: 3.401
training: epoch 27, step 5600, loss 36.557910, time: 3.406
training: epoch 27, step 5800, loss 36.546765, time: 3.399
training: epoch 27, step 6000, loss 36.578812, time: 3.395
training: epoch 27, step 6200, loss 36.615825, time: 3.401
training: epoch 27, step 6400, loss 36.605278, time: 3.398
training: epoch 27, step 6600, loss 36.636792, time: 3.397
training: epoch 27, step 6800, loss 36.649023, time: 3.399
training: epoch 27, step 7000, loss 36.651378, time: 3.399
training: epoch 27, step 7200, loss 36.603323, time: 3.398
training: epoch 27, step 7400, loss 36.582396, time: 3.397
training: epoch 27, step 7600, loss 36.552108, time: 3.398
training: epoch 27, step 7800, loss 36.538715, time: 3.399
training: epoch 27, step 7849, loss 36.548811, time: 0.832
validate: epoch 27, loss 37.800635, charcter error 6.872 time: 4.027
    - [Info] The checkpoint file has been updated.
training: epoch 28, step 200, loss 35.495891, time: 3.348
training: epoch 28, step 400, loss 36.439138, time: 3.387
training: epoch 28, step 600, loss 36.791539, time: 3.390
training: epoch 28, step 800, loss 37.299196, time: 3.396
training: epoch 28, step 1000, loss 37.158080, time: 3.395
training: epoch 28, step 1200, loss 37.058433, time: 3.391
training: epoch 28, step 1400, loss 37.117080, time: 3.395
training: epoch 28, step 1600, loss 36.980368, time: 3.405
training: epoch 28, step 1800, loss 37.003492, time: 3.405
training: epoch 28, step 2000, loss 36.936661, time: 3.402
training: epoch 28, step 2200, loss 36.860230, time: 3.399
training: epoch 28, step 2400, loss 36.853734, time: 3.399
training: epoch 28, step 2600, loss 36.765263, time: 3.397
training: epoch 28, step 2800, loss 36.722236, time: 3.389
training: epoch 28, step 3000, loss 36.676659, time: 3.391
training: epoch 28, step 3200, loss 36.607728, time: 3.393
training: epoch 28, step 3400, loss 36.631290, time: 3.402
training: epoch 28, step 3600, loss 36.715118, time: 3.400
training: epoch 28, step 3800, loss 36.698627, time: 3.389
training: epoch 28, step 4000, loss 36.736304, time: 3.401
training: epoch 28, step 4200, loss 36.732209, time: 3.423
training: epoch 28, step 4400, loss 36.732404, time: 3.396
training: epoch 28, step 4600, loss 36.665687, time: 3.391
training: epoch 28, step 4800, loss 36.618896, time: 3.394
training: epoch 28, step 5000, loss 36.603276, time: 3.403
training: epoch 28, step 5200, loss 36.610819, time: 3.394
training: epoch 28, step 5400, loss 36.597920, time: 3.394
training: epoch 28, step 5600, loss 36.562823, time: 3.401
training: epoch 28, step 5800, loss 36.574957, time: 3.396
training: epoch 28, step 6000, loss 36.546052, time: 3.393
training: epoch 28, step 6200, loss 36.558685, time: 3.393
training: epoch 28, step 6400, loss 36.572289, time: 3.395
training: epoch 28, step 6600, loss 36.616412, time: 3.398
training: epoch 28, step 6800, loss 36.657301, time: 3.393
training: epoch 28, step 7000, loss 36.646670, time: 3.398
training: epoch 28, step 7200, loss 36.650640, time: 3.397
training: epoch 28, step 7400, loss 36.679551, time: 3.400
training: epoch 28, step 7600, loss 36.642207, time: 3.400
training: epoch 28, step 7800, loss 36.632874, time: 3.408
training: epoch 28, step 7849, loss 36.638118, time: 0.834
validate: epoch 28, loss 37.660048, charcter error 6.878 time: 4.016
training: epoch 29, step 200, loss 36.761442, time: 3.355
training: epoch 29, step 400, loss 35.752655, time: 3.397
training: epoch 29, step 600, loss 36.429659, time: 3.408
training: epoch 29, step 800, loss 36.430014, time: 3.407
training: epoch 29, step 1000, loss 36.364721, time: 3.407
training: epoch 29, step 1200, loss 36.221605, time: 3.411
training: epoch 29, step 1400, loss 36.312364, time: 3.406
training: epoch 29, step 1600, loss 36.328702, time: 3.403
training: epoch 29, step 1800, loss 36.397513, time: 3.400
training: epoch 29, step 2000, loss 36.291085, time: 3.396
training: epoch 29, step 2200, loss 36.304515, time: 3.405
training: epoch 29, step 2400, loss 36.312170, time: 3.398
training: epoch 29, step 2600, loss 36.273406, time: 3.393
training: epoch 29, step 2800, loss 36.238488, time: 3.397
training: epoch 29, step 3000, loss 36.366893, time: 3.405
training: epoch 29, step 3200, loss 36.475510, time: 3.407
training: epoch 29, step 3400, loss 36.568547, time: 3.405
training: epoch 29, step 3600, loss 36.623096, time: 3.404
training: epoch 29, step 3800, loss 36.575253, time: 3.410
training: epoch 29, step 4000, loss 36.611250, time: 3.407
training: epoch 29, step 4200, loss 36.679005, time: 3.412
training: epoch 29, step 4400, loss 36.668692, time: 3.402
training: epoch 29, step 4600, loss 36.644822, time: 3.402
training: epoch 29, step 4800, loss 36.619563, time: 3.411
training: epoch 29, step 5000, loss 36.583648, time: 3.403
training: epoch 29, step 5200, loss 36.547284, time: 3.400
training: epoch 29, step 5400, loss 36.546447, time: 3.399
training: epoch 29, step 5600, loss 36.542058, time: 3.402
training: epoch 29, step 5800, loss 36.533300, time: 3.410
training: epoch 29, step 6000, loss 36.496436, time: 3.405
training: epoch 29, step 6200, loss 36.506120, time: 3.411
training: epoch 29, step 6400, loss 36.534297, time: 3.401
training: epoch 29, step 6600, loss 36.519880, time: 3.401
training: epoch 29, step 6800, loss 36.508774, time: 3.410
training: epoch 29, step 7000, loss 36.520423, time: 3.402
training: epoch 29, step 7200, loss 36.495452, time: 3.409
training: epoch 29, step 7400, loss 36.461507, time: 3.408
training: epoch 29, step 7600, loss 36.594987, time: 3.406
training: epoch 29, step 7800, loss 36.662381, time: 3.405
training: epoch 29, step 7849, loss 36.678651, time: 0.834
validate: epoch 29, loss 38.987243, charcter error 7.062 time: 4.019
training: epoch 30, step 200, loss 36.110148, time: 3.353
training: epoch 30, step 400, loss 36.393831, time: 3.396
training: epoch 30, step 600, loss 36.753930, time: 3.410
training: epoch 30, step 800, loss 36.677161, time: 3.410
training: epoch 30, step 1000, loss 36.568955, time: 3.411
training: epoch 30, step 1200, loss 36.575459, time: 3.415
training: epoch 30, step 1400, loss 36.405466, time: 3.413
training: epoch 30, step 1600, loss 36.385956, time: 3.409
training: epoch 30, step 1800, loss 36.451407, time: 3.402
training: epoch 30, step 2000, loss 36.636048, time: 3.407
training: epoch 30, step 2200, loss 36.721222, time: 3.414
training: epoch 30, step 2400, loss 36.699374, time: 3.411
training: epoch 30, step 2600, loss 36.638458, time: 3.407
training: epoch 30, step 2800, loss 36.524911, time: 3.405
training: epoch 30, step 3000, loss 36.465641, time: 3.406
training: epoch 30, step 3200, loss 36.469937, time: 3.413
training: epoch 30, step 3400, loss 36.372471, time: 3.403
training: epoch 30, step 3600, loss 36.365746, time: 3.406
training: epoch 30, step 3800, loss 36.382607, time: 3.411
training: epoch 30, step 4000, loss 36.358283, time: 3.413
training: epoch 30, step 4200, loss 36.371297, time: 3.413
training: epoch 30, step 4400, loss 36.394504, time: 3.414
training: epoch 30, step 4600, loss 36.390818, time: 3.411
training: epoch 30, step 4800, loss 36.373511, time: 3.405
training: epoch 30, step 5000, loss 36.385606, time: 3.408
training: epoch 30, step 5200, loss 36.359610, time: 3.407
training: epoch 30, step 5400, loss 36.312322, time: 3.407
training: epoch 30, step 5600, loss 36.309773, time: 3.408
training: epoch 30, step 5800, loss 36.328286, time: 3.409
training: epoch 30, step 6000, loss 36.319314, time: 3.395
training: epoch 30, step 6200, loss 36.330418, time: 3.393
training: epoch 30, step 6400, loss 36.316203, time: 3.397
training: epoch 30, step 6600, loss 36.316045, time: 3.405
training: epoch 30, step 6800, loss 36.348681, time: 3.400
training: epoch 30, step 7000, loss 36.339961, time: 3.403
training: epoch 30, step 7200, loss 36.329583, time: 3.413
training: epoch 30, step 7400, loss 36.328734, time: 3.413
training: epoch 30, step 7600, loss 36.309031, time: 3.413
training: epoch 30, step 7800, loss 36.286883, time: 3.411
training: epoch 30, step 7849, loss 36.278322, time: 0.835
validate: epoch 30, loss 37.479223, charcter error 6.803 time: 4.016
    - [Info] The checkpoint file has been updated.
training: epoch 31, step 200, loss 36.841931, time: 3.363
training: epoch 31, step 400, loss 36.308876, time: 3.397
training: epoch 31, step 600, loss 36.136409, time: 3.408
training: epoch 31, step 800, loss 36.078358, time: 3.405
training: epoch 31, step 1000, loss 36.125332, time: 3.398
training: epoch 31, step 1200, loss 36.169555, time: 3.406
training: epoch 31, step 1400, loss 36.042939, time: 3.410
training: epoch 31, step 1600, loss 35.986653, time: 3.406
training: epoch 31, step 1800, loss 35.899589, time: 3.407
training: epoch 31, step 2000, loss 35.996870, time: 3.402
training: epoch 31, step 2200, loss 35.846542, time: 3.400
training: epoch 31, step 2400, loss 35.846998, time: 3.407
training: epoch 31, step 2600, loss 35.835713, time: 3.399
training: epoch 31, step 2800, loss 35.913029, time: 3.406
training: epoch 31, step 3000, loss 35.872993, time: 3.405
training: epoch 31, step 3200, loss 35.841775, time: 3.401
training: epoch 31, step 3400, loss 35.902892, time: 3.409
training: epoch 31, step 3600, loss 35.875250, time: 3.399
training: epoch 31, step 3800, loss 35.894702, time: 3.396
training: epoch 31, step 4000, loss 35.953257, time: 3.399
training: epoch 31, step 4200, loss 36.050562, time: 3.395
training: epoch 31, step 4400, loss 36.114290, time: 3.400
training: epoch 31, step 4600, loss 36.143568, time: 3.392
training: epoch 31, step 4800, loss 36.120492, time: 3.395
training: epoch 31, step 5000, loss 36.113639, time: 3.392
training: epoch 31, step 5200, loss 36.114200, time: 3.391
training: epoch 31, step 5400, loss 36.123295, time: 3.397
training: epoch 31, step 5600, loss 36.121001, time: 3.387
training: epoch 31, step 5800, loss 36.105185, time: 3.389
training: epoch 31, step 6000, loss 36.117211, time: 3.393
training: epoch 31, step 6200, loss 36.109641, time: 3.399
training: epoch 31, step 6400, loss 36.113651, time: 3.390
training: epoch 31, step 6600, loss 36.123713, time: 3.388
training: epoch 31, step 6800, loss 36.106077, time: 3.395
training: epoch 31, step 7000, loss 36.108010, time: 3.394
training: epoch 31, step 7200, loss 36.128553, time: 3.389
training: epoch 31, step 7400, loss 36.120155, time: 3.395
training: epoch 31, step 7600, loss 36.147663, time: 3.390
training: epoch 31, step 7800, loss 36.127977, time: 3.396
training: epoch 31, step 7849, loss 36.137243, time: 0.831
validate: epoch 31, loss 37.510737, charcter error 6.837 time: 4.007
training: epoch 32, step 200, loss 36.082400, time: 3.338
training: epoch 32, step 400, loss 35.886547, time: 3.377
training: epoch 32, step 600, loss 35.804817, time: 3.380
training: epoch 32, step 800, loss 35.794548, time: 3.385
training: epoch 32, step 1000, loss 35.756128, time: 3.390
training: epoch 32, step 1200, loss 35.644303, time: 3.391
training: epoch 32, step 1400, loss 35.557620, time: 3.387
training: epoch 32, step 1600, loss 35.547953, time: 3.387
training: epoch 32, step 1800, loss 35.694543, time: 3.385
training: epoch 32, step 2000, loss 35.794338, time: 3.392
training: epoch 32, step 2200, loss 35.819642, time: 3.396
training: epoch 32, step 2400, loss 35.799008, time: 3.405
training: epoch 32, step 2600, loss 35.887408, time: 3.393
training: epoch 32, step 2800, loss 35.907420, time: 3.392
training: epoch 32, step 3000, loss 35.903797, time: 3.397
training: epoch 32, step 3200, loss 35.913750, time: 3.393
training: epoch 32, step 3400, loss 35.954475, time: 3.390
training: epoch 32, step 3600, loss 35.947701, time: 3.393
training: epoch 32, step 3800, loss 35.902866, time: 3.391
training: epoch 32, step 4000, loss 35.922858, time: 3.394
training: epoch 32, step 4200, loss 36.097589, time: 3.391
training: epoch 32, step 4400, loss 36.112793, time: 3.395
training: epoch 32, step 4600, loss 36.091809, time: 3.389
training: epoch 32, step 4800, loss 36.052725, time: 3.388
training: epoch 32, step 5000, loss 36.039075, time: 3.394
training: epoch 32, step 5200, loss 36.062809, time: 3.391
training: epoch 32, step 5400, loss 36.055172, time: 3.385
training: epoch 32, step 5600, loss 36.035646, time: 3.387
training: epoch 32, step 5800, loss 36.020049, time: 3.387
training: epoch 32, step 6000, loss 36.051354, time: 3.386
training: epoch 32, step 6200, loss 36.043035, time: 3.387
training: epoch 32, step 6400, loss 36.043964, time: 3.392
training: epoch 32, step 6600, loss 36.051243, time: 3.391
training: epoch 32, step 6800, loss 36.045772, time: 3.388
training: epoch 32, step 7000, loss 36.065306, time: 3.389
training: epoch 32, step 7200, loss 36.054755, time: 3.390
training: epoch 32, step 7400, loss 36.058866, time: 3.393
training: epoch 32, step 7600, loss 36.031562, time: 3.396
training: epoch 32, step 7800, loss 36.031107, time: 3.390
training: epoch 32, step 7849, loss 36.021493, time: 0.831
validate: epoch 32, loss 37.448839, charcter error 6.788 time: 4.026
    - [Info] The checkpoint file has been updated.
training: epoch 33, step 200, loss 36.333287, time: 3.351
training: epoch 33, step 400, loss 36.627834, time: 3.379
training: epoch 33, step 600, loss 36.259035, time: 3.396
training: epoch 33, step 800, loss 36.172870, time: 3.385
training: epoch 33, step 1000, loss 36.092309, time: 3.391
training: epoch 33, step 1200, loss 36.118889, time: 3.407
training: epoch 33, step 1400, loss 35.877654, time: 3.401
training: epoch 33, step 1600, loss 35.987822, time: 3.393
training: epoch 33, step 1800, loss 36.010308, time: 3.391
training: epoch 33, step 2000, loss 36.019118, time: 3.389
training: epoch 33, step 2200, loss 35.916266, time: 3.387
training: epoch 33, step 2400, loss 35.868678, time: 3.392
training: epoch 33, step 2600, loss 35.792917, time: 3.389
training: epoch 33, step 2800, loss 35.812877, time: 3.397
training: epoch 33, step 3000, loss 35.819691, time: 3.391
training: epoch 33, step 3200, loss 35.973049, time: 3.394
training: epoch 33, step 3400, loss 36.041548, time: 3.394
training: epoch 33, step 3600, loss 36.074482, time: 3.390
training: epoch 33, step 3800, loss 36.115899, time: 3.397
training: epoch 33, step 4000, loss 36.086685, time: 3.390
training: epoch 33, step 4200, loss 36.049358, time: 3.388
training: epoch 33, step 4400, loss 36.081276, time: 3.386
training: epoch 33, step 4600, loss 36.079601, time: 3.392
training: epoch 33, step 4800, loss 36.122322, time: 3.389
training: epoch 33, step 5000, loss 36.090221, time: 3.385
training: epoch 33, step 5200, loss 36.064524, time: 3.391
training: epoch 33, step 5400, loss 35.975906, time: 3.396
training: epoch 33, step 5600, loss 35.974089, time: 3.401
training: epoch 33, step 5800, loss 35.948567, time: 3.400
training: epoch 33, step 6000, loss 35.924844, time: 3.418
training: epoch 33, step 6200, loss 35.952874, time: 3.401
training: epoch 33, step 6400, loss 35.983639, time: 3.396
training: epoch 33, step 6600, loss 35.968775, time: 3.401
training: epoch 33, step 6800, loss 35.942357, time: 3.422
training: epoch 33, step 7000, loss 35.964412, time: 3.429
training: epoch 33, step 7200, loss 35.938068, time: 3.413
training: epoch 33, step 7400, loss 35.957392, time: 3.392
training: epoch 33, step 7600, loss 35.972057, time: 3.393
training: epoch 33, step 7800, loss 35.973253, time: 3.412
training: epoch 33, step 7849, loss 35.969261, time: 0.833
validate: epoch 33, loss 37.155900, charcter error 6.754 time: 4.018
    - [Info] The checkpoint file has been updated.
training: epoch 34, step 200, loss 35.809159, time: 3.354
training: epoch 34, step 400, loss 36.184464, time: 3.385
training: epoch 34, step 600, loss 35.917516, time: 3.380
training: epoch 34, step 800, loss 35.895337, time: 3.389
training: epoch 34, step 1000, loss 35.878556, time: 3.384
training: epoch 34, step 1200, loss 35.737425, time: 3.394
training: epoch 34, step 1400, loss 35.638841, time: 3.391
training: epoch 34, step 1600, loss 35.716000, time: 3.390
training: epoch 34, step 1800, loss 35.776094, time: 3.392
training: epoch 34, step 2000, loss 35.961943, time: 3.387
training: epoch 34, step 2200, loss 35.958195, time: 3.385
training: epoch 34, step 2400, loss 35.940902, time: 3.385
training: epoch 34, step 2600, loss 35.920671, time: 3.382
training: epoch 34, step 2800, loss 36.013345, time: 3.380
training: epoch 34, step 3000, loss 35.894680, time: 3.381
training: epoch 34, step 3200, loss 35.912352, time: 3.389
training: epoch 34, step 3400, loss 35.950765, time: 3.385
training: epoch 34, step 3600, loss 36.008783, time: 3.392
training: epoch 34, step 3800, loss 36.013945, time: 3.384
training: epoch 34, step 4000, loss 36.014562, time: 3.381
training: epoch 34, step 4200, loss 36.018277, time: 3.382
training: epoch 34, step 4400, loss 35.988217, time: 3.389
training: epoch 34, step 4600, loss 35.977794, time: 3.384
training: epoch 34, step 4800, loss 35.976499, time: 3.383
training: epoch 34, step 5000, loss 35.945195, time: 3.388
training: epoch 34, step 5200, loss 35.933332, time: 3.383
training: epoch 34, step 5400, loss 35.922399, time: 3.383
training: epoch 34, step 5600, loss 35.920926, time: 3.384
training: epoch 34, step 5800, loss 35.973516, time: 3.387
training: epoch 34, step 6000, loss 35.978696, time: 3.381
training: epoch 34, step 6200, loss 35.919241, time: 3.381
training: epoch 34, step 6400, loss 35.914876, time: 3.380
training: epoch 34, step 6600, loss 35.876310, time: 3.383
training: epoch 34, step 6800, loss 35.874984, time: 3.380
training: epoch 34, step 7000, loss 35.849268, time: 3.384
training: epoch 34, step 7200, loss 35.838631, time: 3.383
training: epoch 34, step 7400, loss 35.849246, time: 3.396
training: epoch 34, step 7600, loss 35.846888, time: 3.381
training: epoch 34, step 7800, loss 35.836698, time: 3.389
training: epoch 34, step 7849, loss 35.837270, time: 0.828
validate: epoch 34, loss 37.780296, charcter error 6.797 time: 4.025
training: epoch 35, step 200, loss 34.492547, time: 3.342
training: epoch 35, step 400, loss 35.310928, time: 3.380
training: epoch 35, step 600, loss 35.429075, time: 3.400
training: epoch 35, step 800, loss 35.763465, time: 3.398
training: epoch 35, step 1000, loss 35.525028, time: 3.395
training: epoch 35, step 1200, loss 35.578245, time: 3.391
training: epoch 35, step 1400, loss 35.390317, time: 3.390
training: epoch 35, step 1600, loss 35.753957, time: 3.392
training: epoch 35, step 1800, loss 35.927957, time: 3.399
training: epoch 35, step 2000, loss 35.951128, time: 3.397
training: epoch 35, step 2200, loss 35.915191, time: 3.394
training: epoch 35, step 2400, loss 35.942002, time: 3.394
training: epoch 35, step 2600, loss 35.870658, time: 3.394
training: epoch 35, step 2800, loss 35.819688, time: 3.459
training: epoch 35, step 3000, loss 35.821708, time: 3.485
training: epoch 35, step 3200, loss 35.828077, time: 3.540
training: epoch 35, step 3400, loss 35.757211, time: 3.536
training: epoch 35, step 3600, loss 35.771197, time: 3.516
training: epoch 35, step 3800, loss 35.772689, time: 3.413
training: epoch 35, step 4000, loss 35.824235, time: 3.411
training: epoch 35, step 4200, loss 35.825710, time: 3.403
training: epoch 35, step 4400, loss 35.816700, time: 3.492
training: epoch 35, step 4600, loss 35.828422, time: 3.510
training: epoch 35, step 4800, loss 35.815438, time: 3.497
training: epoch 35, step 5000, loss 35.789637, time: 3.532
training: epoch 35, step 5200, loss 35.758038, time: 3.427
training: epoch 35, step 5400, loss 35.756343, time: 3.394
training: epoch 35, step 5600, loss 35.812283, time: 3.395
training: epoch 35, step 5800, loss 35.837266, time: 3.392
training: epoch 35, step 6000, loss 35.844530, time: 3.394
training: epoch 35, step 6200, loss 35.833761, time: 3.388
training: epoch 35, step 6400, loss 35.806394, time: 3.390
training: epoch 35, step 6600, loss 35.798275, time: 3.395
training: epoch 35, step 6800, loss 35.807358, time: 3.394
training: epoch 35, step 7000, loss 35.839215, time: 3.390
training: epoch 35, step 7200, loss 35.852219, time: 3.398
training: epoch 35, step 7400, loss 35.829145, time: 3.395
training: epoch 35, step 7600, loss 35.830459, time: 3.388
training: epoch 35, step 7800, loss 35.812349, time: 3.390
training: epoch 35, step 7849, loss 35.822837, time: 0.832
validate: epoch 35, loss 37.338426, charcter error 6.794 time: 4.019
training: epoch 36, step 200, loss 35.062528, time: 3.340
training: epoch 36, step 400, loss 35.163659, time: 3.377
training: epoch 36, step 600, loss 34.951030, time: 3.390
training: epoch 36, step 800, loss 35.265156, time: 3.390
training: epoch 36, step 1000, loss 35.373804, time: 3.384
training: epoch 36, step 1200, loss 35.573072, time: 3.393
training: epoch 36, step 1400, loss 35.486779, time: 3.383
training: epoch 36, step 1600, loss 35.466717, time: 3.389
training: epoch 36, step 1800, loss 35.576601, time: 3.386
training: epoch 36, step 2000, loss 35.652529, time: 3.380
training: epoch 36, step 2200, loss 35.720752, time: 3.387
training: epoch 36, step 2400, loss 35.692472, time: 3.385
training: epoch 36, step 2600, loss 35.717942, time: 3.388
training: epoch 36, step 2800, loss 35.700894, time: 3.386
training: epoch 36, step 3000, loss 35.836319, time: 3.390
training: epoch 36, step 3200, loss 35.925146, time: 3.384
training: epoch 36, step 3400, loss 35.963380, time: 3.384
training: epoch 36, step 3600, loss 35.896474, time: 3.381
training: epoch 36, step 3800, loss 35.901846, time: 3.386
training: epoch 36, step 4000, loss 35.911338, time: 3.394
training: epoch 36, step 4200, loss 35.893569, time: 3.389
training: epoch 36, step 4400, loss 35.935612, time: 3.385
training: epoch 36, step 4600, loss 35.914118, time: 3.385
training: epoch 36, step 4800, loss 35.879645, time: 3.388
training: epoch 36, step 5000, loss 35.903316, time: 3.385
training: epoch 36, step 5200, loss 35.889981, time: 3.381
training: epoch 36, step 5400, loss 35.875492, time: 3.389
training: epoch 36, step 5600, loss 35.878480, time: 3.403
training: epoch 36, step 5800, loss 35.882810, time: 3.404
training: epoch 36, step 6000, loss 35.866966, time: 3.410
training: epoch 36, step 6200, loss 35.852966, time: 3.468
training: epoch 36, step 6400, loss 35.837140, time: 3.446
training: epoch 36, step 6600, loss 35.811833, time: 3.482
training: epoch 36, step 6800, loss 35.812725, time: 3.478
training: epoch 36, step 7000, loss 35.820180, time: 3.487
training: epoch 36, step 7200, loss 35.817441, time: 3.489
training: epoch 36, step 7400, loss 35.841608, time: 3.461
training: epoch 36, step 7600, loss 35.837042, time: 3.453
training: epoch 36, step 7800, loss 35.817526, time: 3.477
training: epoch 36, step 7849, loss 35.823967, time: 0.856
validate: epoch 36, loss 37.002976, charcter error 6.715 time: 4.035
    - [Info] The checkpoint file has been updated.
training: epoch 37, step 200, loss 35.689989, time: 3.511
training: epoch 37, step 400, loss 35.449307, time: 3.528
training: epoch 37, step 600, loss 35.108863, time: 3.489
training: epoch 37, step 800, loss 35.317511, time: 3.500
training: epoch 37, step 1000, loss 35.395137, time: 3.492
training: epoch 37, step 1200, loss 35.699606, time: 3.415
training: epoch 37, step 1400, loss 35.583741, time: 3.412
training: epoch 37, step 1600, loss 35.467736, time: 3.422
training: epoch 37, step 1800, loss 35.458845, time: 3.438
training: epoch 37, step 2000, loss 35.409528, time: 3.470
training: epoch 37, step 2200, loss 35.343751, time: 3.466
training: epoch 37, step 2400, loss 35.369987, time: 3.517
training: epoch 37, step 2600, loss 35.379347, time: 3.467
training: epoch 37, step 2800, loss 35.467261, time: 3.465
training: epoch 37, step 3000, loss 35.539086, time: 3.456
training: epoch 37, step 3200, loss 35.560724, time: 3.468
training: epoch 37, step 3400, loss 35.544222, time: 3.454
training: epoch 37, step 3600, loss 35.530061, time: 3.473
training: epoch 37, step 3800, loss 35.517784, time: 3.468
training: epoch 37, step 4000, loss 35.496366, time: 3.458
training: epoch 37, step 4200, loss 35.495349, time: 3.480
training: epoch 37, step 4400, loss 35.502111, time: 3.454
training: epoch 37, step 4600, loss 35.479554, time: 3.430
training: epoch 37, step 4800, loss 35.481087, time: 3.446
training: epoch 37, step 5000, loss 35.486890, time: 3.457
training: epoch 37, step 5200, loss 35.480955, time: 3.451
training: epoch 37, step 5400, loss 35.489300, time: 3.479
training: epoch 37, step 5600, loss 35.494099, time: 3.454
training: epoch 37, step 5800, loss 35.467559, time: 3.464
training: epoch 37, step 6000, loss 35.461635, time: 3.466
training: epoch 37, step 6200, loss 35.457607, time: 3.456
training: epoch 37, step 6400, loss 35.443442, time: 3.486
training: epoch 37, step 6600, loss 35.432307, time: 3.498
training: epoch 37, step 6800, loss 35.428832, time: 3.447
training: epoch 37, step 7000, loss 35.435886, time: 3.474
training: epoch 37, step 7200, loss 35.437392, time: 3.479
training: epoch 37, step 7400, loss 35.435832, time: 3.474
training: epoch 37, step 7600, loss 35.432650, time: 3.436
training: epoch 37, step 7800, loss 35.475616, time: 3.432
training: epoch 37, step 7849, loss 35.478090, time: 0.840
validate: epoch 37, loss 37.056811, charcter error 6.719 time: 4.036
training: epoch 38, step 200, loss 37.646566, time: 3.365
training: epoch 38, step 400, loss 35.917113, time: 3.397
training: epoch 38, step 600, loss 35.727888, time: 3.409
training: epoch 38, step 800, loss 35.893992, time: 3.407
training: epoch 38, step 1000, loss 35.855005, time: 3.398
training: epoch 38, step 1200, loss 35.606031, time: 3.401
training: epoch 38, step 1400, loss 35.602600, time: 3.399
training: epoch 38, step 1600, loss 35.602969, time: 3.396
training: epoch 38, step 1800, loss 35.555324, time: 3.400
training: epoch 38, step 2000, loss 35.597125, time: 3.403
training: epoch 38, step 2200, loss 35.624017, time: 3.406
training: epoch 38, step 2400, loss 35.585196, time: 3.403
training: epoch 38, step 2600, loss 35.514832, time: 3.397
training: epoch 38, step 2800, loss 35.458772, time: 3.403
training: epoch 38, step 3000, loss 35.515773, time: 3.405
training: epoch 38, step 3200, loss 35.551456, time: 3.402
training: epoch 38, step 3400, loss 35.552192, time: 3.397
training: epoch 38, step 3600, loss 35.527087, time: 3.400
training: epoch 38, step 3800, loss 35.462948, time: 3.404
training: epoch 38, step 4000, loss 35.413151, time: 3.401
training: epoch 38, step 4200, loss 35.388081, time: 3.395
training: epoch 38, step 4400, loss 35.409567, time: 3.399
training: epoch 38, step 4600, loss 35.401382, time: 3.390
training: epoch 38, step 4800, loss 35.498362, time: 3.392
training: epoch 38, step 5000, loss 35.526743, time: 3.389
training: epoch 38, step 5200, loss 35.544008, time: 3.404
training: epoch 38, step 5400, loss 35.574526, time: 3.403
training: epoch 38, step 5600, loss 35.609478, time: 3.401
training: epoch 38, step 5800, loss 35.606576, time: 3.406
training: epoch 38, step 6000, loss 35.633862, time: 3.405
training: epoch 38, step 6200, loss 35.652013, time: 3.402
training: epoch 38, step 6400, loss 35.618178, time: 3.403
training: epoch 38, step 6600, loss 35.606115, time: 3.405
training: epoch 38, step 6800, loss 35.578677, time: 3.399
training: epoch 38, step 7000, loss 35.586649, time: 3.396
training: epoch 38, step 7200, loss 35.585258, time: 3.394
training: epoch 38, step 7400, loss 35.579896, time: 3.396
training: epoch 38, step 7600, loss 35.557638, time: 3.395
training: epoch 38, step 7800, loss 35.566981, time: 3.398
training: epoch 38, step 7849, loss 35.579617, time: 0.834
validate: epoch 38, loss 36.985275, charcter error 6.732 time: 4.029
training: epoch 39, step 200, loss 34.094089, time: 3.348
training: epoch 39, step 400, loss 34.897265, time: 3.395
training: epoch 39, step 600, loss 35.125242, time: 3.403
training: epoch 39, step 800, loss 34.858568, time: 3.395
training: epoch 39, step 1000, loss 35.180050, time: 3.403
training: epoch 39, step 1200, loss 35.263975, time: 3.406
training: epoch 39, step 1400, loss 35.361362, time: 3.410
training: epoch 39, step 1600, loss 35.326737, time: 3.413
training: epoch 39, step 1800, loss 35.214826, time: 3.408
training: epoch 39, step 2000, loss 35.145447, time: 3.401
training: epoch 39, step 2200, loss 35.110633, time: 3.410
training: epoch 39, step 2400, loss 35.085545, time: 3.413
training: epoch 39, step 2600, loss 35.188872, time: 3.410
training: epoch 39, step 2800, loss 35.226699, time: 3.412
training: epoch 39, step 3000, loss 35.263252, time: 3.410
training: epoch 39, step 3200, loss 35.368218, time: 3.409
training: epoch 39, step 3400, loss 35.430806, time: 3.412
training: epoch 39, step 3600, loss 35.422842, time: 3.413
training: epoch 39, step 3800, loss 35.454130, time: 3.414
training: epoch 39, step 4000, loss 35.432314, time: 3.413
training: epoch 39, step 4200, loss 35.393198, time: 3.413
training: epoch 39, step 4400, loss 35.480965, time: 3.413
training: epoch 39, step 4600, loss 35.515010, time: 3.413
training: epoch 39, step 4800, loss 35.553247, time: 3.413
training: epoch 39, step 5000, loss 35.539600, time: 3.413
training: epoch 39, step 5200, loss 35.554299, time: 3.412
training: epoch 39, step 5400, loss 35.548667, time: 3.401
training: epoch 39, step 5600, loss 35.569794, time: 3.407
training: epoch 39, step 5800, loss 35.567947, time: 3.409
training: epoch 39, step 6000, loss 35.552309, time: 3.413
training: epoch 39, step 6200, loss 35.533792, time: 3.405
training: epoch 39, step 6400, loss 35.539209, time: 3.412
training: epoch 39, step 6600, loss 35.513424, time: 3.408
training: epoch 39, step 6800, loss 35.516498, time: 3.409
training: epoch 39, step 7000, loss 35.520025, time: 3.408
training: epoch 39, step 7200, loss 35.488220, time: 3.410
training: epoch 39, step 7400, loss 35.453549, time: 3.410
training: epoch 39, step 7600, loss 35.455878, time: 3.412
training: epoch 39, step 7800, loss 35.452272, time: 3.399
training: epoch 39, step 7849, loss 35.441699, time: 0.835
validate: epoch 39, loss 36.916383, charcter error 6.683 time: 4.024
    - [Info] The checkpoint file has been updated.
training: epoch 40, step 200, loss 34.167370, time: 3.361
training: epoch 40, step 400, loss 34.407008, time: 3.404
training: epoch 40, step 600, loss 34.502272, time: 3.405
training: epoch 40, step 800, loss 34.670184, time: 3.401
training: epoch 40, step 1000, loss 34.708663, time: 3.396
training: epoch 40, step 1200, loss 34.763542, time: 3.406
training: epoch 40, step 1400, loss 34.769769, time: 3.413
training: epoch 40, step 1600, loss 34.934747, time: 3.413
training: epoch 40, step 1800, loss 34.931827, time: 3.409
training: epoch 40, step 2000, loss 35.025803, time: 3.398
training: epoch 40, step 2200, loss 35.142795, time: 3.408
training: epoch 40, step 2400, loss 35.039424, time: 3.403
training: epoch 40, step 2600, loss 35.054066, time: 3.400
training: epoch 40, step 2800, loss 35.075634, time: 3.405
training: epoch 40, step 3000, loss 35.111172, time: 3.405
training: epoch 40, step 3200, loss 35.138113, time: 3.409
training: epoch 40, step 3400, loss 35.169921, time: 3.412
training: epoch 40, step 3600, loss 35.195866, time: 3.407
training: epoch 40, step 3800, loss 35.240372, time: 3.413
training: epoch 40, step 4000, loss 35.254511, time: 3.410
training: epoch 40, step 4200, loss 35.218607, time: 3.410
training: epoch 40, step 4400, loss 35.170334, time: 3.404
training: epoch 40, step 4600, loss 35.161755, time: 3.409
training: epoch 40, step 4800, loss 35.185359, time: 3.410
training: epoch 40, step 5000, loss 35.216313, time: 3.408
training: epoch 40, step 5200, loss 35.204856, time: 3.415
training: epoch 40, step 5400, loss 35.182085, time: 3.413
training: epoch 40, step 5600, loss 35.194898, time: 3.413
training: epoch 40, step 5800, loss 35.157861, time: 3.411
training: epoch 40, step 6000, loss 35.138574, time: 3.406
training: epoch 40, step 6200, loss 35.156835, time: 3.405
training: epoch 40, step 6400, loss 35.147669, time: 3.413
training: epoch 40, step 6600, loss 35.175586, time: 3.410
training: epoch 40, step 6800, loss 35.152196, time: 3.413
training: epoch 40, step 7000, loss 35.174499, time: 3.413
training: epoch 40, step 7200, loss 35.172651, time: 3.413
training: epoch 40, step 7400, loss 35.194201, time: 3.413
training: epoch 40, step 7600, loss 35.200044, time: 3.406
training: epoch 40, step 7800, loss 35.207928, time: 3.400
training: epoch 40, step 7849, loss 35.208250, time: 0.832
validate: epoch 40, loss 36.991595, charcter error 6.714 time: 4.023
training: epoch 41, step 200, loss 34.687250, time: 3.354
training: epoch 41, step 400, loss 34.948101, time: 3.401
training: epoch 41, step 600, loss 34.731554, time: 3.414
training: epoch 41, step 800, loss 35.141549, time: 3.413
training: epoch 41, step 1000, loss 35.370514, time: 3.411
training: epoch 41, step 1200, loss 35.320659, time: 3.408
training: epoch 41, step 1400, loss 35.234917, time: 3.407
training: epoch 41, step 1600, loss 35.270744, time: 3.408
training: epoch 41, step 1800, loss 35.176729, time: 3.413
training: epoch 41, step 2000, loss 35.083760, time: 3.403
training: epoch 41, step 2200, loss 35.085364, time: 3.412
training: epoch 41, step 2400, loss 35.088501, time: 3.413
training: epoch 41, step 2600, loss 35.103942, time: 3.413
training: epoch 41, step 2800, loss 35.012963, time: 3.413
training: epoch 41, step 3000, loss 35.023881, time: 3.413
training: epoch 41, step 3200, loss 35.048768, time: 3.414
training: epoch 41, step 3400, loss 35.003658, time: 3.413
training: epoch 41, step 3600, loss 35.025106, time: 3.413
training: epoch 41, step 3800, loss 35.097477, time: 3.413
training: epoch 41, step 4000, loss 35.076408, time: 3.408
training: epoch 41, step 4200, loss 35.088549, time: 3.416
training: epoch 41, step 4400, loss 35.073883, time: 3.398
training: epoch 41, step 4600, loss 35.104426, time: 3.404
training: epoch 41, step 4800, loss 35.066686, time: 3.404
training: epoch 41, step 5000, loss 35.064435, time: 3.413
training: epoch 41, step 5200, loss 35.086819, time: 3.413
training: epoch 41, step 5400, loss 35.080069, time: 3.440
training: epoch 41, step 5600, loss 35.076313, time: 3.438
training: epoch 41, step 5800, loss 35.090455, time: 3.433
training: epoch 41, step 6000, loss 35.033811, time: 3.438
training: epoch 41, step 6200, loss 35.008228, time: 3.450
training: epoch 41, step 6400, loss 35.044904, time: 3.437
training: epoch 41, step 6600, loss 35.044724, time: 3.442
training: epoch 41, step 6800, loss 35.088174, time: 3.423
training: epoch 41, step 7000, loss 35.112814, time: 3.443
training: epoch 41, step 7200, loss 35.103806, time: 3.446
training: epoch 41, step 7400, loss 35.128757, time: 3.431
training: epoch 41, step 7600, loss 35.134664, time: 3.449
training: epoch 41, step 7800, loss 35.129124, time: 3.439
training: epoch 41, step 7849, loss 35.122128, time: 0.845
validate: epoch 41, loss 37.372806, charcter error 6.798 time: 4.198
training: epoch 42, step 200, loss 35.891365, time: 3.382
training: epoch 42, step 400, loss 35.615662, time: 3.427
training: epoch 42, step 600, loss 35.411552, time: 3.426
training: epoch 42, step 800, loss 35.315139, time: 3.416
training: epoch 42, step 1000, loss 35.273570, time: 3.420
training: epoch 42, step 1200, loss 35.067238, time: 3.423
training: epoch 42, step 1400, loss 35.068665, time: 3.412
training: epoch 42, step 1600, loss 34.978440, time: 3.415
training: epoch 42, step 1800, loss 35.087349, time: 3.417
training: epoch 42, step 2000, loss 35.095577, time: 3.428
training: epoch 42, step 2200, loss 35.013187, time: 3.434
training: epoch 42, step 2400, loss 35.029461, time: 3.409
training: epoch 42, step 2600, loss 35.020767, time: 3.431
training: epoch 42, step 2800, loss 34.995208, time: 3.419
training: epoch 42, step 3000, loss 35.294857, time: 3.429
training: epoch 42, step 3200, loss 35.391109, time: 3.433
training: epoch 42, step 3400, loss 35.409735, time: 3.429
training: epoch 42, step 3600, loss 35.405957, time: 3.434
training: epoch 42, step 3800, loss 35.404302, time: 3.434
training: epoch 42, step 4000, loss 35.401759, time: 3.424
training: epoch 42, step 4200, loss 35.427855, time: 3.417
training: epoch 42, step 4400, loss 35.394758, time: 3.427
training: epoch 42, step 4600, loss 35.427867, time: 3.420
training: epoch 42, step 4800, loss 35.395338, time: 3.410
training: epoch 42, step 5000, loss 35.363429, time: 3.416
training: epoch 42, step 5200, loss 35.417980, time: 3.421
training: epoch 42, step 5400, loss 35.408159, time: 3.414
training: epoch 42, step 5600, loss 35.407654, time: 3.412
training: epoch 42, step 5800, loss 35.384803, time: 3.413
training: epoch 42, step 6000, loss 35.355234, time: 3.407
training: epoch 42, step 6200, loss 35.355783, time: 3.418
training: epoch 42, step 6400, loss 35.367264, time: 3.406
training: epoch 42, step 6600, loss 35.368795, time: 3.423
training: epoch 42, step 6800, loss 35.360779, time: 3.412
training: epoch 42, step 7000, loss 35.359596, time: 3.411
training: epoch 42, step 7200, loss 35.376304, time: 3.415
training: epoch 42, step 7400, loss 35.366217, time: 3.422
training: epoch 42, step 7600, loss 35.338923, time: 3.429
training: epoch 42, step 7800, loss 35.320859, time: 3.417
training: epoch 42, step 7849, loss 35.321293, time: 0.836
validate: epoch 42, loss 36.871479, charcter error 6.688 time: 4.025
training: epoch 43, step 200, loss 35.148967, time: 3.345
training: epoch 43, step 400, loss 34.937747, time: 3.387
training: epoch 43, step 600, loss 35.063827, time: 3.397
training: epoch 43, step 800, loss 35.314618, time: 3.385
training: epoch 43, step 1000, loss 35.263396, time: 3.386
training: epoch 43, step 1200, loss 35.200715, time: 3.390
training: epoch 43, step 1400, loss 35.189156, time: 3.388
training: epoch 43, step 1600, loss 35.009258, time: 3.388
training: epoch 43, step 1800, loss 35.033986, time: 3.391
training: epoch 43, step 2000, loss 35.053873, time: 3.400
training: epoch 43, step 2200, loss 35.041635, time: 3.389
training: epoch 43, step 2400, loss 35.003997, time: 3.388
training: epoch 43, step 2600, loss 34.998499, time: 3.403
training: epoch 43, step 2800, loss 35.085056, time: 3.399
training: epoch 43, step 3000, loss 35.256789, time: 3.389
training: epoch 43, step 3200, loss 35.261850, time: 3.386
training: epoch 43, step 3400, loss 35.304074, time: 3.387
training: epoch 43, step 3600, loss 35.333802, time: 3.388
training: epoch 43, step 3800, loss 35.305476, time: 3.390
training: epoch 43, step 4000, loss 35.333440, time: 3.389
training: epoch 43, step 4200, loss 35.355905, time: 3.402
training: epoch 43, step 4400, loss 35.365079, time: 3.388
training: epoch 43, step 4600, loss 35.460841, time: 3.391
training: epoch 43, step 4800, loss 35.546622, time: 3.384
training: epoch 43, step 5000, loss 35.578033, time: 3.391
training: epoch 43, step 5200, loss 35.589895, time: 3.389
training: epoch 43, step 5400, loss 35.591746, time: 3.388
training: epoch 43, step 5600, loss 35.550166, time: 3.399
training: epoch 43, step 5800, loss 35.526384, time: 3.402
training: epoch 43, step 6000, loss 35.505698, time: 3.392
training: epoch 43, step 6200, loss 35.487529, time: 3.393
training: epoch 43, step 6400, loss 35.521810, time: 3.397
training: epoch 43, step 6600, loss 35.519431, time: 3.392
training: epoch 43, step 6800, loss 35.487218, time: 3.390
training: epoch 43, step 7000, loss 35.472208, time: 3.392
training: epoch 43, step 7200, loss 35.514427, time: 3.397
training: epoch 43, step 7400, loss 35.542398, time: 3.398
training: epoch 43, step 7600, loss 35.531069, time: 3.390
training: epoch 43, step 7800, loss 35.516548, time: 3.402
training: epoch 43, step 7849, loss 35.491791, time: 0.832
validate: epoch 43, loss 37.096236, charcter error 6.731 time: 4.011
training: epoch 44, step 200, loss 34.491783, time: 3.345
training: epoch 44, step 400, loss 34.995523, time: 3.389
training: epoch 44, step 600, loss 34.872748, time: 3.395
training: epoch 44, step 800, loss 34.996250, time: 3.401
training: epoch 44, step 1000, loss 34.966834, time: 3.391
training: epoch 44, step 1200, loss 34.826717, time: 3.394
training: epoch 44, step 1400, loss 34.875659, time: 3.399
training: epoch 44, step 1600, loss 34.934511, time: 3.407
training: epoch 44, step 1800, loss 35.014777, time: 3.393
training: epoch 44, step 2000, loss 34.964660, time: 3.388
training: epoch 44, step 2200, loss 34.901984, time: 3.399
training: epoch 44, step 2400, loss 34.890558, time: 3.395
training: epoch 44, step 2600, loss 34.910524, time: 3.393
training: epoch 44, step 2800, loss 34.918781, time: 3.397
training: epoch 44, step 3000, loss 34.955152, time: 3.398
training: epoch 44, step 3200, loss 34.961383, time: 3.396
training: epoch 44, step 3400, loss 34.995024, time: 3.388
training: epoch 44, step 3600, loss 34.963606, time: 3.388
training: epoch 44, step 3800, loss 34.922448, time: 3.389
training: epoch 44, step 4000, loss 34.871869, time: 3.388
training: epoch 44, step 4200, loss 34.841552, time: 3.388
training: epoch 44, step 4400, loss 34.871809, time: 3.384
training: epoch 44, step 4600, loss 34.871650, time: 3.387
training: epoch 44, step 4800, loss 34.880169, time: 3.393
training: epoch 44, step 5000, loss 34.858519, time: 3.389
training: epoch 44, step 5200, loss 34.878417, time: 3.385
training: epoch 44, step 5400, loss 34.888970, time: 3.387
training: epoch 44, step 5600, loss 34.883980, time: 3.394
training: epoch 44, step 5800, loss 34.899141, time: 3.393
training: epoch 44, step 6000, loss 34.968471, time: 3.388
training: epoch 44, step 6200, loss 34.980938, time: 3.389
training: epoch 44, step 6400, loss 34.985682, time: 3.384
training: epoch 44, step 6600, loss 35.002198, time: 3.386
training: epoch 44, step 6800, loss 35.016730, time: 3.393
training: epoch 44, step 7000, loss 35.030563, time: 3.390
training: epoch 44, step 7200, loss 34.993701, time: 3.386
training: epoch 44, step 7400, loss 34.998829, time: 3.389
training: epoch 44, step 7600, loss 35.024149, time: 3.387
training: epoch 44, step 7800, loss 35.014610, time: 3.391
training: epoch 44, step 7849, loss 35.020326, time: 0.830
validate: epoch 44, loss 36.645830, charcter error 6.640 time: 4.022
    - [Info] The checkpoint file has been updated.
training: epoch 45, step 200, loss 35.074806, time: 3.349
training: epoch 45, step 400, loss 35.510990, time: 3.391
training: epoch 45, step 600, loss 35.213953, time: 3.403
training: epoch 45, step 800, loss 34.946322, time: 3.402
training: epoch 45, step 1000, loss 34.923621, time: 3.397
training: epoch 45, step 1200, loss 34.622910, time: 3.400
training: epoch 45, step 1400, loss 34.707502, time: 3.388
training: epoch 45, step 1600, loss 34.671579, time: 3.382
training: epoch 45, step 1800, loss 34.666676, time: 3.396
training: epoch 45, step 2000, loss 34.591391, time: 3.397
training: epoch 45, step 2200, loss 34.742949, time: 3.389
training: epoch 45, step 2400, loss 34.792089, time: 3.390
training: epoch 45, step 2600, loss 34.856726, time: 3.397
training: epoch 45, step 2800, loss 34.785152, time: 3.396
training: epoch 45, step 3000, loss 34.932207, time: 3.395
training: epoch 45, step 3200, loss 35.099611, time: 3.403
training: epoch 45, step 3400, loss 35.123901, time: 3.394
training: epoch 45, step 3600, loss 35.154430, time: 3.391
training: epoch 45, step 3800, loss 35.168859, time: 3.394
training: epoch 45, step 4000, loss 35.204444, time: 3.392
training: epoch 45, step 4200, loss 35.176651, time: 3.391
training: epoch 45, step 4400, loss 35.137562, time: 3.386
training: epoch 45, step 4600, loss 35.120890, time: 3.394
training: epoch 45, step 4800, loss 35.120778, time: 3.391
training: epoch 45, step 5000, loss 35.124075, time: 3.402
training: epoch 45, step 5200, loss 35.119615, time: 3.401
training: epoch 45, step 5400, loss 35.073842, time: 3.406
training: epoch 45, step 5600, loss 35.099754, time: 3.408
training: epoch 45, step 5800, loss 35.116573, time: 3.405
training: epoch 45, step 6000, loss 35.149022, time: 3.404
training: epoch 45, step 6200, loss 35.153445, time: 3.414
training: epoch 45, step 6400, loss 35.145931, time: 3.497
training: epoch 45, step 6600, loss 35.148792, time: 3.506
training: epoch 45, step 6800, loss 35.153827, time: 3.553
training: epoch 45, step 7000, loss 35.163031, time: 3.533
training: epoch 45, step 7200, loss 35.189152, time: 3.525
training: epoch 45, step 7400, loss 35.190045, time: 3.547
training: epoch 45, step 7600, loss 35.192900, time: 3.523
training: epoch 45, step 7800, loss 35.163407, time: 3.509
training: epoch 45, step 7849, loss 35.163649, time: 0.854
validate: epoch 45, loss 36.854098, charcter error 6.665 time: 4.046
training: epoch 46, step 200, loss 34.114574, time: 3.514
training: epoch 46, step 400, loss 34.192494, time: 3.589
training: epoch 46, step 600, loss 34.371953, time: 3.563
training: epoch 46, step 800, loss 34.365752, time: 3.501
training: epoch 46, step 1000, loss 34.425376, time: 3.462
training: epoch 46, step 1200, loss 34.464490, time: 3.442
training: epoch 46, step 1400, loss 34.363101, time: 3.421
training: epoch 46, step 1600, loss 34.433073, time: 3.416
training: epoch 46, step 1800, loss 34.458379, time: 3.400
training: epoch 46, step 2000, loss 34.495185, time: 3.401
training: epoch 46, step 2200, loss 34.450316, time: 3.402
training: epoch 46, step 2400, loss 34.452369, time: 3.400
training: epoch 46, step 2600, loss 34.585361, time: 3.395
training: epoch 46, step 2800, loss 34.616741, time: 3.400
training: epoch 46, step 3000, loss 34.604467, time: 3.400
training: epoch 46, step 3200, loss 34.713303, time: 3.390
training: epoch 46, step 3400, loss 34.712172, time: 3.386
training: epoch 46, step 3600, loss 34.783107, time: 3.390
training: epoch 46, step 3800, loss 34.873355, time: 3.388
training: epoch 46, step 4000, loss 34.894634, time: 3.397
training: epoch 46, step 4200, loss 34.852281, time: 3.390
training: epoch 46, step 4400, loss 34.858369, time: 3.390
training: epoch 46, step 4600, loss 34.859470, time: 3.388
training: epoch 46, step 4800, loss 34.892946, time: 3.380
training: epoch 46, step 5000, loss 34.888623, time: 3.389
training: epoch 46, step 5200, loss 34.921751, time: 3.390
training: epoch 46, step 5400, loss 34.928102, time: 3.384
training: epoch 46, step 5600, loss 34.933941, time: 3.382
training: epoch 46, step 5800, loss 34.918328, time: 3.387
training: epoch 46, step 6000, loss 34.912499, time: 3.389
training: epoch 46, step 6200, loss 34.903587, time: 3.397
training: epoch 46, step 6400, loss 34.878043, time: 3.396
training: epoch 46, step 6600, loss 34.896082, time: 3.389
training: epoch 46, step 6800, loss 34.863265, time: 3.395
training: epoch 46, step 7000, loss 34.839608, time: 3.394
training: epoch 46, step 7200, loss 34.864986, time: 3.386
training: epoch 46, step 7400, loss 34.865993, time: 3.386
training: epoch 46, step 7600, loss 34.878816, time: 3.394
training: epoch 46, step 7800, loss 34.882929, time: 3.390
training: epoch 46, step 7849, loss 34.882265, time: 0.830
validate: epoch 46, loss 37.147147, charcter error 6.764 time: 4.043
training: epoch 47, step 200, loss 34.508020, time: 3.342
training: epoch 47, step 400, loss 34.526290, time: 3.387
training: epoch 47, step 600, loss 34.675013, time: 3.393
training: epoch 47, step 800, loss 34.605487, time: 3.403
training: epoch 47, step 1000, loss 34.496980, time: 3.406
training: epoch 47, step 1200, loss 34.596708, time: 3.407
training: epoch 47, step 1400, loss 34.536779, time: 3.409
training: epoch 47, step 1600, loss 34.535514, time: 3.489
training: epoch 47, step 1800, loss 34.601437, time: 3.500
training: epoch 47, step 2000, loss 34.783163, time: 3.494
training: epoch 47, step 2200, loss 35.142082, time: 3.477
training: epoch 47, step 2400, loss 35.371584, time: 3.504
training: epoch 47, step 2600, loss 35.491479, time: 3.523
training: epoch 47, step 2800, loss 35.513872, time: 3.477
training: epoch 47, step 3000, loss 35.568409, time: 3.474
training: epoch 47, step 3200, loss 35.595495, time: 3.479
training: epoch 47, step 3400, loss 35.584230, time: 3.471
training: epoch 47, step 3600, loss 35.657054, time: 3.541
training: epoch 47, step 3800, loss 35.661309, time: 3.533
training: epoch 47, step 4000, loss 35.619456, time: 3.494
training: epoch 47, step 4200, loss 35.607632, time: 3.518
training: epoch 47, step 4400, loss 35.578036, time: 3.498
training: epoch 47, step 4600, loss 35.573814, time: 3.473
training: epoch 47, step 4800, loss 35.568824, time: 3.407
training: epoch 47, step 5000, loss 35.545238, time: 3.408
training: epoch 47, step 5200, loss 35.512607, time: 3.421
training: epoch 47, step 5400, loss 35.507601, time: 3.473
training: epoch 47, step 5600, loss 35.503434, time: 3.516
training: epoch 47, step 5800, loss 35.514443, time: 3.506
training: epoch 47, step 6000, loss 35.482787, time: 3.490
training: epoch 47, step 6200, loss 35.488804, time: 3.482
training: epoch 47, step 6400, loss 35.471611, time: 3.489
training: epoch 47, step 6600, loss 35.437594, time: 3.480
training: epoch 47, step 6800, loss 35.429425, time: 3.479
training: epoch 47, step 7000, loss 35.419577, time: 3.492
training: epoch 47, step 7200, loss 35.409273, time: 3.483
training: epoch 47, step 7400, loss 35.398217, time: 3.494
training: epoch 47, step 7600, loss 35.377582, time: 3.500
training: epoch 47, step 7800, loss 35.366964, time: 3.494
training: epoch 47, step 7849, loss 35.364313, time: 0.868
validate: epoch 47, loss 36.823265, charcter error 6.696 time: 4.042
training: epoch 48, step 200, loss 34.905125, time: 3.436
training: epoch 48, step 400, loss 34.490759, time: 3.491
training: epoch 48, step 600, loss 34.863874, time: 3.508
training: epoch 48, step 800, loss 34.653066, time: 3.500
training: epoch 48, step 1000, loss 34.598287, time: 3.591
training: epoch 48, step 1200, loss 34.814009, time: 3.507
training: epoch 48, step 1400, loss 34.552304, time: 3.506
training: epoch 48, step 1600, loss 34.468626, time: 3.452
training: epoch 48, step 1800, loss 34.435595, time: 3.501
training: epoch 48, step 2000, loss 34.437443, time: 3.513
training: epoch 48, step 2200, loss 34.347288, time: 3.514
training: epoch 48, step 2400, loss 34.310139, time: 3.459
training: epoch 48, step 2600, loss 34.301728, time: 3.477
training: epoch 48, step 2800, loss 34.343071, time: 3.545
training: epoch 48, step 3000, loss 34.383564, time: 3.484
training: epoch 48, step 3200, loss 34.346307, time: 3.447
training: epoch 48, step 3400, loss 34.413793, time: 3.447
training: epoch 48, step 3600, loss 34.508516, time: 3.434
training: epoch 48, step 3800, loss 34.550483, time: 3.430
training: epoch 48, step 4000, loss 34.520543, time: 3.422
training: epoch 48, step 4200, loss 34.532479, time: 3.415
training: epoch 48, step 4400, loss 34.509215, time: 3.413
training: epoch 48, step 4600, loss 34.528193, time: 3.414
training: epoch 48, step 4800, loss 34.535607, time: 3.418
training: epoch 48, step 5000, loss 34.590113, time: 3.412
training: epoch 48, step 5200, loss 34.587135, time: 3.409
training: epoch 48, step 5400, loss 34.589722, time: 3.408
training: epoch 48, step 5600, loss 34.578719, time: 3.413
training: epoch 48, step 5800, loss 34.568138, time: 3.408
training: epoch 48, step 6000, loss 34.601654, time: 3.413
training: epoch 48, step 6200, loss 34.605990, time: 3.410
training: epoch 48, step 6400, loss 34.611191, time: 3.405
training: epoch 48, step 6600, loss 34.625204, time: 3.405
training: epoch 48, step 6800, loss 34.598414, time: 3.412
training: epoch 48, step 7000, loss 34.639307, time: 3.413
training: epoch 48, step 7200, loss 34.630348, time: 3.413
training: epoch 48, step 7400, loss 34.635405, time: 3.413
training: epoch 48, step 7600, loss 34.651505, time: 3.413
training: epoch 48, step 7800, loss 34.658181, time: 3.413
training: epoch 48, step 7849, loss 34.658810, time: 0.837
validate: epoch 48, loss 36.874154, charcter error 6.696 time: 4.038
training: epoch 49, step 200, loss 36.257252, time: 3.353
training: epoch 49, step 400, loss 35.425850, time: 3.399
training: epoch 49, step 600, loss 34.788919, time: 3.408
training: epoch 49, step 800, loss 34.910250, time: 3.406
training: epoch 49, step 1000, loss 34.920541, time: 3.408
training: epoch 49, step 1200, loss 35.057966, time: 3.406
training: epoch 49, step 1400, loss 35.094038, time: 3.410
training: epoch 49, step 1600, loss 34.990215, time: 3.411
training: epoch 49, step 1800, loss 34.964802, time: 3.410
training: epoch 49, step 2000, loss 34.870869, time: 3.404
training: epoch 49, step 2200, loss 34.873574, time: 3.402
training: epoch 49, step 2400, loss 34.873864, time: 3.399
training: epoch 49, step 2600, loss 34.831408, time: 3.405
training: epoch 49, step 2800, loss 34.853177, time: 3.411
training: epoch 49, step 3000, loss 34.852228, time: 3.409
training: epoch 49, step 3200, loss 34.836382, time: 3.411
training: epoch 49, step 3400, loss 34.796026, time: 3.413
training: epoch 49, step 3600, loss 34.797978, time: 3.413
training: epoch 49, step 3800, loss 34.724534, time: 3.411
training: epoch 49, step 4000, loss 34.703300, time: 3.409
training: epoch 49, step 4200, loss 34.723814, time: 3.413
training: epoch 49, step 4400, loss 34.695714, time: 3.413
training: epoch 49, step 4600, loss 34.704289, time: 3.413
training: epoch 49, step 4800, loss 34.838057, time: 3.413
training: epoch 49, step 5000, loss 34.847954, time: 3.410
training: epoch 49, step 5200, loss 34.813347, time: 3.413
training: epoch 49, step 5400, loss 34.873909, time: 3.413
training: epoch 49, step 5600, loss 34.913255, time: 3.413
training: epoch 49, step 5800, loss 34.872432, time: 3.413
training: epoch 49, step 6000, loss 34.878626, time: 3.413
training: epoch 49, step 6200, loss 34.890961, time: 3.413
training: epoch 49, step 6400, loss 34.894811, time: 3.413
training: epoch 49, step 6600, loss 34.872188, time: 3.412
training: epoch 49, step 6800, loss 34.831557, time: 3.413
training: epoch 49, step 7000, loss 34.847124, time: 3.411
training: epoch 49, step 7200, loss 34.840895, time: 3.414
training: epoch 49, step 7400, loss 34.854465, time: 3.411
training: epoch 49, step 7600, loss 34.893762, time: 3.413
training: epoch 49, step 7800, loss 34.931983, time: 3.412
training: epoch 49, step 7849, loss 34.948825, time: 0.836
validate: epoch 49, loss 37.648109, charcter error 6.804 time: 4.025
training: epoch 50, step 200, loss 35.321194, time: 3.357
training: epoch 50, step 400, loss 35.566515, time: 3.405
training: epoch 50, step 600, loss 34.849478, time: 3.412
training: epoch 50, step 800, loss 34.968219, time: 3.413
training: epoch 50, step 1000, loss 35.079904, time: 3.413
training: epoch 50, step 1200, loss 35.004484, time: 3.410
training: epoch 50, step 1400, loss 35.025598, time: 3.414
training: epoch 50, step 1600, loss 34.993630, time: 3.413
training: epoch 50, step 1800, loss 35.046059, time: 3.413
training: epoch 50, step 2000, loss 35.103434, time: 3.413
training: epoch 50, step 2200, loss 35.038183, time: 3.413
training: epoch 50, step 2400, loss 34.975723, time: 3.411
training: epoch 50, step 2600, loss 34.970017, time: 3.411
training: epoch 50, step 2800, loss 34.951803, time: 3.410
training: epoch 50, step 3000, loss 34.919413, time: 3.413
training: epoch 50, step 3200, loss 34.988317, time: 3.408
training: epoch 50, step 3400, loss 35.011115, time: 3.401
training: epoch 50, step 3600, loss 34.970441, time: 3.402
training: epoch 50, step 3800, loss 35.004892, time: 3.411
training: epoch 50, step 4000, loss 34.938812, time: 3.411
training: epoch 50, step 4200, loss 34.907839, time: 3.412
training: epoch 50, step 4400, loss 34.862397, time: 3.413
training: epoch 50, step 4600, loss 34.792999, time: 3.407
training: epoch 50, step 4800, loss 34.789886, time: 3.410
training: epoch 50, step 5000, loss 34.784843, time: 3.410
training: epoch 50, step 5200, loss 34.757103, time: 3.413
training: epoch 50, step 5400, loss 34.771945, time: 3.413
training: epoch 50, step 5600, loss 34.820064, time: 3.413
training: epoch 50, step 5800, loss 34.873903, time: 3.412
training: epoch 50, step 6000, loss 34.890248, time: 3.413
training: epoch 50, step 6200, loss 34.913466, time: 3.413
training: epoch 50, step 6400, loss 34.905588, time: 3.413
training: epoch 50, step 6600, loss 34.910089, time: 3.413
training: epoch 50, step 6800, loss 34.897033, time: 3.413
training: epoch 50, step 7000, loss 34.886981, time: 3.413
training: epoch 50, step 7200, loss 34.905477, time: 3.413
training: epoch 50, step 7400, loss 34.873830, time: 3.413
training: epoch 50, step 7600, loss 34.873831, time: 3.414
training: epoch 50, step 7800, loss 34.851477, time: 3.413
training: epoch 50, step 7849, loss 34.878506, time: 0.836
validate: epoch 50, loss 42.564974, charcter error 7.657 time: 4.020
training: epoch 51, step 200, loss 37.234342, time: 3.358
training: epoch 51, step 400, loss 35.834328, time: 3.409
training: epoch 51, step 600, loss 35.324881, time: 3.413
training: epoch 51, step 800, loss 35.025157, time: 3.413
training: epoch 51, step 1000, loss 35.017450, time: 3.413
training: epoch 51, step 1200, loss 34.931491, time: 3.413
training: epoch 51, step 1400, loss 35.086807, time: 3.413
training: epoch 51, step 1600, loss 35.149229, time: 3.413
training: epoch 51, step 1800, loss 35.406674, time: 3.413
training: epoch 51, step 2000, loss 35.440121, time: 3.413
training: epoch 51, step 2200, loss 35.387276, time: 3.413
training: epoch 51, step 2400, loss 35.440120, time: 3.413
training: epoch 51, step 2600, loss 35.404894, time: 3.414
training: epoch 51, step 2800, loss 35.310588, time: 3.413
training: epoch 51, step 3000, loss 35.271170, time: 3.413
training: epoch 51, step 3200, loss 35.227237, time: 3.413
training: epoch 51, step 3400, loss 35.208695, time: 3.414
training: epoch 51, step 3600, loss 35.215587, time: 3.413
training: epoch 51, step 3800, loss 35.152922, time: 3.413
training: epoch 51, step 4000, loss 35.149385, time: 3.415
training: epoch 51, step 4200, loss 35.161839, time: 3.413
training: epoch 51, step 4400, loss 35.148257, time: 3.413
training: epoch 51, step 4600, loss 35.145380, time: 3.413
training: epoch 51, step 4800, loss 35.093350, time: 3.413
training: epoch 51, step 5000, loss 35.037233, time: 3.413
training: epoch 51, step 5200, loss 34.987394, time: 3.413
training: epoch 51, step 5400, loss 34.965773, time: 3.415
training: epoch 51, step 5600, loss 34.919956, time: 3.413
training: epoch 51, step 5800, loss 34.917881, time: 3.414
training: epoch 51, step 6000, loss 34.907272, time: 3.415
training: epoch 51, step 6200, loss 34.880067, time: 3.413
training: epoch 51, step 6400, loss 34.852501, time: 3.414
training: epoch 51, step 6600, loss 34.810684, time: 3.413
training: epoch 51, step 6800, loss 34.812009, time: 3.413
training: epoch 51, step 7000, loss 34.803431, time: 3.413
training: epoch 51, step 7200, loss 34.843102, time: 3.413
training: epoch 51, step 7400, loss 34.859486, time: 3.413
training: epoch 51, step 7600, loss 34.825763, time: 3.413
training: epoch 51, step 7800, loss 34.864913, time: 3.413
training: epoch 51, step 7849, loss 34.851129, time: 0.836
validate: epoch 51, loss 36.405814, charcter error 6.609 time: 4.022
    - [Info] The checkpoint file has been updated.
training: epoch 52, step 200, loss 34.454637, time: 3.361
training: epoch 52, step 400, loss 34.423477, time: 3.406
training: epoch 52, step 600, loss 34.697919, time: 3.412
training: epoch 52, step 800, loss 34.319504, time: 3.401
training: epoch 52, step 1000, loss 34.410522, time: 3.410
training: epoch 52, step 1200, loss 34.590949, time: 3.403
training: epoch 52, step 1400, loss 34.580021, time: 3.407
training: epoch 52, step 1600, loss 34.475041, time: 3.404
training: epoch 52, step 1800, loss 34.427171, time: 3.408
training: epoch 52, step 2000, loss 34.384843, time: 3.409
training: epoch 52, step 2200, loss 34.321984, time: 3.401
training: epoch 52, step 2400, loss 34.448649, time: 3.410
training: epoch 52, step 2600, loss 34.437076, time: 3.413
training: epoch 52, step 2800, loss 34.411341, time: 3.410
training: epoch 52, step 3000, loss 34.343341, time: 3.410
training: epoch 52, step 3200, loss 34.402839, time: 3.398
training: epoch 52, step 3400, loss 34.392610, time: 3.401
training: epoch 52, step 3600, loss 34.386678, time: 3.408
training: epoch 52, step 3800, loss 34.373709, time: 3.412
training: epoch 52, step 4000, loss 34.385888, time: 3.410
training: epoch 52, step 4200, loss 34.372892, time: 3.413
training: epoch 52, step 4400, loss 34.392642, time: 3.408
training: epoch 52, step 4600, loss 34.381356, time: 3.401
training: epoch 52, step 4800, loss 34.395746, time: 3.404
training: epoch 52, step 5000, loss 34.385641, time: 3.411
training: epoch 52, step 5200, loss 34.399287, time: 3.401
training: epoch 52, step 5400, loss 34.365843, time: 3.393
training: epoch 52, step 5600, loss 34.353276, time: 3.398
training: epoch 52, step 5800, loss 34.385830, time: 3.404
training: epoch 52, step 6000, loss 34.445101, time: 3.400
training: epoch 52, step 6200, loss 34.459956, time: 3.395
training: epoch 52, step 6400, loss 34.458507, time: 3.401
training: epoch 52, step 6600, loss 34.471165, time: 3.413
training: epoch 52, step 6800, loss 34.490098, time: 3.404
training: epoch 52, step 7000, loss 34.512239, time: 3.403
training: epoch 52, step 7200, loss 34.546619, time: 3.401
training: epoch 52, step 7400, loss 34.567145, time: 3.407
training: epoch 52, step 7600, loss 34.566696, time: 3.413
training: epoch 52, step 7800, loss 34.570761, time: 3.397
training: epoch 52, step 7849, loss 34.567047, time: 0.832
validate: epoch 52, loss 36.632487, charcter error 6.640 time: 4.014
training: epoch 53, step 200, loss 33.946330, time: 3.351
training: epoch 53, step 400, loss 33.988903, time: 3.395
training: epoch 53, step 600, loss 33.854385, time: 3.412
training: epoch 53, step 800, loss 34.070359, time: 3.413
training: epoch 53, step 1000, loss 34.124388, time: 3.402
training: epoch 53, step 1200, loss 34.017220, time: 3.397
training: epoch 53, step 1400, loss 34.023364, time: 3.395
training: epoch 53, step 1600, loss 34.118404, time: 3.400
training: epoch 53, step 1800, loss 34.148945, time: 3.403
training: epoch 53, step 2000, loss 34.305991, time: 3.410
training: epoch 53, step 2200, loss 34.407104, time: 3.413
training: epoch 53, step 2400, loss 34.598397, time: 3.413
training: epoch 53, step 2600, loss 34.633041, time: 3.413
training: epoch 53, step 2800, loss 34.734080, time: 3.406
training: epoch 53, step 3000, loss 34.753511, time: 3.413
training: epoch 53, step 3200, loss 34.717847, time: 3.413
training: epoch 53, step 3400, loss 34.740829, time: 3.412
training: epoch 53, step 3600, loss 34.713300, time: 3.412
training: epoch 53, step 3800, loss 34.727470, time: 3.410
training: epoch 53, step 4000, loss 34.712591, time: 3.405
training: epoch 53, step 4200, loss 34.673783, time: 3.410
training: epoch 53, step 4400, loss 34.660458, time: 3.408
training: epoch 53, step 4600, loss 34.689100, time: 3.404
training: epoch 53, step 4800, loss 34.671133, time: 3.407
training: epoch 53, step 5000, loss 34.652501, time: 3.407
training: epoch 53, step 5200, loss 34.621673, time: 3.409
training: epoch 53, step 5400, loss 34.601731, time: 3.410
training: epoch 53, step 5600, loss 34.586473, time: 3.413
training: epoch 53, step 5800, loss 34.586657, time: 3.413
training: epoch 53, step 6000, loss 34.558898, time: 3.404
training: epoch 53, step 6200, loss 34.543154, time: 3.405
training: epoch 53, step 6400, loss 34.531400, time: 3.410
training: epoch 53, step 6600, loss 34.518352, time: 3.413
training: epoch 53, step 6800, loss 34.491224, time: 3.413
training: epoch 53, step 7000, loss 34.503261, time: 3.413
training: epoch 53, step 7200, loss 34.474099, time: 3.413
training: epoch 53, step 7400, loss 34.481631, time: 3.413
training: epoch 53, step 7600, loss 34.523805, time: 3.413
training: epoch 53, step 7800, loss 34.538458, time: 3.413
training: epoch 53, step 7849, loss 34.550391, time: 0.836
validate: epoch 53, loss 37.056759, charcter error 6.716 time: 4.024
training: epoch 54, step 200, loss 35.491471, time: 3.356
training: epoch 54, step 400, loss 35.182048, time: 3.409
training: epoch 54, step 600, loss 34.755176, time: 3.413
training: epoch 54, step 800, loss 34.800710, time: 3.413
training: epoch 54, step 1000, loss 34.843581, time: 3.413
training: epoch 54, step 1200, loss 34.713907, time: 3.413
training: epoch 54, step 1400, loss 34.730225, time: 3.413
training: epoch 54, step 1600, loss 34.615658, time: 3.413
training: epoch 54, step 1800, loss 34.745482, time: 3.413
training: epoch 54, step 2000, loss 34.773920, time: 3.413
training: epoch 54, step 2200, loss 34.908089, time: 3.413
training: epoch 54, step 2400, loss 34.935714, time: 3.413
training: epoch 54, step 2600, loss 34.824846, time: 3.411
training: epoch 54, step 2800, loss 34.845188, time: 3.403
training: epoch 54, step 3000, loss 34.774756, time: 3.405
training: epoch 54, step 3200, loss 34.778642, time: 3.413
training: epoch 54, step 3400, loss 34.711223, time: 3.413
training: epoch 54, step 3600, loss 34.672796, time: 3.414
training: epoch 54, step 3800, loss 34.691633, time: 3.413
training: epoch 54, step 4000, loss 34.739587, time: 3.413
training: epoch 54, step 4200, loss 34.829375, time: 3.413
training: epoch 54, step 4400, loss 34.789810, time: 3.413
training: epoch 54, step 4600, loss 34.829640, time: 3.413
training: epoch 54, step 4800, loss 34.792264, time: 3.413
training: epoch 54, step 5000, loss 34.770837, time: 3.413
training: epoch 54, step 5200, loss 34.757591, time: 3.413
training: epoch 54, step 5400, loss 34.781865, time: 3.413
training: epoch 54, step 5600, loss 34.777318, time: 3.413
training: epoch 54, step 5800, loss 34.782517, time: 3.413
training: epoch 54, step 6000, loss 34.762307, time: 3.413
training: epoch 54, step 6200, loss 34.780775, time: 3.413
training: epoch 54, step 6400, loss 34.767122, time: 3.413
training: epoch 54, step 6600, loss 34.793504, time: 3.413
training: epoch 54, step 6800, loss 34.783446, time: 3.413
training: epoch 54, step 7000, loss 34.803601, time: 3.413
training: epoch 54, step 7200, loss 34.826938, time: 3.413
training: epoch 54, step 7400, loss 34.808996, time: 3.413
training: epoch 54, step 7600, loss 34.819287, time: 3.415
training: epoch 54, step 7800, loss 34.832670, time: 3.415
training: epoch 54, step 7849, loss 34.824193, time: 0.836
validate: epoch 54, loss 36.589868, charcter error 6.654 time: 4.017
training: epoch 55, step 200, loss 34.329727, time: 3.367
training: epoch 55, step 400, loss 34.937513, time: 3.409
training: epoch 55, step 600, loss 34.706268, time: 3.413
training: epoch 55, step 800, loss 34.626120, time: 3.413
training: epoch 55, step 1000, loss 34.668918, time: 3.413
training: epoch 55, step 1200, loss 34.496849, time: 3.413
training: epoch 55, step 1400, loss 34.534110, time: 3.413
training: epoch 55, step 1600, loss 34.551556, time: 3.413
training: epoch 55, step 1800, loss 34.565328, time: 3.413
training: epoch 55, step 2000, loss 34.553692, time: 3.413
training: epoch 55, step 2200, loss 34.525002, time: 3.413
training: epoch 55, step 2400, loss 34.554028, time: 3.413
training: epoch 55, step 2600, loss 34.560354, time: 3.413
training: epoch 55, step 2800, loss 34.484113, time: 3.410
training: epoch 55, step 3000, loss 34.472602, time: 3.399
training: epoch 55, step 3200, loss 34.454396, time: 3.404
training: epoch 55, step 3400, loss 34.436728, time: 3.407
training: epoch 55, step 3600, loss 34.391967, time: 3.409
training: epoch 55, step 3800, loss 34.360316, time: 3.407
training: epoch 55, step 4000, loss 34.317996, time: 3.413
training: epoch 55, step 4200, loss 34.395617, time: 3.413
training: epoch 55, step 4400, loss 34.433306, time: 3.413
training: epoch 55, step 4600, loss 34.510201, time: 3.413
training: epoch 55, step 4800, loss 34.602568, time: 3.404
training: epoch 55, step 5000, loss 34.657759, time: 3.404
training: epoch 55, step 5200, loss 34.691710, time: 3.399
training: epoch 55, step 5400, loss 34.686193, time: 3.399
training: epoch 55, step 5600, loss 34.675256, time: 3.400
training: epoch 55, step 5800, loss 34.689920, time: 3.409
training: epoch 55, step 6000, loss 34.666579, time: 3.405
training: epoch 55, step 6200, loss 34.641978, time: 3.406
training: epoch 55, step 6400, loss 34.649023, time: 3.410
training: epoch 55, step 6600, loss 34.646678, time: 3.406
training: epoch 55, step 6800, loss 34.659057, time: 3.401
training: epoch 55, step 7000, loss 34.653762, time: 3.402
training: epoch 55, step 7200, loss 34.631316, time: 3.395
training: epoch 55, step 7400, loss 34.639959, time: 3.397
training: epoch 55, step 7600, loss 34.607319, time: 3.404
training: epoch 55, step 7800, loss 34.587206, time: 3.401
training: epoch 55, step 7849, loss 34.597207, time: 0.832
validate: epoch 55, loss 36.637416, charcter error 6.620 time: 4.020
training: epoch 56, step 200, loss 33.725469, time: 3.345
training: epoch 56, step 400, loss 34.391831, time: 3.386
training: epoch 56, step 600, loss 34.532062, time: 3.400
training: epoch 56, step 800, loss 34.449453, time: 3.397
training: epoch 56, step 1000, loss 34.201818, time: 3.406
training: epoch 56, step 1200, loss 34.273969, time: 3.410
training: epoch 56, step 1400, loss 34.116107, time: 3.408
training: epoch 56, step 1600, loss 34.139153, time: 3.490
training: epoch 56, step 1800, loss 34.221350, time: 3.517
training: epoch 56, step 2000, loss 34.142987, time: 3.563
training: epoch 56, step 2200, loss 34.189222, time: 3.577
training: epoch 56, step 2400, loss 34.169451, time: 3.533
training: epoch 56, step 2600, loss 34.155998, time: 3.529
training: epoch 56, step 2800, loss 34.217874, time: 3.542
training: epoch 56, step 3000, loss 34.228710, time: 3.514
training: epoch 56, step 3200, loss 34.219265, time: 3.521
training: epoch 56, step 3400, loss 34.125151, time: 3.506
training: epoch 56, step 3600, loss 34.105343, time: 3.503
training: epoch 56, step 3800, loss 34.128377, time: 3.563
training: epoch 56, step 4000, loss 34.118531, time: 3.558
training: epoch 56, step 4200, loss 34.158553, time: 3.480
training: epoch 56, step 4400, loss 34.191006, time: 3.467
training: epoch 56, step 4600, loss 34.196335, time: 3.427
training: epoch 56, step 4800, loss 34.209399, time: 3.425
training: epoch 56, step 5000, loss 34.329447, time: 3.420
training: epoch 56, step 5200, loss 34.374435, time: 3.414
training: epoch 56, step 5400, loss 34.388798, time: 3.407
training: epoch 56, step 5600, loss 34.391384, time: 3.400
training: epoch 56, step 5800, loss 34.366565, time: 3.402
training: epoch 56, step 6000, loss 34.388211, time: 3.403
training: epoch 56, step 6200, loss 34.422606, time: 3.406
training: epoch 56, step 6400, loss 34.400078, time: 3.400
training: epoch 56, step 6600, loss 34.397883, time: 3.399
training: epoch 56, step 6800, loss 34.402540, time: 3.390
training: epoch 56, step 7000, loss 34.389235, time: 3.390
training: epoch 56, step 7200, loss 34.388894, time: 3.392
training: epoch 56, step 7400, loss 34.414171, time: 3.396
training: epoch 56, step 7600, loss 34.417420, time: 3.404
training: epoch 56, step 7800, loss 34.425343, time: 3.409
training: epoch 56, step 7849, loss 34.420009, time: 0.836
validate: epoch 56, loss 36.423524, charcter error 6.577 time: 4.037
    - [Info] The checkpoint file has been updated.
training: epoch 57, step 200, loss 34.542155, time: 3.361
training: epoch 57, step 400, loss 35.216059, time: 3.388
training: epoch 57, step 600, loss 35.407355, time: 3.410
training: epoch 57, step 800, loss 35.436372, time: 3.400
training: epoch 57, step 1000, loss 35.414140, time: 3.403
training: epoch 57, step 1200, loss 35.382600, time: 3.410
training: epoch 57, step 1400, loss 35.420236, time: 3.404
training: epoch 57, step 1600, loss 35.242383, time: 3.406
training: epoch 57, step 1800, loss 35.149866, time: 3.409
training: epoch 57, step 2000, loss 34.989806, time: 3.406
training: epoch 57, step 2200, loss 34.877217, time: 3.406
training: epoch 57, step 2400, loss 34.798555, time: 3.403
training: epoch 57, step 2600, loss 34.762818, time: 3.401
training: epoch 57, step 2800, loss 34.727394, time: 3.412
training: epoch 57, step 3000, loss 34.719577, time: 3.399
training: epoch 57, step 3200, loss 34.692496, time: 3.402
training: epoch 57, step 3400, loss 34.723013, time: 3.403
training: epoch 57, step 3600, loss 34.693192, time: 3.402
training: epoch 57, step 3800, loss 34.759990, time: 3.401
training: epoch 57, step 4000, loss 34.744493, time: 3.402
training: epoch 57, step 4200, loss 34.747951, time: 3.404
training: epoch 57, step 4400, loss 34.747420, time: 3.394
training: epoch 57, step 4600, loss 34.721024, time: 3.420
training: epoch 57, step 4800, loss 34.719501, time: 3.403
training: epoch 57, step 5000, loss 34.677722, time: 3.430
training: epoch 57, step 5200, loss 34.674477, time: 3.416
training: epoch 57, step 5400, loss 34.730986, time: 3.478
training: epoch 57, step 5600, loss 34.671676, time: 3.484
training: epoch 57, step 5800, loss 34.626952, time: 3.496
training: epoch 57, step 6000, loss 34.640835, time: 3.492
training: epoch 57, step 6200, loss 34.642704, time: 3.461
training: epoch 57, step 6400, loss 34.624540, time: 3.459
training: epoch 57, step 6600, loss 34.628863, time: 3.481
training: epoch 57, step 6800, loss 34.605229, time: 3.491
training: epoch 57, step 7000, loss 34.587192, time: 3.523
training: epoch 57, step 7200, loss 34.559544, time: 3.529
training: epoch 57, step 7400, loss 34.517792, time: 3.487
training: epoch 57, step 7600, loss 34.525561, time: 3.506
training: epoch 57, step 7800, loss 34.517701, time: 3.508
training: epoch 57, step 7849, loss 34.518991, time: 0.859
validate: epoch 57, loss 36.871037, charcter error 6.689 time: 4.034
training: epoch 58, step 200, loss 34.690512, time: 3.375
training: epoch 58, step 400, loss 34.629834, time: 3.419
training: epoch 58, step 600, loss 34.438379, time: 3.451
training: epoch 58, step 800, loss 34.460279, time: 3.492
training: epoch 58, step 1000, loss 34.351204, time: 3.487
training: epoch 58, step 1200, loss 34.400570, time: 3.495
training: epoch 58, step 1400, loss 34.313988, time: 3.468
training: epoch 58, step 1600, loss 34.272869, time: 3.472
training: epoch 58, step 1800, loss 34.237967, time: 3.450
training: epoch 58, step 2000, loss 34.108560, time: 3.449
training: epoch 58, step 2200, loss 34.165295, time: 3.463
training: epoch 58, step 2400, loss 34.102411, time: 3.460
training: epoch 58, step 2600, loss 34.018371, time: 3.469
training: epoch 58, step 2800, loss 34.101274, time: 3.483
training: epoch 58, step 3000, loss 34.165936, time: 3.491
training: epoch 58, step 3200, loss 34.235317, time: 3.479
training: epoch 58, step 3400, loss 34.253927, time: 3.459
training: epoch 58, step 3600, loss 34.276422, time: 3.486
training: epoch 58, step 3800, loss 34.217936, time: 3.468
training: epoch 58, step 4000, loss 34.251210, time: 3.463
training: epoch 58, step 4200, loss 34.268636, time: 3.478
training: epoch 58, step 4400, loss 34.295142, time: 3.479
training: epoch 58, step 4600, loss 34.374135, time: 3.489
training: epoch 58, step 4800, loss 34.332741, time: 3.454
training: epoch 58, step 5000, loss 34.311618, time: 3.469
training: epoch 58, step 5200, loss 34.341226, time: 3.501
training: epoch 58, step 5400, loss 34.323897, time: 3.508
training: epoch 58, step 5600, loss 34.266238, time: 3.460
training: epoch 58, step 5800, loss 34.261506, time: 3.472
training: epoch 58, step 6000, loss 34.196132, time: 3.514
training: epoch 58, step 6200, loss 34.195848, time: 3.547
training: epoch 58, step 6400, loss 34.178286, time: 3.478
training: epoch 58, step 6600, loss 34.200682, time: 3.463
training: epoch 58, step 6800, loss 34.190051, time: 3.465
training: epoch 58, step 7000, loss 34.205876, time: 3.433
training: epoch 58, step 7200, loss 34.201968, time: 3.426
training: epoch 58, step 7400, loss 34.187016, time: 3.426
training: epoch 58, step 7600, loss 34.177687, time: 3.419
training: epoch 58, step 7800, loss 34.178000, time: 3.414
training: epoch 58, step 7849, loss 34.180957, time: 0.836
validate: epoch 58, loss 36.126543, charcter error 6.560 time: 4.039
    - [Info] The checkpoint file has been updated.
training: epoch 59, step 200, loss 34.180946, time: 3.371
training: epoch 59, step 400, loss 34.093910, time: 3.410
training: epoch 59, step 600, loss 33.820296, time: 3.414
training: epoch 59, step 800, loss 33.979996, time: 3.413
training: epoch 59, step 1000, loss 33.895323, time: 3.416
training: epoch 59, step 1200, loss 33.769578, time: 3.413
training: epoch 59, step 1400, loss 33.864772, time: 3.413
training: epoch 59, step 1600, loss 33.977380, time: 3.413
training: epoch 59, step 1800, loss 34.027493, time: 3.413
training: epoch 59, step 2000, loss 34.024791, time: 3.413
training: epoch 59, step 2200, loss 33.976192, time: 3.413
training: epoch 59, step 2400, loss 33.923137, time: 3.413
training: epoch 59, step 2600, loss 33.876489, time: 3.413
training: epoch 59, step 2800, loss 33.855348, time: 3.413
training: epoch 59, step 3000, loss 33.840108, time: 3.413
training: epoch 59, step 3200, loss 33.886723, time: 3.413
training: epoch 59, step 3400, loss 33.894321, time: 3.413
training: epoch 59, step 3600, loss 33.914438, time: 3.413
training: epoch 59, step 3800, loss 33.913607, time: 3.413
training: epoch 59, step 4000, loss 33.914878, time: 3.413
training: epoch 59, step 4200, loss 33.916092, time: 3.413
training: epoch 59, step 4400, loss 33.920833, time: 3.413
training: epoch 59, step 4600, loss 33.917037, time: 3.413
training: epoch 59, step 4800, loss 33.931835, time: 3.413
training: epoch 59, step 5000, loss 33.947160, time: 3.413
training: epoch 59, step 5200, loss 33.941552, time: 3.417
training: epoch 59, step 5400, loss 33.982740, time: 3.413
training: epoch 59, step 5600, loss 34.039693, time: 3.413
training: epoch 59, step 5800, loss 34.049125, time: 3.413
training: epoch 59, step 6000, loss 34.015172, time: 3.413
training: epoch 59, step 6200, loss 34.035147, time: 3.413
training: epoch 59, step 6400, loss 34.095974, time: 3.415
training: epoch 59, step 6600, loss 34.138323, time: 3.415
training: epoch 59, step 6800, loss 34.152971, time: 3.419
training: epoch 59, step 7000, loss 34.152338, time: 3.417
training: epoch 59, step 7200, loss 34.176620, time: 3.413
training: epoch 59, step 7400, loss 34.200718, time: 3.415
training: epoch 59, step 7600, loss 34.183144, time: 3.413
training: epoch 59, step 7800, loss 34.153368, time: 3.413
training: epoch 59, step 7849, loss 34.145187, time: 0.836
validate: epoch 59, loss 36.187659, charcter error 6.547 time: 4.019
    - [Info] The checkpoint file has been updated.
training: epoch 60, step 200, loss 33.629038, time: 3.374
training: epoch 60, step 400, loss 34.012420, time: 3.413
training: epoch 60, step 600, loss 34.127549, time: 3.413
training: epoch 60, step 800, loss 33.726415, time: 3.413
training: epoch 60, step 1000, loss 33.838679, time: 3.413
training: epoch 60, step 1200, loss 33.868873, time: 3.415
training: epoch 60, step 1400, loss 33.969550, time: 3.413
training: epoch 60, step 1600, loss 33.808538, time: 3.415
training: epoch 60, step 1800, loss 33.753250, time: 3.413
training: epoch 60, step 2000, loss 33.704421, time: 3.413
training: epoch 60, step 2200, loss 33.626014, time: 3.413
training: epoch 60, step 2400, loss 33.577698, time: 3.414
training: epoch 60, step 2600, loss 33.664785, time: 3.413
training: epoch 60, step 2800, loss 33.660251, time: 3.413
training: epoch 60, step 3000, loss 33.674839, time: 3.413
training: epoch 60, step 3200, loss 33.633271, time: 3.413
training: epoch 60, step 3400, loss 33.681565, time: 3.413
training: epoch 60, step 3600, loss 33.653831, time: 3.413
training: epoch 60, step 3800, loss 33.678909, time: 3.413
training: epoch 60, step 4000, loss 33.716986, time: 3.414
training: epoch 60, step 4200, loss 33.739187, time: 3.413
training: epoch 60, step 4400, loss 33.816494, time: 3.413
training: epoch 60, step 4600, loss 33.835176, time: 3.413
training: epoch 60, step 4800, loss 33.819106, time: 3.413
training: epoch 60, step 5000, loss 33.799475, time: 3.413
training: epoch 60, step 5200, loss 33.798017, time: 3.413
training: epoch 60, step 5400, loss 33.843480, time: 3.413
training: epoch 60, step 5600, loss 33.895521, time: 3.413
training: epoch 60, step 5800, loss 33.918520, time: 3.413
training: epoch 60, step 6000, loss 33.905023, time: 3.413
training: epoch 60, step 6200, loss 33.952136, time: 3.413
training: epoch 60, step 6400, loss 33.979182, time: 3.413
training: epoch 60, step 6600, loss 34.006522, time: 3.413
training: epoch 60, step 6800, loss 34.014811, time: 3.413
training: epoch 60, step 7000, loss 34.008870, time: 3.413
training: epoch 60, step 7200, loss 34.023392, time: 3.413
training: epoch 60, step 7400, loss 34.029433, time: 3.413
training: epoch 60, step 7600, loss 34.041644, time: 3.413
training: epoch 60, step 7800, loss 34.022785, time: 3.413
training: epoch 60, step 7849, loss 34.022069, time: 0.836
validate: epoch 60, loss 36.169296, charcter error 6.552 time: 4.033
training: epoch 61, step 200, loss 33.552650, time: 3.358
training: epoch 61, step 400, loss 33.630312, time: 3.408
training: epoch 61, step 600, loss 33.474149, time: 3.413
training: epoch 61, step 800, loss 33.585975, time: 3.413
training: epoch 61, step 1000, loss 33.627634, time: 3.413
training: epoch 61, step 1200, loss 33.863105, time: 3.413
training: epoch 61, step 1400, loss 33.847662, time: 3.412
training: epoch 61, step 1600, loss 34.080192, time: 3.398
training: epoch 61, step 1800, loss 34.161115, time: 3.395
training: epoch 61, step 2000, loss 34.124101, time: 3.393
training: epoch 61, step 2200, loss 34.177633, time: 3.392
training: epoch 61, step 2400, loss 34.442404, time: 3.393
training: epoch 61, step 2600, loss 34.528414, time: 3.392
training: epoch 61, step 2800, loss 34.541737, time: 3.389
training: epoch 61, step 3000, loss 34.543176, time: 3.394
training: epoch 61, step 3200, loss 34.544698, time: 3.394
training: epoch 61, step 3400, loss 34.477575, time: 3.392
training: epoch 61, step 3600, loss 34.472405, time: 3.397
training: epoch 61, step 3800, loss 34.435024, time: 3.395
training: epoch 61, step 4000, loss 34.449182, time: 3.399
training: epoch 61, step 4200, loss 34.445713, time: 3.406
training: epoch 61, step 4400, loss 34.499316, time: 3.394
training: epoch 61, step 4600, loss 34.527462, time: 3.391
training: epoch 61, step 4800, loss 34.486033, time: 3.392
training: epoch 61, step 5000, loss 34.461897, time: 3.397
training: epoch 61, step 5200, loss 34.451086, time: 3.393
training: epoch 61, step 5400, loss 34.400768, time: 3.390
training: epoch 61, step 5600, loss 34.405581, time: 3.396
training: epoch 61, step 5800, loss 34.396475, time: 3.403
training: epoch 61, step 6000, loss 34.356455, time: 3.419
training: epoch 61, step 6200, loss 34.339677, time: 3.390
training: epoch 61, step 6400, loss 34.369985, time: 3.392
training: epoch 61, step 6600, loss 34.349192, time: 3.392
training: epoch 61, step 6800, loss 34.316785, time: 3.395
training: epoch 61, step 7000, loss 34.293805, time: 3.397
training: epoch 61, step 7200, loss 34.321438, time: 3.394
training: epoch 61, step 7400, loss 34.298886, time: 3.393
training: epoch 61, step 7600, loss 34.296291, time: 3.397
training: epoch 61, step 7800, loss 34.262974, time: 3.390
training: epoch 61, step 7849, loss 34.264417, time: 0.831
validate: epoch 61, loss 36.125566, charcter error 6.546 time: 4.012
    - [Info] The checkpoint file has been updated.
training: epoch 62, step 200, loss 32.649780, time: 3.347
training: epoch 62, step 400, loss 33.115813, time: 3.380
training: epoch 62, step 600, loss 32.885985, time: 3.386
training: epoch 62, step 800, loss 32.921705, time: 3.388
training: epoch 62, step 1000, loss 33.242007, time: 3.389
training: epoch 62, step 1200, loss 33.332943, time: 3.391
training: epoch 62, step 1400, loss 33.567604, time: 3.393
training: epoch 62, step 1600, loss 33.711446, time: 3.395
training: epoch 62, step 1800, loss 33.695909, time: 3.393
training: epoch 62, step 2000, loss 33.733894, time: 3.395
training: epoch 62, step 2200, loss 33.660096, time: 3.391
training: epoch 62, step 2400, loss 33.678517, time: 3.392
training: epoch 62, step 2600, loss 33.760219, time: 3.392
training: epoch 62, step 2800, loss 33.780136, time: 3.390
training: epoch 62, step 3000, loss 33.743028, time: 3.392
training: epoch 62, step 3200, loss 33.732439, time: 3.392
training: epoch 62, step 3400, loss 33.787869, time: 3.394
training: epoch 62, step 3600, loss 33.774649, time: 3.392
training: epoch 62, step 3800, loss 33.803091, time: 3.390
training: epoch 62, step 4000, loss 33.823060, time: 3.390
training: epoch 62, step 4200, loss 33.836663, time: 3.390
training: epoch 62, step 4400, loss 33.862077, time: 3.388
training: epoch 62, step 4600, loss 33.847624, time: 3.384
training: epoch 62, step 4800, loss 33.844421, time: 3.389
training: epoch 62, step 5000, loss 33.854990, time: 3.389
training: epoch 62, step 5200, loss 33.874436, time: 3.388
training: epoch 62, step 5400, loss 33.867117, time: 3.389
training: epoch 62, step 5600, loss 33.835360, time: 3.389
training: epoch 62, step 5800, loss 33.852108, time: 3.389
training: epoch 62, step 6000, loss 33.851764, time: 3.390
training: epoch 62, step 6200, loss 33.854753, time: 3.391
training: epoch 62, step 6400, loss 33.841035, time: 3.392
training: epoch 62, step 6600, loss 33.845209, time: 3.389
training: epoch 62, step 6800, loss 33.866942, time: 3.391
training: epoch 62, step 7000, loss 33.878362, time: 3.389
training: epoch 62, step 7200, loss 33.868736, time: 3.383
training: epoch 62, step 7400, loss 33.872785, time: 3.383
training: epoch 62, step 7600, loss 33.860112, time: 3.381
training: epoch 62, step 7800, loss 33.889624, time: 3.386
training: epoch 62, step 7849, loss 33.889210, time: 0.829
validate: epoch 62, loss 36.216793, charcter error 6.545 time: 4.026
    - [Info] The checkpoint file has been updated.
training: epoch 63, step 200, loss 34.612921, time: 3.349
training: epoch 63, step 400, loss 33.950412, time: 3.377
training: epoch 63, step 600, loss 33.936691, time: 3.385
training: epoch 63, step 800, loss 33.837196, time: 3.384
training: epoch 63, step 1000, loss 33.582183, time: 3.386
training: epoch 63, step 1200, loss 33.578327, time: 3.381
training: epoch 63, step 1400, loss 33.941818, time: 3.386
training: epoch 63, step 1600, loss 34.254949, time: 3.383
training: epoch 63, step 1800, loss 34.347535, time: 3.382
training: epoch 63, step 2000, loss 34.286934, time: 3.382
training: epoch 63, step 2200, loss 34.300851, time: 3.381
training: epoch 63, step 2400, loss 34.324184, time: 3.383
training: epoch 63, step 2600, loss 34.392616, time: 3.384
training: epoch 63, step 2800, loss 34.381850, time: 3.385
training: epoch 63, step 3000, loss 34.392571, time: 3.382
training: epoch 63, step 3200, loss 34.435229, time: 3.380
training: epoch 63, step 3400, loss 34.405518, time: 3.383
training: epoch 63, step 3600, loss 34.363927, time: 3.383
training: epoch 63, step 3800, loss 34.290246, time: 3.383
training: epoch 63, step 4000, loss 34.252966, time: 3.383
training: epoch 63, step 4200, loss 34.229174, time: 3.385
training: epoch 63, step 4400, loss 34.268164, time: 3.384
training: epoch 63, step 4600, loss 34.250370, time: 3.384
training: epoch 63, step 4800, loss 34.237401, time: 3.383
training: epoch 63, step 5000, loss 34.202679, time: 3.381
training: epoch 63, step 5200, loss 34.177350, time: 3.382
training: epoch 63, step 5400, loss 34.176834, time: 3.383
training: epoch 63, step 5600, loss 34.145264, time: 3.381
training: epoch 63, step 5800, loss 34.103251, time: 3.380
training: epoch 63, step 6000, loss 34.088297, time: 3.383
training: epoch 63, step 6200, loss 34.061549, time: 3.379
training: epoch 63, step 6400, loss 34.054405, time: 3.381
training: epoch 63, step 6600, loss 34.063556, time: 3.382
training: epoch 63, step 6800, loss 34.067642, time: 3.380
training: epoch 63, step 7000, loss 34.076804, time: 3.380
training: epoch 63, step 7200, loss 34.069266, time: 3.379
training: epoch 63, step 7400, loss 34.052550, time: 3.383
training: epoch 63, step 7600, loss 34.034037, time: 3.379
training: epoch 63, step 7800, loss 34.043737, time: 3.383
training: epoch 63, step 7849, loss 34.032000, time: 0.827
validate: epoch 63, loss 36.360252, charcter error 6.558 time: 4.010
training: epoch 64, step 200, loss 34.198111, time: 3.332
training: epoch 64, step 400, loss 34.098482, time: 3.375
training: epoch 64, step 600, loss 34.215322, time: 3.381
training: epoch 64, step 800, loss 34.212371, time: 3.384
training: epoch 64, step 1000, loss 34.096436, time: 3.384
training: epoch 64, step 1200, loss 34.023537, time: 3.383
training: epoch 64, step 1400, loss 34.072069, time: 3.384
training: epoch 64, step 1600, loss 34.136613, time: 3.385
training: epoch 64, step 1800, loss 34.171617, time: 3.386
training: epoch 64, step 2000, loss 34.027069, time: 3.381
training: epoch 64, step 2200, loss 34.059518, time: 3.384
training: epoch 64, step 2400, loss 34.007542, time: 3.385
training: epoch 64, step 2600, loss 33.923103, time: 3.381
training: epoch 64, step 2800, loss 33.881745, time: 3.380
training: epoch 64, step 3000, loss 33.918179, time: 3.386
training: epoch 64, step 3200, loss 33.994971, time: 3.382
training: epoch 64, step 3400, loss 34.006154, time: 3.381
training: epoch 64, step 3600, loss 33.991636, time: 3.379
training: epoch 64, step 3800, loss 33.980892, time: 3.379
training: epoch 64, step 4000, loss 33.924156, time: 3.381
training: epoch 64, step 4200, loss 33.950531, time: 3.380
training: epoch 64, step 4400, loss 34.043969, time: 3.382
training: epoch 64, step 4600, loss 34.031291, time: 3.383
training: epoch 64, step 4800, loss 34.060746, time: 3.381
training: epoch 64, step 5000, loss 34.042160, time: 3.380
training: epoch 64, step 5200, loss 34.023854, time: 3.380
training: epoch 64, step 5400, loss 34.024582, time: 3.382
training: epoch 64, step 5600, loss 34.033902, time: 3.379
training: epoch 64, step 5800, loss 34.033205, time: 3.380
training: epoch 64, step 6000, loss 34.048937, time: 3.382
training: epoch 64, step 6200, loss 34.040704, time: 3.380
training: epoch 64, step 6400, loss 34.002740, time: 3.380
training: epoch 64, step 6600, loss 33.987905, time: 3.380
training: epoch 64, step 6800, loss 33.987899, time: 3.379
training: epoch 64, step 7000, loss 33.961004, time: 3.377
training: epoch 64, step 7200, loss 33.960035, time: 3.381
training: epoch 64, step 7400, loss 33.930174, time: 3.382
training: epoch 64, step 7600, loss 33.912049, time: 3.380
training: epoch 64, step 7800, loss 33.919997, time: 3.381
training: epoch 64, step 7849, loss 33.925363, time: 0.829
validate: epoch 64, loss 35.967960, charcter error 6.530 time: 4.011
    - [Info] The checkpoint file has been updated.
training: epoch 65, step 200, loss 33.251506, time: 3.342
training: epoch 65, step 400, loss 33.552062, time: 3.376
training: epoch 65, step 600, loss 33.823429, time: 3.382
training: epoch 65, step 800, loss 33.850746, time: 3.383
training: epoch 65, step 1000, loss 33.677816, time: 3.385
training: epoch 65, step 1200, loss 33.650154, time: 3.383
training: epoch 65, step 1400, loss 33.681704, time: 3.382
training: epoch 65, step 1600, loss 33.791428, time: 3.381
training: epoch 65, step 1800, loss 33.780689, time: 3.381
training: epoch 65, step 2000, loss 33.832974, time: 3.383
training: epoch 65, step 2200, loss 33.835282, time: 3.382
training: epoch 65, step 2400, loss 33.822077, time: 3.382
training: epoch 65, step 2600, loss 33.736993, time: 3.383
training: epoch 65, step 2800, loss 33.773465, time: 3.382
training: epoch 65, step 3000, loss 33.742321, time: 3.383
training: epoch 65, step 3200, loss 33.714836, time: 3.383
training: epoch 65, step 3400, loss 33.705701, time: 3.381
training: epoch 65, step 3600, loss 33.696077, time: 3.381
training: epoch 65, step 3800, loss 33.671507, time: 3.384
training: epoch 65, step 4000, loss 33.627841, time: 3.382
training: epoch 65, step 4200, loss 33.622503, time: 3.384
training: epoch 65, step 4400, loss 33.586415, time: 3.379
training: epoch 65, step 4600, loss 33.587944, time: 3.383
training: epoch 65, step 4800, loss 33.597281, time: 3.381
training: epoch 65, step 5000, loss 33.612954, time: 3.383
training: epoch 65, step 5200, loss 33.608502, time: 3.384
training: epoch 65, step 5400, loss 33.623473, time: 3.378
training: epoch 65, step 5600, loss 33.634742, time: 3.381
training: epoch 65, step 5800, loss 33.627914, time: 3.382
training: epoch 65, step 6000, loss 33.601895, time: 3.384
training: epoch 65, step 6200, loss 33.606196, time: 3.379
training: epoch 65, step 6400, loss 33.647818, time: 3.380
training: epoch 65, step 6600, loss 33.660402, time: 3.381
training: epoch 65, step 6800, loss 33.698916, time: 3.384
training: epoch 65, step 7000, loss 33.701033, time: 3.382
training: epoch 65, step 7200, loss 33.713391, time: 3.381
training: epoch 65, step 7400, loss 33.714378, time: 3.379
training: epoch 65, step 7600, loss 33.704337, time: 3.381
training: epoch 65, step 7800, loss 33.692121, time: 3.381
training: epoch 65, step 7849, loss 33.692009, time: 0.829
validate: epoch 65, loss 36.298068, charcter error 6.562 time: 4.019
training: epoch 66, step 200, loss 32.206679, time: 3.331
training: epoch 66, step 400, loss 32.891425, time: 3.376
training: epoch 66, step 600, loss 32.968539, time: 3.381
training: epoch 66, step 800, loss 32.986284, time: 3.381
training: epoch 66, step 1000, loss 33.098442, time: 3.384
training: epoch 66, step 1200, loss 33.177131, time: 3.382
training: epoch 66, step 1400, loss 33.277883, time: 3.383
training: epoch 66, step 1600, loss 33.370482, time: 3.385
training: epoch 66, step 1800, loss 33.472482, time: 3.382
training: epoch 66, step 2000, loss 33.388815, time: 3.381
training: epoch 66, step 2200, loss 33.397033, time: 3.382
training: epoch 66, step 2400, loss 33.503982, time: 3.384
training: epoch 66, step 2600, loss 33.557584, time: 3.384
training: epoch 66, step 2800, loss 33.513836, time: 3.382
training: epoch 66, step 3000, loss 33.495263, time: 3.384
training: epoch 66, step 3200, loss 33.493720, time: 3.384
training: epoch 66, step 3400, loss 33.519222, time: 3.377
training: epoch 66, step 3600, loss 33.519668, time: 3.380
training: epoch 66, step 3800, loss 33.594686, time: 3.381
training: epoch 66, step 4000, loss 33.600588, time: 3.383
training: epoch 66, step 4200, loss 33.598467, time: 3.385
training: epoch 66, step 4400, loss 33.592162, time: 3.379
training: epoch 66, step 4600, loss 33.582130, time: 3.378
training: epoch 66, step 4800, loss 33.554461, time: 3.380
training: epoch 66, step 5000, loss 33.533557, time: 3.382
training: epoch 66, step 5200, loss 33.511467, time: 3.470
training: epoch 66, step 5400, loss 33.532620, time: 3.502
training: epoch 66, step 5600, loss 33.536678, time: 3.512
training: epoch 66, step 5800, loss 33.553332, time: 3.558
training: epoch 66, step 6000, loss 33.543545, time: 3.514
training: epoch 66, step 6200, loss 33.585207, time: 3.506
training: epoch 66, step 6400, loss 33.600044, time: 3.504
training: epoch 66, step 6600, loss 33.550571, time: 3.526
training: epoch 66, step 6800, loss 33.546057, time: 3.507
training: epoch 66, step 7000, loss 33.550343, time: 3.522
training: epoch 66, step 7200, loss 33.553625, time: 3.489
training: epoch 66, step 7400, loss 33.558974, time: 3.506
training: epoch 66, step 7600, loss 33.572665, time: 3.577
training: epoch 66, step 7800, loss 33.539318, time: 3.506
training: epoch 66, step 7849, loss 33.541111, time: 0.846
validate: epoch 66, loss 35.796143, charcter error 6.515 time: 4.029
    - [Info] The checkpoint file has been updated.
training: epoch 67, step 200, loss 33.466003, time: 3.404
training: epoch 67, step 400, loss 34.501403, time: 3.420
training: epoch 67, step 600, loss 34.715139, time: 3.405
training: epoch 67, step 800, loss 34.207705, time: 3.410
training: epoch 67, step 1000, loss 34.099649, time: 3.393
training: epoch 67, step 1200, loss 34.148940, time: 3.387
training: epoch 67, step 1400, loss 34.082797, time: 3.391
training: epoch 67, step 1600, loss 33.956665, time: 3.384
training: epoch 67, step 1800, loss 33.906268, time: 3.381
training: epoch 67, step 2000, loss 33.877673, time: 3.376
training: epoch 67, step 2200, loss 33.831268, time: 3.380
training: epoch 67, step 2400, loss 33.861730, time: 3.381
training: epoch 67, step 2600, loss 33.856930, time: 3.383
training: epoch 67, step 2800, loss 33.881742, time: 3.382
training: epoch 67, step 3000, loss 33.847257, time: 3.377
training: epoch 67, step 3200, loss 33.881858, time: 3.378
training: epoch 67, step 3400, loss 33.861382, time: 3.380
training: epoch 67, step 3600, loss 33.808930, time: 3.375
training: epoch 67, step 3800, loss 33.753044, time: 3.372
training: epoch 67, step 4000, loss 33.737846, time: 3.379
training: epoch 67, step 4200, loss 33.696529, time: 3.377
training: epoch 67, step 4400, loss 33.732586, time: 3.378
training: epoch 67, step 4600, loss 33.713022, time: 3.378
training: epoch 67, step 4800, loss 33.747237, time: 3.379
training: epoch 67, step 5000, loss 33.766774, time: 3.376
training: epoch 67, step 5200, loss 33.749882, time: 3.375
training: epoch 67, step 5400, loss 33.718953, time: 3.376
training: epoch 67, step 5600, loss 33.724196, time: 3.379
training: epoch 67, step 5800, loss 33.746283, time: 3.378
training: epoch 67, step 6000, loss 33.744104, time: 3.376
training: epoch 67, step 6200, loss 33.693031, time: 3.374
training: epoch 67, step 6400, loss 33.738361, time: 3.378
training: epoch 67, step 6600, loss 33.722893, time: 3.377
training: epoch 67, step 6800, loss 33.700133, time: 3.372
training: epoch 67, step 7000, loss 33.684044, time: 3.379
training: epoch 67, step 7200, loss 33.680850, time: 3.377
training: epoch 67, step 7400, loss 33.650854, time: 3.373
training: epoch 67, step 7600, loss 33.606658, time: 3.374
training: epoch 67, step 7800, loss 33.614503, time: 3.378
training: epoch 67, step 7849, loss 33.620278, time: 0.827
validate: epoch 67, loss 35.805008, charcter error 6.494 time: 4.016
    - [Info] The checkpoint file has been updated.
training: epoch 68, step 200, loss 33.497352, time: 3.348
training: epoch 68, step 400, loss 33.520828, time: 3.374
training: epoch 68, step 600, loss 33.630828, time: 3.433
training: epoch 68, step 800, loss 33.866514, time: 3.423
training: epoch 68, step 1000, loss 33.741802, time: 3.456
training: epoch 68, step 1200, loss 33.817149, time: 3.471
training: epoch 68, step 1400, loss 33.728976, time: 3.486
training: epoch 68, step 1600, loss 33.681608, time: 3.474
training: epoch 68, step 1800, loss 33.601666, time: 3.433
training: epoch 68, step 2000, loss 33.688059, time: 3.441
training: epoch 68, step 2200, loss 33.758567, time: 3.453
training: epoch 68, step 2400, loss 33.806270, time: 3.454
training: epoch 68, step 2600, loss 33.889895, time: 3.495
training: epoch 68, step 2800, loss 33.867149, time: 3.506
training: epoch 68, step 3000, loss 33.850878, time: 3.510
training: epoch 68, step 3200, loss 33.855273, time: 3.459
training: epoch 68, step 3400, loss 33.816726, time: 3.452
training: epoch 68, step 3600, loss 33.730866, time: 3.453
training: epoch 68, step 3800, loss 33.732186, time: 3.389
training: epoch 68, step 4000, loss 33.699778, time: 3.378
training: epoch 68, step 4200, loss 33.697366, time: 3.392
training: epoch 68, step 4400, loss 33.682949, time: 3.452
training: epoch 68, step 4600, loss 33.672654, time: 3.452
training: epoch 68, step 4800, loss 33.653610, time: 3.455
training: epoch 68, step 5000, loss 33.656449, time: 3.465
training: epoch 68, step 5200, loss 33.661179, time: 3.465
training: epoch 68, step 5400, loss 33.687730, time: 3.454
training: epoch 68, step 5600, loss 33.683853, time: 3.433
training: epoch 68, step 5800, loss 33.705713, time: 3.444
training: epoch 68, step 6000, loss 33.736003, time: 3.447
training: epoch 68, step 6200, loss 33.717176, time: 3.461
training: epoch 68, step 6400, loss 33.708664, time: 3.444
training: epoch 68, step 6600, loss 33.722214, time: 3.447
training: epoch 68, step 6800, loss 33.722143, time: 3.457
training: epoch 68, step 7000, loss 33.732646, time: 3.446
training: epoch 68, step 7200, loss 33.716803, time: 3.477
training: epoch 68, step 7400, loss 33.693190, time: 3.431
training: epoch 68, step 7600, loss 33.699816, time: 3.454
training: epoch 68, step 7800, loss 33.696710, time: 3.421
training: epoch 68, step 7849, loss 33.698913, time: 0.837
validate: epoch 68, loss 35.924772, charcter error 6.513 time: 4.038
training: epoch 69, step 200, loss 34.924982, time: 3.527
training: epoch 69, step 400, loss 33.751324, time: 3.497
training: epoch 69, step 600, loss 34.142794, time: 3.454
training: epoch 69, step 800, loss 33.972137, time: 3.446
training: epoch 69, step 1000, loss 33.812451, time: 3.462
training: epoch 69, step 1200, loss 33.716367, time: 3.484
training: epoch 69, step 1400, loss 33.787817, time: 3.447
training: epoch 69, step 1600, loss 33.661756, time: 3.440
training: epoch 69, step 1800, loss 33.672072, time: 3.451
training: epoch 69, step 2000, loss 33.646643, time: 3.479
training: epoch 69, step 2200, loss 33.643505, time: 3.428
training: epoch 69, step 2400, loss 33.594703, time: 3.413
training: epoch 69, step 2600, loss 33.505331, time: 3.413
training: epoch 69, step 2800, loss 33.407690, time: 3.403
training: epoch 69, step 3000, loss 33.486087, time: 3.399
training: epoch 69, step 3200, loss 33.567976, time: 3.390
training: epoch 69, step 3400, loss 33.627850, time: 3.384
training: epoch 69, step 3600, loss 33.569522, time: 3.386
training: epoch 69, step 3800, loss 33.526930, time: 3.382
training: epoch 69, step 4000, loss 33.597100, time: 3.381
training: epoch 69, step 4200, loss 33.618058, time: 3.381
training: epoch 69, step 4400, loss 33.595552, time: 3.377
training: epoch 69, step 4600, loss 33.567345, time: 3.378
training: epoch 69, step 4800, loss 33.584241, time: 3.378
training: epoch 69, step 5000, loss 33.590313, time: 3.374
training: epoch 69, step 5200, loss 33.589083, time: 3.377
training: epoch 69, step 5400, loss 33.570887, time: 3.380
training: epoch 69, step 5600, loss 33.556826, time: 3.375
training: epoch 69, step 5800, loss 33.609892, time: 3.376
training: epoch 69, step 6000, loss 33.607551, time: 3.376
training: epoch 69, step 6200, loss 33.626020, time: 3.380
training: epoch 69, step 6400, loss 33.638297, time: 3.377
training: epoch 69, step 6600, loss 33.640758, time: 3.377
training: epoch 69, step 6800, loss 33.618511, time: 3.378
training: epoch 69, step 7000, loss 33.601494, time: 3.378
training: epoch 69, step 7200, loss 33.595965, time: 3.375
training: epoch 69, step 7400, loss 33.613923, time: 3.376
training: epoch 69, step 7600, loss 33.634506, time: 3.377
training: epoch 69, step 7800, loss 33.629573, time: 3.381
training: epoch 69, step 7849, loss 33.631674, time: 0.828
validate: epoch 69, loss 35.818080, charcter error 6.497 time: 4.036
training: epoch 70, step 200, loss 33.176662, time: 3.330
training: epoch 70, step 400, loss 32.872215, time: 3.365
training: epoch 70, step 600, loss 33.324410, time: 3.375
training: epoch 70, step 800, loss 33.572885, time: 3.375
training: epoch 70, step 1000, loss 33.590638, time: 3.376
training: epoch 70, step 1200, loss 33.500086, time: 3.377
training: epoch 70, step 1400, loss 33.579068, time: 3.377
training: epoch 70, step 1600, loss 33.569055, time: 3.376
training: epoch 70, step 1800, loss 33.617973, time: 3.373
training: epoch 70, step 2000, loss 33.613142, time: 3.376
training: epoch 70, step 2200, loss 33.554787, time: 3.376
training: epoch 70, step 2400, loss 33.505608, time: 3.376
training: epoch 70, step 2600, loss 33.496065, time: 3.376
training: epoch 70, step 2800, loss 33.484246, time: 3.376
training: epoch 70, step 3000, loss 33.539964, time: 3.373
training: epoch 70, step 3200, loss 33.519790, time: 3.372
training: epoch 70, step 3400, loss 33.535435, time: 3.374
training: epoch 70, step 3600, loss 33.501220, time: 3.375
training: epoch 70, step 3800, loss 33.519675, time: 3.377
training: epoch 70, step 4000, loss 33.527348, time: 3.370
training: epoch 70, step 4200, loss 33.489693, time: 3.374
training: epoch 70, step 4400, loss 33.463333, time: 3.371
training: epoch 70, step 4600, loss 33.407839, time: 3.374
training: epoch 70, step 4800, loss 33.440875, time: 3.373
training: epoch 70, step 5000, loss 33.442612, time: 3.374
training: epoch 70, step 5200, loss 33.434155, time: 3.373
training: epoch 70, step 5400, loss 33.484535, time: 3.379
training: epoch 70, step 5600, loss 33.517610, time: 3.374
training: epoch 70, step 5800, loss 33.527818, time: 3.375
training: epoch 70, step 6000, loss 33.518514, time: 3.377
training: epoch 70, step 6200, loss 33.511088, time: 3.377
training: epoch 70, step 6400, loss 33.531212, time: 3.371
training: epoch 70, step 6600, loss 33.512459, time: 3.375
training: epoch 70, step 6800, loss 33.476439, time: 3.380
training: epoch 70, step 7000, loss 33.451579, time: 3.376
training: epoch 70, step 7200, loss 33.446350, time: 3.376
training: epoch 70, step 7400, loss 33.453883, time: 3.379
training: epoch 70, step 7600, loss 33.467353, time: 3.378
training: epoch 70, step 7800, loss 33.494498, time: 3.382
training: epoch 70, step 7849, loss 33.488549, time: 0.828
validate: epoch 70, loss 38.877272, charcter error 7.023 time: 4.015
training: epoch 71, step 200, loss 35.465503, time: 3.333
training: epoch 71, step 400, loss 34.228176, time: 3.371
training: epoch 71, step 600, loss 34.785826, time: 3.376
training: epoch 71, step 800, loss 34.387272, time: 3.375
training: epoch 71, step 1000, loss 34.247911, time: 3.379
training: epoch 71, step 1200, loss 34.307128, time: 3.379
training: epoch 71, step 1400, loss 34.150823, time: 3.385
training: epoch 71, step 1600, loss 34.097059, time: 3.380
training: epoch 71, step 1800, loss 34.175550, time: 3.383
training: epoch 71, step 2000, loss 34.170512, time: 3.381
training: epoch 71, step 2200, loss 34.178681, time: 3.385
training: epoch 71, step 2400, loss 34.182444, time: 3.384
training: epoch 71, step 2600, loss 34.090560, time: 3.388
training: epoch 71, step 2800, loss 34.095443, time: 3.385
training: epoch 71, step 3000, loss 34.046426, time: 3.387
training: epoch 71, step 3200, loss 34.010142, time: 3.387
training: epoch 71, step 3400, loss 33.945486, time: 3.385
training: epoch 71, step 3600, loss 33.881019, time: 3.386
training: epoch 71, step 3800, loss 33.819136, time: 3.385
training: epoch 71, step 4000, loss 33.789163, time: 3.381
training: epoch 71, step 4200, loss 33.820075, time: 3.382
training: epoch 71, step 4400, loss 33.785572, time: 3.386
training: epoch 71, step 4600, loss 33.766326, time: 3.386
training: epoch 71, step 4800, loss 33.788052, time: 3.385
training: epoch 71, step 5000, loss 33.795276, time: 3.385
training: epoch 71, step 5200, loss 33.783398, time: 3.385
training: epoch 71, step 5400, loss 33.794376, time: 3.385
training: epoch 71, step 5600, loss 33.792811, time: 3.387
training: epoch 71, step 5800, loss 33.765776, time: 3.385
training: epoch 71, step 6000, loss 33.768630, time: 3.388
training: epoch 71, step 6200, loss 33.780203, time: 3.388
training: epoch 71, step 6400, loss 33.776196, time: 3.387
training: epoch 71, step 6600, loss 33.783855, time: 3.381
training: epoch 71, step 6800, loss 33.743965, time: 3.378
training: epoch 71, step 7000, loss 33.738052, time: 3.378
training: epoch 71, step 7200, loss 33.721473, time: 3.378
training: epoch 71, step 7400, loss 33.739158, time: 3.379
training: epoch 71, step 7600, loss 33.764550, time: 3.383
training: epoch 71, step 7800, loss 33.759695, time: 3.379
training: epoch 71, step 7849, loss 33.765968, time: 0.827
validate: epoch 71, loss 35.920859, charcter error 6.511 time: 4.017
training: epoch 72, step 200, loss 32.608980, time: 3.334
training: epoch 72, step 400, loss 32.925064, time: 3.369
training: epoch 72, step 600, loss 33.483193, time: 3.379
training: epoch 72, step 800, loss 33.417330, time: 3.383
training: epoch 72, step 1000, loss 33.524450, time: 3.383
training: epoch 72, step 1200, loss 33.335116, time: 3.380
training: epoch 72, step 1400, loss 33.374691, time: 3.383
training: epoch 72, step 1600, loss 33.323352, time: 3.377
training: epoch 72, step 1800, loss 33.292338, time: 3.377
training: epoch 72, step 2000, loss 33.254232, time: 3.381
training: epoch 72, step 2200, loss 33.269173, time: 3.378
training: epoch 72, step 2400, loss 33.251446, time: 3.377
training: epoch 72, step 2600, loss 33.261684, time: 3.376
training: epoch 72, step 2800, loss 33.233855, time: 3.381
training: epoch 72, step 3000, loss 33.209244, time: 3.380
training: epoch 72, step 3200, loss 33.225926, time: 3.380
training: epoch 72, step 3400, loss 33.256938, time: 3.381
training: epoch 72, step 3600, loss 33.295031, time: 3.386
training: epoch 72, step 3800, loss 33.363809, time: 3.389
training: epoch 72, step 4000, loss 33.351649, time: 3.383
training: epoch 72, step 4200, loss 33.313242, time: 3.386
training: epoch 72, step 4400, loss 33.322732, time: 3.385
training: epoch 72, step 4600, loss 33.341665, time: 3.380
training: epoch 72, step 4800, loss 33.294037, time: 3.384
training: epoch 72, step 5000, loss 33.265901, time: 3.387
training: epoch 72, step 5200, loss 33.241451, time: 3.387
training: epoch 72, step 5400, loss 33.251602, time: 3.385
training: epoch 72, step 5600, loss 33.250693, time: 3.385
training: epoch 72, step 5800, loss 33.243219, time: 3.385
training: epoch 72, step 6000, loss 33.253833, time: 3.385
training: epoch 72, step 6200, loss 33.266086, time: 3.389
training: epoch 72, step 6400, loss 33.260587, time: 3.385
training: epoch 72, step 6600, loss 33.261624, time: 3.385
training: epoch 72, step 6800, loss 33.267410, time: 3.385
training: epoch 72, step 7000, loss 33.287759, time: 3.386
training: epoch 72, step 7200, loss 33.284414, time: 3.384
training: epoch 72, step 7400, loss 33.293035, time: 3.383
training: epoch 72, step 7600, loss 33.278514, time: 3.384
training: epoch 72, step 7800, loss 33.274105, time: 3.386
training: epoch 72, step 7849, loss 33.281698, time: 0.828
validate: epoch 72, loss 35.695867, charcter error 6.464 time: 4.019
    - [Info] The checkpoint file has been updated.
training: epoch 73, step 200, loss 33.142751, time: 3.340
training: epoch 73, step 400, loss 33.362352, time: 3.369
training: epoch 73, step 600, loss 33.612312, time: 3.377
training: epoch 73, step 800, loss 33.383649, time: 3.375
training: epoch 73, step 1000, loss 33.216147, time: 3.374
training: epoch 73, step 1200, loss 33.320665, time: 3.375
training: epoch 73, step 1400, loss 33.323661, time: 3.375
training: epoch 73, step 1600, loss 33.448301, time: 3.378
training: epoch 73, step 1800, loss 33.400948, time: 3.379
training: epoch 73, step 2000, loss 33.358272, time: 3.379
training: epoch 73, step 2200, loss 33.303399, time: 3.382
training: epoch 73, step 2400, loss 33.311011, time: 3.380
training: epoch 73, step 2600, loss 33.320884, time: 3.381
training: epoch 73, step 2800, loss 33.297392, time: 3.379
training: epoch 73, step 3000, loss 33.335967, time: 3.380
training: epoch 73, step 3200, loss 33.303815, time: 3.374
training: epoch 73, step 3400, loss 33.311580, time: 3.378
training: epoch 73, step 3600, loss 33.362086, time: 3.377
training: epoch 73, step 3800, loss 33.344831, time: 3.376
training: epoch 73, step 4000, loss 33.338729, time: 3.379
training: epoch 73, step 4200, loss 33.323851, time: 3.376
training: epoch 73, step 4400, loss 33.302054, time: 3.373
training: epoch 73, step 4600, loss 33.316628, time: 3.377
training: epoch 73, step 4800, loss 33.332057, time: 3.378
training: epoch 73, step 5000, loss 33.314004, time: 3.378
training: epoch 73, step 5200, loss 33.278637, time: 3.376
training: epoch 73, step 5400, loss 33.280505, time: 3.378
training: epoch 73, step 5600, loss 33.280101, time: 3.377
training: epoch 73, step 5800, loss 33.283207, time: 3.382
training: epoch 73, step 6000, loss 33.246468, time: 3.373
training: epoch 73, step 6200, loss 33.248020, time: 3.379
training: epoch 73, step 6400, loss 33.273023, time: 3.379
training: epoch 73, step 6600, loss 33.283131, time: 3.381
training: epoch 73, step 6800, loss 33.263985, time: 3.380
training: epoch 73, step 7000, loss 33.284803, time: 3.380
training: epoch 73, step 7200, loss 33.283241, time: 3.380
training: epoch 73, step 7400, loss 33.287073, time: 3.381
training: epoch 73, step 7600, loss 33.305516, time: 3.381
training: epoch 73, step 7800, loss 33.285247, time: 3.380
training: epoch 73, step 7849, loss 33.282524, time: 0.827
validate: epoch 73, loss 36.720730, charcter error 6.650 time: 4.008
training: epoch 74, step 200, loss 33.599625, time: 3.330
training: epoch 74, step 400, loss 33.300569, time: 3.365
training: epoch 74, step 600, loss 33.164662, time: 3.374
training: epoch 74, step 800, loss 33.293511, time: 3.372
training: epoch 74, step 1000, loss 33.138433, time: 3.370
training: epoch 74, step 1200, loss 33.139881, time: 3.372
training: epoch 74, step 1400, loss 33.212936, time: 3.375
training: epoch 74, step 1600, loss 33.298677, time: 3.380
training: epoch 74, step 1800, loss 33.393186, time: 3.373
training: epoch 74, step 2000, loss 33.453192, time: 3.376
training: epoch 74, step 2200, loss 33.453522, time: 3.376
training: epoch 74, step 2400, loss 33.378713, time: 3.375
training: epoch 74, step 2600, loss 33.366607, time: 3.373
training: epoch 74, step 2800, loss 33.390656, time: 3.373
training: epoch 74, step 3000, loss 33.381378, time: 3.376
training: epoch 74, step 3200, loss 33.365234, time: 3.372
training: epoch 74, step 3400, loss 33.369024, time: 3.375
training: epoch 74, step 3600, loss 33.350823, time: 3.374
training: epoch 74, step 3800, loss 33.329318, time: 3.376
training: epoch 74, step 4000, loss 33.350566, time: 3.377
training: epoch 74, step 4200, loss 33.372887, time: 3.379
training: epoch 74, step 4400, loss 33.368683, time: 3.379
training: epoch 74, step 4600, loss 33.385520, time: 3.374
training: epoch 74, step 4800, loss 33.388828, time: 3.378
training: epoch 74, step 5000, loss 33.387870, time: 3.376
training: epoch 74, step 5200, loss 33.357908, time: 3.376
training: epoch 74, step 5400, loss 33.323754, time: 3.375
training: epoch 74, step 5600, loss 33.299667, time: 3.378
training: epoch 74, step 5800, loss 33.255243, time: 3.378
training: epoch 74, step 6000, loss 33.257211, time: 3.374
training: epoch 74, step 6200, loss 33.258077, time: 3.375
training: epoch 74, step 6400, loss 33.251150, time: 3.373
training: epoch 74, step 6600, loss 33.241982, time: 3.373
training: epoch 74, step 6800, loss 33.249017, time: 3.373
training: epoch 74, step 7000, loss 33.250917, time: 3.376
training: epoch 74, step 7200, loss 33.271883, time: 3.374
training: epoch 74, step 7400, loss 33.274296, time: 3.373
training: epoch 74, step 7600, loss 33.275494, time: 3.371
training: epoch 74, step 7800, loss 33.269469, time: 3.376
training: epoch 74, step 7849, loss 33.280392, time: 0.827
validate: epoch 74, loss 36.134457, charcter error 6.527 time: 4.018
training: epoch 75, step 200, loss 33.181282, time: 3.333
training: epoch 75, step 400, loss 33.482706, time: 3.370
training: epoch 75, step 600, loss 33.376675, time: 3.375
training: epoch 75, step 800, loss 33.305646, time: 3.376
training: epoch 75, step 1000, loss 33.337794, time: 3.379
training: epoch 75, step 1200, loss 33.262948, time: 3.375
training: epoch 75, step 1400, loss 33.477840, time: 3.375
training: epoch 75, step 1600, loss 33.586089, time: 3.376
training: epoch 75, step 1800, loss 33.592366, time: 3.379
training: epoch 75, step 2000, loss 33.506528, time: 3.370
training: epoch 75, step 2200, loss 33.519761, time: 3.369
training: epoch 75, step 2400, loss 33.483396, time: 3.372
training: epoch 75, step 2600, loss 33.499744, time: 3.375
training: epoch 75, step 2800, loss 33.453316, time: 3.373
training: epoch 75, step 3000, loss 33.476848, time: 3.374
training: epoch 75, step 3200, loss 33.504463, time: 3.372
training: epoch 75, step 3400, loss 33.466719, time: 3.374
training: epoch 75, step 3600, loss 33.406143, time: 3.374
training: epoch 75, step 3800, loss 33.369900, time: 3.377
training: epoch 75, step 4000, loss 33.343860, time: 3.377
training: epoch 75, step 4200, loss 33.323419, time: 3.376
training: epoch 75, step 4400, loss 33.351969, time: 3.372
training: epoch 75, step 4600, loss 33.357440, time: 3.374
training: epoch 75, step 4800, loss 33.351747, time: 3.379
training: epoch 75, step 5000, loss 33.347806, time: 3.378
training: epoch 75, step 5200, loss 33.368248, time: 3.381
training: epoch 75, step 5400, loss 33.350879, time: 3.375
training: epoch 75, step 5600, loss 33.313116, time: 3.375
training: epoch 75, step 5800, loss 33.295986, time: 3.376
training: epoch 75, step 6000, loss 33.316338, time: 3.376
training: epoch 75, step 6200, loss 33.333712, time: 3.372
training: epoch 75, step 6400, loss 33.338269, time: 3.376
training: epoch 75, step 6600, loss 33.301975, time: 3.377
training: epoch 75, step 6800, loss 33.307381, time: 3.374
training: epoch 75, step 7000, loss 33.308314, time: 3.375
training: epoch 75, step 7200, loss 33.314499, time: 3.374
training: epoch 75, step 7400, loss 33.313238, time: 3.375
training: epoch 75, step 7600, loss 33.294112, time: 3.376
training: epoch 75, step 7800, loss 33.277585, time: 3.375
training: epoch 75, step 7849, loss 33.278567, time: 0.827
validate: epoch 75, loss 35.750871, charcter error 6.473 time: 4.014
training: epoch 76, step 200, loss 32.244422, time: 3.330
training: epoch 76, step 400, loss 32.448319, time: 3.372
training: epoch 76, step 600, loss 32.409014, time: 3.374
training: epoch 76, step 800, loss 32.586813, time: 3.378
training: epoch 76, step 1000, loss 32.658149, time: 3.376
training: epoch 76, step 1200, loss 32.824703, time: 3.379
training: epoch 76, step 1400, loss 32.887461, time: 3.377
training: epoch 76, step 1600, loss 32.940345, time: 3.375
training: epoch 76, step 1800, loss 33.030908, time: 3.378
training: epoch 76, step 2000, loss 33.056151, time: 3.379
training: epoch 76, step 2200, loss 33.127128, time: 3.379
training: epoch 76, step 2400, loss 33.103718, time: 3.379
training: epoch 76, step 2600, loss 33.166121, time: 3.376
training: epoch 76, step 2800, loss 33.148307, time: 3.374
training: epoch 76, step 3000, loss 33.124459, time: 3.373
training: epoch 76, step 3200, loss 33.103416, time: 3.371
training: epoch 76, step 3400, loss 33.088198, time: 3.372
training: epoch 76, step 3600, loss 33.066307, time: 3.372
training: epoch 76, step 3800, loss 33.127534, time: 3.373
training: epoch 76, step 4000, loss 33.127839, time: 3.371
training: epoch 76, step 4200, loss 33.198813, time: 3.371
training: epoch 76, step 4400, loss 33.185576, time: 3.371
training: epoch 76, step 4600, loss 33.248712, time: 3.374
training: epoch 76, step 4800, loss 33.229381, time: 3.377
training: epoch 76, step 5000, loss 33.238447, time: 3.377
training: epoch 76, step 5200, loss 33.234241, time: 3.380
training: epoch 76, step 5400, loss 33.224675, time: 3.378
training: epoch 76, step 5600, loss 33.212043, time: 3.378
training: epoch 76, step 5800, loss 33.208152, time: 3.379
training: epoch 76, step 6000, loss 33.233530, time: 3.374
training: epoch 76, step 6200, loss 33.222675, time: 3.377
training: epoch 76, step 6400, loss 33.234993, time: 3.374
training: epoch 76, step 6600, loss 33.230905, time: 3.377
training: epoch 76, step 6800, loss 33.232215, time: 3.374
training: epoch 76, step 7000, loss 33.231616, time: 3.374
training: epoch 76, step 7200, loss 33.211914, time: 3.374
training: epoch 76, step 7400, loss 33.212502, time: 3.378
training: epoch 76, step 7600, loss 33.216338, time: 3.375
training: epoch 76, step 7800, loss 33.275096, time: 3.372
training: epoch 76, step 7849, loss 33.292152, time: 0.827
validate: epoch 76, loss 36.932677, charcter error 6.662 time: 4.019
training: epoch 77, step 200, loss 34.223212, time: 3.328
training: epoch 77, step 400, loss 33.840301, time: 3.363
training: epoch 77, step 600, loss 33.461914, time: 3.375
training: epoch 77, step 800, loss 33.236856, time: 3.378
training: epoch 77, step 1000, loss 33.346459, time: 3.375
training: epoch 77, step 1200, loss 33.206310, time: 3.410
training: epoch 77, step 1400, loss 33.123813, time: 3.445
training: epoch 77, step 1600, loss 33.019460, time: 3.505
training: epoch 77, step 1800, loss 32.942438, time: 3.537
training: epoch 77, step 2000, loss 32.956417, time: 3.506
training: epoch 77, step 2200, loss 32.951273, time: 3.504
training: epoch 77, step 2400, loss 32.873325, time: 3.516
training: epoch 77, step 2600, loss 32.944762, time: 3.509
training: epoch 77, step 2800, loss 33.010863, time: 3.498
training: epoch 77, step 3000, loss 33.002912, time: 3.498
training: epoch 77, step 3200, loss 32.987228, time: 3.478
training: epoch 77, step 3400, loss 32.998927, time: 3.520
training: epoch 77, step 3600, loss 33.010748, time: 3.552
training: epoch 77, step 3800, loss 33.021775, time: 3.474
training: epoch 77, step 4000, loss 33.055575, time: 3.430
training: epoch 77, step 4200, loss 33.055862, time: 3.419
training: epoch 77, step 4400, loss 33.021851, time: 3.416
training: epoch 77, step 4600, loss 32.998147, time: 3.396
training: epoch 77, step 4800, loss 33.008448, time: 3.400
training: epoch 77, step 5000, loss 32.976716, time: 3.388
training: epoch 77, step 5200, loss 32.957957, time: 3.384
training: epoch 77, step 5400, loss 33.000645, time: 3.385
training: epoch 77, step 5600, loss 32.994435, time: 3.387
training: epoch 77, step 5800, loss 33.034220, time: 3.383
training: epoch 77, step 6000, loss 33.046219, time: 3.382
training: epoch 77, step 6200, loss 33.053445, time: 3.379
training: epoch 77, step 6400, loss 33.081386, time: 3.379
training: epoch 77, step 6600, loss 33.076557, time: 3.375
training: epoch 77, step 6800, loss 33.104243, time: 3.379
training: epoch 77, step 7000, loss 33.130613, time: 3.377
training: epoch 77, step 7200, loss 33.129174, time: 3.375
training: epoch 77, step 7400, loss 33.112961, time: 3.377
training: epoch 77, step 7600, loss 33.141635, time: 3.379
training: epoch 77, step 7800, loss 33.141374, time: 3.375
training: epoch 77, step 7849, loss 33.147894, time: 0.828
validate: epoch 77, loss 35.616848, charcter error 6.446 time: 4.045
    - [Info] The checkpoint file has been updated.
training: epoch 78, step 200, loss 32.057638, time: 3.751
training: epoch 78, step 400, loss 32.350712, time: 3.714
training: epoch 78, step 600, loss 32.412089, time: 3.590
training: epoch 78, step 800, loss 32.584160, time: 3.584
training: epoch 78, step 1000, loss 32.670521, time: 3.578
training: epoch 78, step 1200, loss 32.719493, time: 3.618
training: epoch 78, step 1400, loss 32.660754, time: 3.585
training: epoch 78, step 1600, loss 32.755905, time: 3.574
training: epoch 78, step 1800, loss 32.785401, time: 3.567
training: epoch 78, step 2000, loss 32.867867, time: 3.498
training: epoch 78, step 2200, loss 32.925947, time: 3.478
training: epoch 78, step 2400, loss 32.934663, time: 3.435
training: epoch 78, step 2600, loss 32.850341, time: 3.418
training: epoch 78, step 2800, loss 32.929992, time: 3.408
training: epoch 78, step 3000, loss 33.046107, time: 3.396
training: epoch 78, step 3200, loss 33.077486, time: 3.385
training: epoch 78, step 3400, loss 33.065130, time: 3.385
training: epoch 78, step 3600, loss 33.039717, time: 3.379
training: epoch 78, step 3800, loss 33.056926, time: 3.380
training: epoch 78, step 4000, loss 33.121615, time: 3.398
training: epoch 78, step 4200, loss 33.160553, time: 3.423
training: epoch 78, step 4400, loss 33.187398, time: 3.383
training: epoch 78, step 4600, loss 33.174482, time: 3.398
training: epoch 78, step 4800, loss 33.210292, time: 3.442
training: epoch 78, step 5000, loss 33.184163, time: 3.474
training: epoch 78, step 5200, loss 33.163213, time: 3.461
training: epoch 78, step 5400, loss 33.129768, time: 3.472
training: epoch 78, step 5600, loss 33.149204, time: 3.467
training: epoch 78, step 5800, loss 33.184418, time: 3.531
training: epoch 78, step 6000, loss 33.197997, time: 3.494
training: epoch 78, step 6200, loss 33.212431, time: 3.466
training: epoch 78, step 6400, loss 33.225825, time: 3.486
training: epoch 78, step 6600, loss 33.226840, time: 3.524
training: epoch 78, step 6800, loss 33.225777, time: 3.574
training: epoch 78, step 7000, loss 33.235420, time: 3.640
training: epoch 78, step 7200, loss 33.232665, time: 3.546
training: epoch 78, step 7400, loss 33.220770, time: 3.576
training: epoch 78, step 7600, loss 33.256126, time: 3.644
training: epoch 78, step 7800, loss 33.261046, time: 3.551
training: epoch 78, step 7849, loss 33.258565, time: 0.888
validate: epoch 78, loss 36.128175, charcter error 6.499 time: 4.040
training: epoch 79, step 200, loss 32.295498, time: 3.628
training: epoch 79, step 400, loss 32.690133, time: 3.577
training: epoch 79, step 600, loss 32.807856, time: 3.608
training: epoch 79, step 800, loss 33.114040, time: 3.614
training: epoch 79, step 1000, loss 33.067332, time: 3.443
training: epoch 79, step 1200, loss 32.946645, time: 3.378
training: epoch 79, step 1400, loss 32.888739, time: 3.404
training: epoch 79, step 1600, loss 32.975153, time: 3.520
training: epoch 79, step 1800, loss 32.891735, time: 3.476
training: epoch 79, step 2000, loss 32.864993, time: 3.489
training: epoch 79, step 2200, loss 32.873723, time: 3.472
training: epoch 79, step 2400, loss 33.069174, time: 3.515
training: epoch 79, step 2600, loss 33.146293, time: 3.475
training: epoch 79, step 2800, loss 33.262647, time: 3.454
training: epoch 79, step 3000, loss 33.343040, time: 3.470
training: epoch 79, step 3200, loss 33.354627, time: 3.445
training: epoch 79, step 3400, loss 33.360681, time: 3.450
training: epoch 79, step 3600, loss 33.322640, time: 3.445
training: epoch 79, step 3800, loss 33.266336, time: 3.445
training: epoch 79, step 4000, loss 33.240411, time: 3.451
training: epoch 79, step 4200, loss 33.227321, time: 3.463
training: epoch 79, step 4400, loss 33.252584, time: 3.443
training: epoch 79, step 4600, loss 33.247719, time: 3.425
training: epoch 79, step 4800, loss 33.239447, time: 3.429
training: epoch 79, step 5000, loss 33.186187, time: 3.437
training: epoch 79, step 5200, loss 33.167171, time: 3.432
training: epoch 79, step 5400, loss 33.149759, time: 3.445
training: epoch 79, step 5600, loss 33.163489, time: 3.444
training: epoch 79, step 5800, loss 33.174925, time: 3.465
training: epoch 79, step 6000, loss 33.161502, time: 3.437
training: epoch 79, step 6200, loss 33.146539, time: 3.449
training: epoch 79, step 6400, loss 33.153739, time: 3.472
training: epoch 79, step 6600, loss 33.126298, time: 3.484
training: epoch 79, step 6800, loss 33.139117, time: 3.437
training: epoch 79, step 7000, loss 33.122333, time: 3.436
training: epoch 79, step 7200, loss 33.105378, time: 3.447
training: epoch 79, step 7400, loss 33.115131, time: 3.508
training: epoch 79, step 7600, loss 33.119931, time: 3.426
training: epoch 79, step 7800, loss 33.117904, time: 3.424
training: epoch 79, step 7849, loss 33.124697, time: 0.837
validate: epoch 79, loss 36.055089, charcter error 6.514 time: 4.035
training: epoch 80, step 200, loss 32.984102, time: 3.362
training: epoch 80, step 400, loss 32.932091, time: 3.390
training: epoch 80, step 600, loss 32.840770, time: 3.388
training: epoch 80, step 800, loss 33.059027, time: 3.383
training: epoch 80, step 1000, loss 33.209635, time: 3.378
training: epoch 80, step 1200, loss 33.079715, time: 3.381
training: epoch 80, step 1400, loss 32.992891, time: 3.381
training: epoch 80, step 1600, loss 32.971277, time: 3.379
training: epoch 80, step 1800, loss 32.922532, time: 3.376
training: epoch 80, step 2000, loss 32.933109, time: 3.376
training: epoch 80, step 2200, loss 32.920652, time: 3.377
training: epoch 80, step 2400, loss 32.918669, time: 3.379
training: epoch 80, step 2600, loss 33.057371, time: 3.377
training: epoch 80, step 2800, loss 33.062537, time: 3.380
training: epoch 80, step 3000, loss 33.015167, time: 3.378
training: epoch 80, step 3200, loss 32.976625, time: 3.379
training: epoch 80, step 3400, loss 32.977781, time: 3.374
training: epoch 80, step 3600, loss 32.979156, time: 3.378
training: epoch 80, step 3800, loss 32.948435, time: 3.375
training: epoch 80, step 4000, loss 32.946792, time: 3.372
training: epoch 80, step 4200, loss 33.018052, time: 3.377
training: epoch 80, step 4400, loss 33.047106, time: 3.380
training: epoch 80, step 4600, loss 33.047666, time: 3.378
training: epoch 80, step 4800, loss 33.042286, time: 3.382
training: epoch 80, step 5000, loss 33.048226, time: 3.381
training: epoch 80, step 5200, loss 33.083492, time: 3.378
training: epoch 80, step 5400, loss 33.109851, time: 3.380
training: epoch 80, step 5600, loss 33.092583, time: 3.381
training: epoch 80, step 5800, loss 33.091819, time: 3.380
training: epoch 80, step 6000, loss 33.121592, time: 3.381
training: epoch 80, step 6200, loss 33.109411, time: 3.381
training: epoch 80, step 6400, loss 33.038149, time: 3.381
training: epoch 80, step 6600, loss 33.072234, time: 3.383
training: epoch 80, step 6800, loss 33.133503, time: 3.383
training: epoch 80, step 7000, loss 33.141844, time: 3.381
training: epoch 80, step 7200, loss 33.128819, time: 3.379
training: epoch 80, step 7400, loss 33.122853, time: 3.378
training: epoch 80, step 7600, loss 33.124205, time: 3.378
training: epoch 80, step 7800, loss 33.123249, time: 3.381
training: epoch 80, step 7849, loss 33.132620, time: 0.830
validate: epoch 80, loss 35.773316, charcter error 6.467 time: 4.015
training: epoch 81, step 200, loss 33.098168, time: 3.333
training: epoch 81, step 400, loss 33.098775, time: 3.370
training: epoch 81, step 600, loss 33.229224, time: 3.378
training: epoch 81, step 800, loss 32.939370, time: 3.380
training: epoch 81, step 1000, loss 33.039288, time: 3.381
training: epoch 81, step 1200, loss 33.139264, time: 3.381
training: epoch 81, step 1400, loss 33.252510, time: 3.381
training: epoch 81, step 1600, loss 33.339181, time: 3.381
training: epoch 81, step 1800, loss 33.209139, time: 3.380
training: epoch 81, step 2000, loss 33.186585, time: 3.378
training: epoch 81, step 2200, loss 33.097019, time: 3.375
training: epoch 81, step 2400, loss 33.204029, time: 3.378
training: epoch 81, step 2600, loss 33.148000, time: 3.377
training: epoch 81, step 2800, loss 33.032860, time: 3.376
training: epoch 81, step 3000, loss 32.972365, time: 3.376
training: epoch 81, step 3200, loss 33.013405, time: 3.376
training: epoch 81, step 3400, loss 33.069928, time: 3.375
training: epoch 81, step 3600, loss 33.040692, time: 3.376
training: epoch 81, step 3800, loss 33.046935, time: 3.377
training: epoch 81, step 4000, loss 33.014690, time: 3.374
training: epoch 81, step 4200, loss 33.016055, time: 3.375
training: epoch 81, step 4400, loss 33.025608, time: 3.379
training: epoch 81, step 4600, loss 33.061177, time: 3.376
training: epoch 81, step 4800, loss 33.067984, time: 3.378
training: epoch 81, step 5000, loss 33.091838, time: 3.381
training: epoch 81, step 5200, loss 33.089645, time: 3.377
training: epoch 81, step 5400, loss 33.089550, time: 3.375
training: epoch 81, step 5600, loss 33.124937, time: 3.378
training: epoch 81, step 5800, loss 33.166209, time: 3.378
training: epoch 81, step 6000, loss 33.162298, time: 3.378
training: epoch 81, step 6200, loss 33.161453, time: 3.381
training: epoch 81, step 6400, loss 33.164817, time: 3.382
training: epoch 81, step 6600, loss 33.178422, time: 3.381
training: epoch 81, step 6800, loss 33.200337, time: 3.382
training: epoch 81, step 7000, loss 33.179793, time: 3.381
training: epoch 81, step 7200, loss 33.183385, time: 3.380
training: epoch 81, step 7400, loss 33.197042, time: 3.380
training: epoch 81, step 7600, loss 33.187761, time: 3.381
training: epoch 81, step 7800, loss 33.186848, time: 3.383
training: epoch 81, step 7849, loss 33.160590, time: 0.827
validate: epoch 81, loss 35.747603, charcter error 6.483 time: 4.010
training: epoch 82, step 200, loss 32.657774, time: 3.331
training: epoch 82, step 400, loss 32.313881, time: 3.367
training: epoch 82, step 600, loss 32.290026, time: 3.376
training: epoch 82, step 800, loss 32.466403, time: 3.377
training: epoch 82, step 1000, loss 32.725112, time: 3.377
training: epoch 82, step 1200, loss 32.878818, time: 3.375
training: epoch 82, step 1400, loss 32.970282, time: 3.379
training: epoch 82, step 1600, loss 32.961957, time: 3.380
training: epoch 82, step 1800, loss 32.943519, time: 3.379
training: epoch 82, step 2000, loss 32.809601, time: 3.379
training: epoch 82, step 2200, loss 32.798954, time: 3.378
training: epoch 82, step 2400, loss 32.931806, time: 3.379
training: epoch 82, step 2600, loss 32.916220, time: 3.380
training: epoch 82, step 2800, loss 32.968746, time: 3.380
training: epoch 82, step 3000, loss 32.909450, time: 3.378
training: epoch 82, step 3200, loss 32.943569, time: 3.378
training: epoch 82, step 3400, loss 32.952309, time: 3.374
training: epoch 82, step 3600, loss 32.993944, time: 3.373
training: epoch 82, step 3800, loss 32.992944, time: 3.379
training: epoch 82, step 4000, loss 32.988615, time: 3.379
training: epoch 82, step 4200, loss 32.987160, time: 3.377
training: epoch 82, step 4400, loss 32.957653, time: 3.378
training: epoch 82, step 4600, loss 33.016440, time: 3.384
training: epoch 82, step 4800, loss 33.044234, time: 3.382
training: epoch 82, step 5000, loss 33.024859, time: 3.380
training: epoch 82, step 5200, loss 32.999452, time: 3.379
training: epoch 82, step 5400, loss 33.011983, time: 3.381
training: epoch 82, step 5600, loss 33.057459, time: 3.382
training: epoch 82, step 5800, loss 33.013023, time: 3.378
training: epoch 82, step 6000, loss 32.984860, time: 3.379
training: epoch 82, step 6200, loss 32.971032, time: 3.383
training: epoch 82, step 6400, loss 32.979129, time: 3.384
training: epoch 82, step 6600, loss 33.070402, time: 3.382
training: epoch 82, step 6800, loss 33.151993, time: 3.376
training: epoch 82, step 7000, loss 33.213282, time: 3.381
training: epoch 82, step 7200, loss 33.262723, time: 3.385
training: epoch 82, step 7400, loss 33.256059, time: 3.381
training: epoch 82, step 7600, loss 33.291405, time: 3.381
training: epoch 82, step 7800, loss 33.299494, time: 3.378
training: epoch 82, step 7849, loss 33.307722, time: 0.828
validate: epoch 82, loss 36.305403, charcter error 6.571 time: 4.015
training: epoch 83, step 200, loss 33.154018, time: 3.338
training: epoch 83, step 400, loss 33.123611, time: 3.381
training: epoch 83, step 600, loss 32.957007, time: 3.387
training: epoch 83, step 800, loss 32.798702, time: 3.388
training: epoch 83, step 1000, loss 32.918598, time: 3.386
training: epoch 83, step 1200, loss 33.164433, time: 3.377
training: epoch 83, step 1400, loss 33.041603, time: 3.376
training: epoch 83, step 1600, loss 33.156495, time: 3.376
training: epoch 83, step 1800, loss 33.170917, time: 3.381
training: epoch 83, step 2000, loss 33.128538, time: 3.382
training: epoch 83, step 2200, loss 33.136656, time: 3.385
training: epoch 83, step 2400, loss 33.156126, time: 3.383
training: epoch 83, step 2600, loss 33.146015, time: 3.381
training: epoch 83, step 2800, loss 33.142804, time: 3.386
training: epoch 83, step 3000, loss 33.109219, time: 3.384
training: epoch 83, step 3200, loss 33.143495, time: 3.382
training: epoch 83, step 3400, loss 33.162492, time: 3.389
training: epoch 83, step 3600, loss 33.196832, time: 3.384
training: epoch 83, step 3800, loss 33.208301, time: 3.382
training: epoch 83, step 4000, loss 33.166170, time: 3.382
training: epoch 83, step 4200, loss 33.145494, time: 3.386
training: epoch 83, step 4400, loss 33.148590, time: 3.383
training: epoch 83, step 4600, loss 33.142867, time: 3.382
training: epoch 83, step 4800, loss 33.131796, time: 3.384
training: epoch 83, step 5000, loss 33.157624, time: 3.379
training: epoch 83, step 5200, loss 33.136045, time: 3.380
training: epoch 83, step 5400, loss 33.132367, time: 3.380
training: epoch 83, step 5600, loss 33.111958, time: 3.379
training: epoch 83, step 5800, loss 33.099567, time: 3.385
training: epoch 83, step 6000, loss 33.084376, time: 3.380
training: epoch 83, step 6200, loss 33.062301, time: 3.381
training: epoch 83, step 6400, loss 33.055868, time: 3.384
training: epoch 83, step 6600, loss 33.072321, time: 3.385
training: epoch 83, step 6800, loss 33.068075, time: 3.388
training: epoch 83, step 7000, loss 33.071882, time: 3.381
training: epoch 83, step 7200, loss 33.062092, time: 3.380
training: epoch 83, step 7400, loss 33.072625, time: 3.386
training: epoch 83, step 7600, loss 33.068561, time: 3.386
training: epoch 83, step 7800, loss 33.064333, time: 3.387
training: epoch 83, step 7849, loss 33.062010, time: 0.828
validate: epoch 83, loss 36.021981, charcter error 6.518 time: 4.016
training: epoch 84, step 200, loss 32.749864, time: 3.339
training: epoch 84, step 400, loss 33.105434, time: 3.376
training: epoch 84, step 600, loss 33.108146, time: 3.386
training: epoch 84, step 800, loss 32.886797, time: 3.382
training: epoch 84, step 1000, loss 32.739884, time: 3.378
training: epoch 84, step 1200, loss 32.787872, time: 3.379
training: epoch 84, step 1400, loss 33.015074, time: 3.386
training: epoch 84, step 1600, loss 33.122168, time: 3.385
training: epoch 84, step 1800, loss 33.065575, time: 3.378
training: epoch 84, step 2000, loss 32.991599, time: 3.383
training: epoch 84, step 2200, loss 33.085988, time: 3.386
training: epoch 84, step 2400, loss 33.026266, time: 3.386
training: epoch 84, step 2600, loss 33.017643, time: 3.382
training: epoch 84, step 2800, loss 32.942168, time: 3.388
training: epoch 84, step 3000, loss 32.950790, time: 3.389
training: epoch 84, step 3200, loss 32.950440, time: 3.390
training: epoch 84, step 3400, loss 32.954018, time: 3.390
training: epoch 84, step 3600, loss 32.994702, time: 3.385
training: epoch 84, step 3800, loss 32.977353, time: 3.382
training: epoch 84, step 4000, loss 32.937112, time: 3.383
training: epoch 84, step 4200, loss 32.961898, time: 3.376
training: epoch 84, step 4400, loss 32.969508, time: 3.378
training: epoch 84, step 4600, loss 32.960850, time: 3.382
training: epoch 84, step 4800, loss 32.947499, time: 3.387
training: epoch 84, step 5000, loss 32.917746, time: 3.384
training: epoch 84, step 5200, loss 32.889010, time: 3.387
training: epoch 84, step 5400, loss 32.848351, time: 3.383
training: epoch 84, step 5600, loss 32.836007, time: 3.383
training: epoch 84, step 5800, loss 32.863170, time: 3.381
training: epoch 84, step 6000, loss 32.873403, time: 3.379
training: epoch 84, step 6200, loss 32.868821, time: 3.377
training: epoch 84, step 6400, loss 32.924449, time: 3.378
training: epoch 84, step 6600, loss 32.965322, time: 3.379
training: epoch 84, step 6800, loss 33.010452, time: 3.388
training: epoch 84, step 7000, loss 33.015590, time: 3.385
training: epoch 84, step 7200, loss 33.039127, time: 3.390
training: epoch 84, step 7400, loss 33.047552, time: 3.384
training: epoch 84, step 7600, loss 33.060308, time: 3.386
training: epoch 84, step 7800, loss 33.048380, time: 3.381
training: epoch 84, step 7849, loss 33.036931, time: 0.833
validate: epoch 84, loss 36.006044, charcter error 6.503 time: 4.017
training: epoch 85, step 200, loss 33.486514, time: 3.340
training: epoch 85, step 400, loss 32.991280, time: 3.375
training: epoch 85, step 600, loss 33.414324, time: 3.377
training: epoch 85, step 800, loss 33.283471, time: 3.378
training: epoch 85, step 1000, loss 33.087767, time: 3.383
training: epoch 85, step 1200, loss 32.952822, time: 3.385
training: epoch 85, step 1400, loss 32.976022, time: 3.391
training: epoch 85, step 1600, loss 32.846566, time: 3.392
training: epoch 85, step 1800, loss 32.889309, time: 3.389
training: epoch 85, step 2000, loss 32.926773, time: 3.386
training: epoch 85, step 2200, loss 32.878889, time: 3.380
training: epoch 85, step 2400, loss 32.903398, time: 3.380
training: epoch 85, step 2600, loss 32.972889, time: 3.380
training: epoch 85, step 2800, loss 32.908235, time: 3.381
training: epoch 85, step 3000, loss 32.878902, time: 3.385
training: epoch 85, step 3200, loss 32.919396, time: 3.381
training: epoch 85, step 3400, loss 32.971695, time: 3.386
training: epoch 85, step 3600, loss 32.985801, time: 3.377
training: epoch 85, step 3800, loss 32.946682, time: 3.381
training: epoch 85, step 4000, loss 32.911664, time: 3.384
training: epoch 85, step 4200, loss 32.855007, time: 3.381
training: epoch 85, step 4400, loss 32.833625, time: 3.381
training: epoch 85, step 4600, loss 32.826867, time: 3.378
training: epoch 85, step 4800, loss 32.832370, time: 3.379
training: epoch 85, step 5000, loss 32.850478, time: 3.379
training: epoch 85, step 5200, loss 32.864476, time: 3.377
training: epoch 85, step 5400, loss 32.855846, time: 3.381
training: epoch 85, step 5600, loss 32.860569, time: 3.379
training: epoch 85, step 5800, loss 32.846964, time: 3.378
training: epoch 85, step 6000, loss 32.870772, time: 3.380
training: epoch 85, step 6200, loss 32.849058, time: 3.378
training: epoch 85, step 6400, loss 32.829038, time: 3.375
training: epoch 85, step 6600, loss 32.846083, time: 3.377
training: epoch 85, step 6800, loss 32.836572, time: 3.379
training: epoch 85, step 7000, loss 32.836265, time: 3.375
training: epoch 85, step 7200, loss 32.819283, time: 3.374
training: epoch 85, step 7400, loss 32.835609, time: 3.382
training: epoch 85, step 7600, loss 32.856201, time: 3.377
training: epoch 85, step 7800, loss 32.843968, time: 3.377
training: epoch 85, step 7849, loss 32.842483, time: 0.827
validate: epoch 85, loss 35.701941, charcter error 6.456 time: 4.022
training: epoch 86, step 200, loss 33.106869, time: 3.333
training: epoch 86, step 400, loss 33.156083, time: 3.366
training: epoch 86, step 600, loss 33.164117, time: 3.368
training: epoch 86, step 800, loss 32.917111, time: 3.370
training: epoch 86, step 1000, loss 32.920843, time: 3.377
training: epoch 86, step 1200, loss 32.867391, time: 3.371
training: epoch 86, step 1400, loss 33.008179, time: 3.372
training: epoch 86, step 1600, loss 33.138294, time: 3.377
training: epoch 86, step 1800, loss 33.137877, time: 3.374
training: epoch 86, step 2000, loss 33.135964, time: 3.370
training: epoch 86, step 2200, loss 33.056052, time: 3.369
training: epoch 86, step 2400, loss 33.045875, time: 3.370
training: epoch 86, step 2600, loss 32.996822, time: 3.374
training: epoch 86, step 2800, loss 32.988263, time: 3.373
training: epoch 86, step 3000, loss 32.999043, time: 3.371
training: epoch 86, step 3200, loss 33.040131, time: 3.374
training: epoch 86, step 3400, loss 33.014497, time: 3.375
training: epoch 86, step 3600, loss 33.003121, time: 3.377
training: epoch 86, step 3800, loss 32.992288, time: 3.372
training: epoch 86, step 4000, loss 33.024032, time: 3.375
training: epoch 86, step 4200, loss 33.046855, time: 3.371
training: epoch 86, step 4400, loss 33.050202, time: 3.372
training: epoch 86, step 4600, loss 33.029812, time: 3.373
training: epoch 86, step 4800, loss 32.982964, time: 3.372
training: epoch 86, step 5000, loss 32.916477, time: 3.375
training: epoch 86, step 5200, loss 32.944264, time: 3.373
training: epoch 86, step 5400, loss 32.930763, time: 3.372
training: epoch 86, step 5600, loss 32.927914, time: 3.377
training: epoch 86, step 5800, loss 32.919895, time: 3.369
training: epoch 86, step 6000, loss 32.898041, time: 3.370
training: epoch 86, step 6200, loss 32.897475, time: 3.371
training: epoch 86, step 6400, loss 32.882191, time: 3.371
training: epoch 86, step 6600, loss 32.901625, time: 3.372
training: epoch 86, step 6800, loss 32.865515, time: 3.375
training: epoch 86, step 7000, loss 32.873441, time: 3.373
training: epoch 86, step 7200, loss 32.904154, time: 3.376
training: epoch 86, step 7400, loss 32.920150, time: 3.374
training: epoch 86, step 7600, loss 32.946631, time: 3.375
training: epoch 86, step 7800, loss 32.953155, time: 3.379
training: epoch 86, step 7849, loss 32.958270, time: 0.828
validate: epoch 86, loss 35.681516, charcter error 6.443 time: 4.019
    - [Info] The checkpoint file has been updated.
training: epoch 87, step 200, loss 32.736150, time: 3.342
training: epoch 87, step 400, loss 32.768927, time: 3.371
training: epoch 87, step 600, loss 32.784552, time: 3.377
training: epoch 87, step 800, loss 32.644411, time: 3.380
training: epoch 87, step 1000, loss 32.663102, time: 3.373
training: epoch 87, step 1200, loss 32.635531, time: 3.373
training: epoch 87, step 1400, loss 32.557609, time: 3.376
training: epoch 87, step 1600, loss 32.543855, time: 3.380
training: epoch 87, step 1800, loss 32.564682, time: 3.381
training: epoch 87, step 2000, loss 32.516280, time: 3.380
training: epoch 87, step 2200, loss 32.444615, time: 3.376
training: epoch 87, step 2400, loss 32.449874, time: 3.378
training: epoch 87, step 2600, loss 32.481827, time: 3.382
training: epoch 87, step 2800, loss 32.601751, time: 3.381
training: epoch 87, step 3000, loss 32.630154, time: 3.377
training: epoch 87, step 3200, loss 32.710284, time: 3.377
training: epoch 87, step 3400, loss 32.656968, time: 3.383
training: epoch 87, step 3600, loss 32.692359, time: 3.382
training: epoch 87, step 3800, loss 32.671929, time: 3.379
training: epoch 87, step 4000, loss 32.690422, time: 3.379
training: epoch 87, step 4200, loss 32.649845, time: 3.384
training: epoch 87, step 4400, loss 32.657299, time: 3.377
training: epoch 87, step 4600, loss 32.700096, time: 3.380
training: epoch 87, step 4800, loss 32.732046, time: 3.379
training: epoch 87, step 5000, loss 32.765798, time: 3.490
training: epoch 87, step 5200, loss 32.738646, time: 3.507
training: epoch 87, step 5400, loss 32.745102, time: 3.505
training: epoch 87, step 5600, loss 32.753753, time: 3.519
training: epoch 87, step 5800, loss 32.793255, time: 3.512
training: epoch 87, step 6000, loss 32.814281, time: 3.512
training: epoch 87, step 6200, loss 32.794060, time: 3.534
training: epoch 87, step 6400, loss 32.816565, time: 3.517
training: epoch 87, step 6600, loss 32.794641, time: 3.492
training: epoch 87, step 6800, loss 32.846310, time: 3.531
training: epoch 87, step 7000, loss 32.893269, time: 3.516
training: epoch 87, step 7200, loss 32.885762, time: 3.512
training: epoch 87, step 7400, loss 32.917431, time: 3.605
training: epoch 87, step 7600, loss 32.889144, time: 3.524
training: epoch 87, step 7800, loss 32.880230, time: 3.482
training: epoch 87, step 7849, loss 32.893718, time: 0.858
validate: epoch 87, loss 36.516289, charcter error 6.600 time: 4.033
training: epoch 88, step 200, loss 34.945832, time: 3.467
training: epoch 88, step 400, loss 33.413391, time: 3.476
training: epoch 88, step 600, loss 33.039145, time: 3.475
training: epoch 88, step 800, loss 33.370930, time: 3.479
training: epoch 88, step 1000, loss 33.304609, time: 3.468
training: epoch 88, step 1200, loss 33.050129, time: 3.460
training: epoch 88, step 1400, loss 33.115370, time: 3.446
training: epoch 88, step 1600, loss 33.134284, time: 3.447
training: epoch 88, step 1800, loss 33.103830, time: 3.419
training: epoch 88, step 2000, loss 33.118010, time: 3.435
training: epoch 88, step 2200, loss 33.112651, time: 3.427
training: epoch 88, step 2400, loss 33.078523, time: 3.408
training: epoch 88, step 2600, loss 33.097859, time: 3.422
training: epoch 88, step 2800, loss 33.117970, time: 3.411
training: epoch 88, step 3000, loss 33.101965, time: 3.408
training: epoch 88, step 3200, loss 33.011990, time: 3.410
training: epoch 88, step 3400, loss 33.010094, time: 3.396
training: epoch 88, step 3600, loss 32.990328, time: 3.400
training: epoch 88, step 3800, loss 32.951354, time: 3.397
training: epoch 88, step 4000, loss 32.943291, time: 3.395
training: epoch 88, step 4200, loss 32.915279, time: 3.390
training: epoch 88, step 4400, loss 32.855101, time: 3.383
training: epoch 88, step 4600, loss 32.826777, time: 3.389
training: epoch 88, step 4800, loss 32.836402, time: 3.386
training: epoch 88, step 5000, loss 32.804120, time: 3.389
training: epoch 88, step 5200, loss 32.794325, time: 3.383
training: epoch 88, step 5400, loss 32.822186, time: 3.379
training: epoch 88, step 5600, loss 32.831205, time: 3.378
training: epoch 88, step 5800, loss 32.844410, time: 3.383
training: epoch 88, step 6000, loss 32.856108, time: 3.384
training: epoch 88, step 6200, loss 32.888757, time: 3.382
training: epoch 88, step 6400, loss 32.913771, time: 3.374
training: epoch 88, step 6600, loss 32.909360, time: 3.383
training: epoch 88, step 6800, loss 32.902570, time: 3.383
training: epoch 88, step 7000, loss 32.879369, time: 3.383
training: epoch 88, step 7200, loss 32.840292, time: 3.375
training: epoch 88, step 7400, loss 32.822140, time: 3.380
training: epoch 88, step 7600, loss 32.842456, time: 3.377
training: epoch 88, step 7800, loss 32.838632, time: 3.381
training: epoch 88, step 7849, loss 32.847985, time: 0.829
validate: epoch 88, loss 35.788861, charcter error 6.492 time: 4.016
training: epoch 89, step 200, loss 33.219204, time: 3.340
training: epoch 89, step 400, loss 32.725513, time: 3.438
training: epoch 89, step 600, loss 32.699377, time: 3.527
training: epoch 89, step 800, loss 32.697841, time: 3.503
training: epoch 89, step 1000, loss 32.589732, time: 3.500
training: epoch 89, step 1200, loss 32.608446, time: 3.495
training: epoch 89, step 1400, loss 32.559490, time: 3.515
training: epoch 89, step 1600, loss 32.659340, time: 3.480
training: epoch 89, step 1800, loss 32.665651, time: 3.491
training: epoch 89, step 2000, loss 32.697789, time: 3.468
training: epoch 89, step 2200, loss 32.583602, time: 3.472
training: epoch 89, step 2400, loss 32.595816, time: 3.491
training: epoch 89, step 2600, loss 32.650212, time: 3.516
training: epoch 89, step 2800, loss 32.758805, time: 3.503
training: epoch 89, step 3000, loss 32.858487, time: 3.494
training: epoch 89, step 3200, loss 32.855274, time: 3.493
training: epoch 89, step 3400, loss 32.884935, time: 3.504
training: epoch 89, step 3600, loss 32.875314, time: 3.526
training: epoch 89, step 3800, loss 32.861976, time: 3.373
training: epoch 89, step 4000, loss 32.845349, time: 3.377
training: epoch 89, step 4200, loss 32.855440, time: 3.379
training: epoch 89, step 4400, loss 32.816512, time: 3.375
training: epoch 89, step 4600, loss 32.855200, time: 3.424
training: epoch 89, step 4800, loss 32.841072, time: 3.571
training: epoch 89, step 5000, loss 32.804926, time: 3.521
training: epoch 89, step 5200, loss 32.821969, time: 3.484
training: epoch 89, step 5400, loss 32.873726, time: 3.481
training: epoch 89, step 5600, loss 32.881383, time: 3.472
training: epoch 89, step 5800, loss 32.874315, time: 3.457
training: epoch 89, step 6000, loss 32.876244, time: 3.464
training: epoch 89, step 6200, loss 32.835318, time: 3.459
training: epoch 89, step 6400, loss 32.823638, time: 3.487
training: epoch 89, step 6600, loss 32.814869, time: 3.483
training: epoch 89, step 6800, loss 32.816399, time: 3.492
training: epoch 89, step 7000, loss 32.817177, time: 3.502
training: epoch 89, step 7200, loss 32.798814, time: 3.468
training: epoch 89, step 7400, loss 32.818614, time: 3.458
training: epoch 89, step 7600, loss 32.797098, time: 3.462
training: epoch 89, step 7800, loss 32.805262, time: 3.469
training: epoch 89, step 7849, loss 32.812527, time: 0.855
validate: epoch 89, loss 35.836290, charcter error 6.475 time: 4.041
training: epoch 90, step 200, loss 33.222850, time: 3.410
training: epoch 90, step 400, loss 32.873781, time: 3.448
training: epoch 90, step 600, loss 32.516746, time: 3.466
training: epoch 90, step 800, loss 32.777602, time: 3.649
training: epoch 90, step 1000, loss 32.501882, time: 3.544
training: epoch 90, step 1200, loss 32.414705, time: 3.515
training: epoch 90, step 1400, loss 32.518330, time: 3.505
training: epoch 90, step 1600, loss 32.384592, time: 3.501
training: epoch 90, step 1800, loss 32.513256, time: 3.479
training: epoch 90, step 2000, loss 32.534222, time: 3.464
training: epoch 90, step 2200, loss 32.486977, time: 3.489
training: epoch 90, step 2400, loss 32.514272, time: 3.493
training: epoch 90, step 2600, loss 32.623520, time: 3.496
training: epoch 90, step 2800, loss 32.602312, time: 3.489
training: epoch 90, step 3000, loss 32.615822, time: 3.500
training: epoch 90, step 3200, loss 32.699471, time: 3.476
training: epoch 90, step 3400, loss 32.688760, time: 3.466
training: epoch 90, step 3600, loss 32.724493, time: 3.458
training: epoch 90, step 3800, loss 32.737047, time: 3.430
training: epoch 90, step 4000, loss 32.769284, time: 3.443
training: epoch 90, step 4200, loss 32.813848, time: 3.437
training: epoch 90, step 4400, loss 32.846354, time: 3.417
training: epoch 90, step 4600, loss 32.821755, time: 3.416
training: epoch 90, step 4800, loss 32.774610, time: 3.427
training: epoch 90, step 5000, loss 32.764255, time: 3.412
training: epoch 90, step 5200, loss 32.725052, time: 3.415
training: epoch 90, step 5400, loss 32.714970, time: 3.415
training: epoch 90, step 5600, loss 32.726726, time: 3.405
training: epoch 90, step 5800, loss 32.729010, time: 3.407
training: epoch 90, step 6000, loss 32.705331, time: 3.402
training: epoch 90, step 6200, loss 32.679976, time: 3.403
training: epoch 90, step 6400, loss 32.699851, time: 3.404
training: epoch 90, step 6600, loss 32.721111, time: 3.401
training: epoch 90, step 6800, loss 32.750509, time: 3.405
training: epoch 90, step 7000, loss 32.771994, time: 3.393
training: epoch 90, step 7200, loss 32.748143, time: 3.392
training: epoch 90, step 7400, loss 32.739340, time: 3.395
training: epoch 90, step 7600, loss 32.728861, time: 3.392
training: epoch 90, step 7800, loss 32.732665, time: 3.390
training: epoch 90, step 7849, loss 32.737351, time: 0.831
validate: epoch 90, loss 35.677702, charcter error 6.447 time: 4.037
training: epoch 91, step 200, loss 33.111585, time: 3.344
training: epoch 91, step 400, loss 32.586687, time: 3.382
training: epoch 91, step 600, loss 32.821344, time: 3.387
training: epoch 91, step 800, loss 32.978572, time: 3.390
training: epoch 91, step 1000, loss 32.906365, time: 3.395
training: epoch 91, step 1200, loss 32.750752, time: 3.392
training: epoch 91, step 1400, loss 32.663114, time: 3.390
training: epoch 91, step 1600, loss 32.673141, time: 3.390
training: epoch 91, step 1800, loss 32.687623, time: 3.393
training: epoch 91, step 2000, loss 32.841377, time: 3.394
training: epoch 91, step 2200, loss 32.846495, time: 3.393
training: epoch 91, step 2400, loss 32.821227, time: 3.387
training: epoch 91, step 2600, loss 32.855150, time: 3.394
training: epoch 91, step 2800, loss 32.865205, time: 3.390
training: epoch 91, step 3000, loss 32.898306, time: 3.387
training: epoch 91, step 3200, loss 32.940099, time: 3.394
training: epoch 91, step 3400, loss 32.878747, time: 3.389
training: epoch 91, step 3600, loss 32.826918, time: 3.393
training: epoch 91, step 3800, loss 32.841986, time: 3.393
training: epoch 91, step 4000, loss 32.813115, time: 3.398
training: epoch 91, step 4200, loss 32.781432, time: 3.393
training: epoch 91, step 4400, loss 32.763887, time: 3.395
training: epoch 91, step 4600, loss 32.786980, time: 3.392
training: epoch 91, step 4800, loss 32.834031, time: 3.395
training: epoch 91, step 5000, loss 32.791634, time: 3.391
training: epoch 91, step 5200, loss 32.859922, time: 3.390
training: epoch 91, step 5400, loss 32.880320, time: 3.391
training: epoch 91, step 5600, loss 32.830360, time: 3.389
training: epoch 91, step 5800, loss 32.840824, time: 3.389
training: epoch 91, step 6000, loss 32.877940, time: 3.389
training: epoch 91, step 6200, loss 32.840640, time: 3.392
training: epoch 91, step 6400, loss 32.846552, time: 3.393
training: epoch 91, step 6600, loss 32.835827, time: 3.392
training: epoch 91, step 6800, loss 32.818765, time: 3.391
training: epoch 91, step 7000, loss 32.783606, time: 3.390
training: epoch 91, step 7200, loss 32.801818, time: 3.387
training: epoch 91, step 7400, loss 32.828224, time: 3.392
training: epoch 91, step 7600, loss 32.821363, time: 3.389
training: epoch 91, step 7800, loss 32.805826, time: 3.387
training: epoch 91, step 7849, loss 32.810312, time: 0.832
validate: epoch 91, loss 35.523985, charcter error 6.429 time: 4.023
    - [Info] The checkpoint file has been updated.
training: epoch 92, step 200, loss 31.493122, time: 3.346
training: epoch 92, step 400, loss 31.802466, time: 3.377
training: epoch 92, step 600, loss 32.580868, time: 3.390
training: epoch 92, step 800, loss 32.465785, time: 3.389
training: epoch 92, step 1000, loss 32.471660, time: 3.390
training: epoch 92, step 1200, loss 32.498138, time: 3.388
training: epoch 92, step 1400, loss 32.460370, time: 3.387
training: epoch 92, step 1600, loss 32.380288, time: 3.392
training: epoch 92, step 1800, loss 32.476251, time: 3.383
training: epoch 92, step 2000, loss 32.481977, time: 3.385
training: epoch 92, step 2200, loss 32.461105, time: 3.389
training: epoch 92, step 2400, loss 32.423635, time: 3.386
training: epoch 92, step 2600, loss 32.433692, time: 3.387
training: epoch 92, step 2800, loss 32.450248, time: 3.390
training: epoch 92, step 3000, loss 32.517691, time: 3.387
training: epoch 92, step 3200, loss 32.485339, time: 3.385
training: epoch 92, step 3400, loss 32.497341, time: 3.387
training: epoch 92, step 3600, loss 32.532932, time: 3.386
training: epoch 92, step 3800, loss 32.494371, time: 3.389
training: epoch 92, step 4000, loss 32.514252, time: 3.390
training: epoch 92, step 4200, loss 32.557789, time: 3.391
training: epoch 92, step 4400, loss 32.603083, time: 3.389
training: epoch 92, step 4600, loss 32.610234, time: 3.390
training: epoch 92, step 4800, loss 32.680802, time: 3.388
training: epoch 92, step 5000, loss 32.668529, time: 3.391
training: epoch 92, step 5200, loss 32.677043, time: 3.385
training: epoch 92, step 5400, loss 32.677960, time: 3.387
training: epoch 92, step 5600, loss 32.674724, time: 3.393
training: epoch 92, step 5800, loss 32.668469, time: 3.389
training: epoch 92, step 6000, loss 32.658024, time: 3.390
training: epoch 92, step 6200, loss 32.676878, time: 3.387
training: epoch 92, step 6400, loss 32.697582, time: 3.391
training: epoch 92, step 6600, loss 32.699691, time: 3.384
training: epoch 92, step 6800, loss 32.711840, time: 3.385
training: epoch 92, step 7000, loss 32.730986, time: 3.388
training: epoch 92, step 7200, loss 32.742313, time: 3.394
training: epoch 92, step 7400, loss 32.779738, time: 3.398
training: epoch 92, step 7600, loss 32.766666, time: 3.391
training: epoch 92, step 7800, loss 32.745786, time: 3.392
training: epoch 92, step 7849, loss 32.727586, time: 0.831
validate: epoch 92, loss 35.642470, charcter error 6.450 time: 4.019
training: epoch 93, step 200, loss 31.927159, time: 3.344
training: epoch 93, step 400, loss 32.372248, time: 3.386
training: epoch 93, step 600, loss 32.562259, time: 3.392
training: epoch 93, step 800, loss 32.660102, time: 3.399
training: epoch 93, step 1000, loss 32.651924, time: 3.399
training: epoch 93, step 1200, loss 32.620908, time: 3.397
training: epoch 93, step 1400, loss 32.545968, time: 3.395
training: epoch 93, step 1600, loss 32.348315, time: 3.395
training: epoch 93, step 1800, loss 32.354680, time: 3.393
training: epoch 93, step 2000, loss 32.430087, time: 3.397
training: epoch 93, step 2200, loss 32.485799, time: 3.401
training: epoch 93, step 2400, loss 32.537550, time: 3.395
training: epoch 93, step 2600, loss 32.551883, time: 3.396
training: epoch 93, step 2800, loss 32.510924, time: 3.396
training: epoch 93, step 3000, loss 32.507312, time: 3.398
training: epoch 93, step 3200, loss 32.548657, time: 3.397
training: epoch 93, step 3400, loss 32.520562, time: 3.396
training: epoch 93, step 3600, loss 32.614671, time: 3.396
training: epoch 93, step 3800, loss 32.593641, time: 3.397
training: epoch 93, step 4000, loss 32.621092, time: 3.396
training: epoch 93, step 4200, loss 32.600266, time: 3.396
training: epoch 93, step 4400, loss 32.615961, time: 3.392
training: epoch 93, step 4600, loss 32.562724, time: 3.389
training: epoch 93, step 4800, loss 32.568089, time: 3.392
training: epoch 93, step 5000, loss 32.540508, time: 3.393
training: epoch 93, step 5200, loss 32.564257, time: 3.396
training: epoch 93, step 5400, loss 32.582780, time: 3.394
training: epoch 93, step 5600, loss 32.599569, time: 3.396
training: epoch 93, step 5800, loss 32.599651, time: 3.393
training: epoch 93, step 6000, loss 32.583750, time: 3.391
training: epoch 93, step 6200, loss 32.595399, time: 3.396
training: epoch 93, step 6400, loss 32.606226, time: 3.388
training: epoch 93, step 6600, loss 32.624989, time: 3.390
training: epoch 93, step 6800, loss 32.603709, time: 3.393
training: epoch 93, step 7000, loss 32.600273, time: 3.396
training: epoch 93, step 7200, loss 32.616506, time: 3.398
training: epoch 93, step 7400, loss 32.646419, time: 3.395
training: epoch 93, step 7600, loss 32.703936, time: 3.391
training: epoch 93, step 7800, loss 32.727185, time: 3.397
training: epoch 93, step 7849, loss 32.742644, time: 0.831
validate: epoch 93, loss 36.125545, charcter error 6.549 time: 4.021
training: epoch 94, step 200, loss 32.338723, time: 3.335
training: epoch 94, step 400, loss 32.888266, time: 3.380
training: epoch 94, step 600, loss 32.615665, time: 3.384
training: epoch 94, step 800, loss 32.630092, time: 3.386
training: epoch 94, step 1000, loss 32.537398, time: 3.382
training: epoch 94, step 1200, loss 32.392730, time: 3.384
training: epoch 94, step 1400, loss 32.479119, time: 3.385
training: epoch 94, step 1600, loss 32.553379, time: 3.390
training: epoch 94, step 1800, loss 32.476796, time: 3.387
training: epoch 94, step 2000, loss 32.547317, time: 3.389
training: epoch 94, step 2200, loss 32.555185, time: 3.391
training: epoch 94, step 2400, loss 32.586958, time: 3.389
training: epoch 94, step 2600, loss 32.624757, time: 3.393
training: epoch 94, step 2800, loss 32.653836, time: 3.390
training: epoch 94, step 3000, loss 32.607097, time: 3.389
training: epoch 94, step 3200, loss 32.599634, time: 3.389
training: epoch 94, step 3400, loss 32.610731, time: 3.390
training: epoch 94, step 3600, loss 32.598571, time: 3.389
training: epoch 94, step 3800, loss 32.564463, time: 3.388
training: epoch 94, step 4000, loss 32.572360, time: 3.396
training: epoch 94, step 4200, loss 32.535282, time: 3.390
training: epoch 94, step 4400, loss 32.508129, time: 3.391
training: epoch 94, step 4600, loss 32.483128, time: 3.394
training: epoch 94, step 4800, loss 32.536427, time: 3.392
training: epoch 94, step 5000, loss 32.518997, time: 3.388
training: epoch 94, step 5200, loss 32.555733, time: 3.386
training: epoch 94, step 5400, loss 32.583221, time: 3.393
training: epoch 94, step 5600, loss 32.601844, time: 3.392
training: epoch 94, step 5800, loss 32.603786, time: 3.394
training: epoch 94, step 6000, loss 32.624808, time: 3.394
training: epoch 94, step 6200, loss 32.640034, time: 3.394
training: epoch 94, step 6400, loss 32.638849, time: 3.389
training: epoch 94, step 6600, loss 32.654564, time: 3.392
training: epoch 94, step 6800, loss 32.656946, time: 3.393
training: epoch 94, step 7000, loss 32.646476, time: 3.397
training: epoch 94, step 7200, loss 32.673496, time: 3.388
training: epoch 94, step 7400, loss 32.677721, time: 3.391
training: epoch 94, step 7600, loss 32.690063, time: 3.396
training: epoch 94, step 7800, loss 32.695490, time: 3.393
training: epoch 94, step 7849, loss 32.691777, time: 0.831
validate: epoch 94, loss 35.494617, charcter error 6.407 time: 4.015
    - [Info] The checkpoint file has been updated.
training: epoch 95, step 200, loss 31.841433, time: 3.348
training: epoch 95, step 400, loss 32.629142, time: 3.381
training: epoch 95, step 600, loss 32.796222, time: 3.391
training: epoch 95, step 800, loss 32.585950, time: 3.399
training: epoch 95, step 1000, loss 32.572104, time: 3.402
training: epoch 95, step 1200, loss 32.472824, time: 3.393
training: epoch 95, step 1400, loss 32.542741, time: 3.400
training: epoch 95, step 1600, loss 32.551101, time: 3.395
training: epoch 95, step 1800, loss 32.432545, time: 3.397
training: epoch 95, step 2000, loss 32.404273, time: 3.400
training: epoch 95, step 2200, loss 32.377007, time: 3.397
training: epoch 95, step 2400, loss 32.354951, time: 3.389
training: epoch 95, step 2600, loss 32.395293, time: 3.393
training: epoch 95, step 2800, loss 32.429624, time: 3.392
training: epoch 95, step 3000, loss 32.455104, time: 3.396
training: epoch 95, step 3200, loss 32.430563, time: 3.398
training: epoch 95, step 3400, loss 32.444173, time: 3.393
training: epoch 95, step 3600, loss 32.410191, time: 3.389
training: epoch 95, step 3800, loss 32.450228, time: 3.390
training: epoch 95, step 4000, loss 32.457854, time: 3.397
training: epoch 95, step 4200, loss 32.553720, time: 3.396
training: epoch 95, step 4400, loss 32.492997, time: 3.397
training: epoch 95, step 4600, loss 32.501529, time: 3.394
training: epoch 95, step 4800, loss 32.559271, time: 3.394
training: epoch 95, step 5000, loss 32.548757, time: 3.395
training: epoch 95, step 5200, loss 32.504474, time: 3.395
training: epoch 95, step 5400, loss 32.524009, time: 3.400
training: epoch 95, step 5600, loss 32.578736, time: 3.401
training: epoch 95, step 5800, loss 32.575480, time: 3.396
training: epoch 95, step 6000, loss 32.582358, time: 3.398
training: epoch 95, step 6200, loss 32.596975, time: 3.403
training: epoch 95, step 6400, loss 32.614968, time: 3.397
training: epoch 95, step 6600, loss 32.603465, time: 3.397
training: epoch 95, step 6800, loss 32.645749, time: 3.402
training: epoch 95, step 7000, loss 32.659929, time: 3.395
training: epoch 95, step 7200, loss 32.646313, time: 3.395
training: epoch 95, step 7400, loss 32.645537, time: 3.392
training: epoch 95, step 7600, loss 32.651059, time: 3.399
training: epoch 95, step 7800, loss 32.644278, time: 3.393
training: epoch 95, step 7849, loss 32.648419, time: 0.831
validate: epoch 95, loss 35.569168, charcter error 6.440 time: 4.022
training: epoch 96, step 200, loss 32.507536, time: 3.348
training: epoch 96, step 400, loss 33.021967, time: 3.385
training: epoch 96, step 600, loss 32.868539, time: 3.392
training: epoch 96, step 800, loss 33.030915, time: 3.387
training: epoch 96, step 1000, loss 32.775454, time: 3.394
training: epoch 96, step 1200, loss 32.781902, time: 3.399
training: epoch 96, step 1400, loss 32.630852, time: 3.394
training: epoch 96, step 1600, loss 32.624524, time: 3.396
training: epoch 96, step 1800, loss 32.524314, time: 3.394
training: epoch 96, step 2000, loss 32.440916, time: 3.393
training: epoch 96, step 2200, loss 32.485679, time: 3.394
training: epoch 96, step 2400, loss 32.450744, time: 3.393
training: epoch 96, step 2600, loss 32.452013, time: 3.396
training: epoch 96, step 2800, loss 32.428108, time: 3.395
training: epoch 96, step 3000, loss 32.394871, time: 3.387
training: epoch 96, step 3200, loss 32.355734, time: 3.392
training: epoch 96, step 3400, loss 32.392526, time: 3.394
training: epoch 96, step 3600, loss 32.454246, time: 3.390
training: epoch 96, step 3800, loss 32.451232, time: 3.390
training: epoch 96, step 4000, loss 32.523543, time: 3.392
training: epoch 96, step 4200, loss 32.524702, time: 3.388
training: epoch 96, step 4400, loss 32.532890, time: 3.388
training: epoch 96, step 4600, loss 32.521312, time: 3.381
training: epoch 96, step 4800, loss 32.501669, time: 3.386
training: epoch 96, step 5000, loss 32.508797, time: 3.389
training: epoch 96, step 5200, loss 32.533141, time: 3.390
training: epoch 96, step 5400, loss 32.516334, time: 3.388
training: epoch 96, step 5600, loss 32.509187, time: 3.390
training: epoch 96, step 5800, loss 32.496120, time: 3.387
training: epoch 96, step 6000, loss 32.502884, time: 3.385
training: epoch 96, step 6200, loss 32.528073, time: 3.390
training: epoch 96, step 6400, loss 32.520448, time: 3.384
training: epoch 96, step 6600, loss 32.506166, time: 3.384
training: epoch 96, step 6800, loss 32.510842, time: 3.386
training: epoch 96, step 7000, loss 32.520071, time: 3.382
training: epoch 96, step 7200, loss 32.502979, time: 3.385
training: epoch 96, step 7400, loss 32.511417, time: 3.383
training: epoch 96, step 7600, loss 32.525843, time: 3.382
training: epoch 96, step 7800, loss 32.552265, time: 3.383
training: epoch 96, step 7849, loss 32.552188, time: 0.832
validate: epoch 96, loss 35.967122, charcter error 6.481 time: 4.015
training: epoch 97, step 200, loss 33.428369, time: 3.339
training: epoch 97, step 400, loss 33.069228, time: 3.380
training: epoch 97, step 600, loss 32.771538, time: 3.383
training: epoch 97, step 800, loss 32.749375, time: 3.388
training: epoch 97, step 1000, loss 33.017018, time: 3.390
training: epoch 97, step 1200, loss 32.906570, time: 3.387
training: epoch 97, step 1400, loss 32.911820, time: 3.386
training: epoch 97, step 1600, loss 32.772770, time: 3.385
training: epoch 97, step 1800, loss 32.637177, time: 3.384
training: epoch 97, step 2000, loss 32.650228, time: 3.389
training: epoch 97, step 2200, loss 32.552939, time: 3.388
training: epoch 97, step 2400, loss 32.444565, time: 3.381
training: epoch 97, step 2600, loss 32.409269, time: 3.388
training: epoch 97, step 2800, loss 32.484456, time: 3.379
training: epoch 97, step 3000, loss 32.527140, time: 3.382
training: epoch 97, step 3200, loss 32.521285, time: 3.383
training: epoch 97, step 3400, loss 32.524487, time: 3.383
training: epoch 97, step 3600, loss 32.560091, time: 3.384
training: epoch 97, step 3800, loss 32.545064, time: 3.384
training: epoch 97, step 4000, loss 32.516154, time: 3.385
training: epoch 97, step 4200, loss 32.476581, time: 3.384
training: epoch 97, step 4400, loss 32.524359, time: 3.388
training: epoch 97, step 4600, loss 32.535022, time: 3.385
training: epoch 97, step 4800, loss 32.482290, time: 3.388
training: epoch 97, step 5000, loss 32.492644, time: 3.385
training: epoch 97, step 5200, loss 32.466164, time: 3.386
training: epoch 97, step 5400, loss 32.479424, time: 3.401
training: epoch 97, step 5600, loss 32.482824, time: 3.399
training: epoch 97, step 5800, loss 32.454435, time: 3.392
training: epoch 97, step 6000, loss 32.486052, time: 3.399
training: epoch 97, step 6200, loss 32.471213, time: 3.393
training: epoch 97, step 6400, loss 32.478974, time: 3.398
training: epoch 97, step 6600, loss 32.505856, time: 3.399
training: epoch 97, step 6800, loss 32.528373, time: 3.397
training: epoch 97, step 7000, loss 32.528595, time: 3.393
training: epoch 97, step 7200, loss 32.528951, time: 3.387
training: epoch 97, step 7400, loss 32.517223, time: 3.391
training: epoch 97, step 7600, loss 32.482975, time: 3.388
training: epoch 97, step 7800, loss 32.493024, time: 3.389
training: epoch 97, step 7849, loss 32.484805, time: 0.830
validate: epoch 97, loss 36.204188, charcter error 6.529 time: 4.025
training: epoch 98, step 200, loss 32.556028, time: 3.336
training: epoch 98, step 400, loss 32.570447, time: 3.380
training: epoch 98, step 600, loss 32.657488, time: 3.407
training: epoch 98, step 800, loss 32.372057, time: 3.388
training: epoch 98, step 1000, loss 32.250193, time: 3.388
training: epoch 98, step 1200, loss 32.402486, time: 3.410
training: epoch 98, step 1400, loss 32.409657, time: 3.433
training: epoch 98, step 1600, loss 32.377645, time: 3.463
training: epoch 98, step 1800, loss 32.240308, time: 3.538
training: epoch 98, step 2000, loss 32.258078, time: 3.523
training: epoch 98, step 2200, loss 32.205332, time: 3.545
training: epoch 98, step 2400, loss 32.286938, time: 3.515
training: epoch 98, step 2600, loss 32.323257, time: 3.527
training: epoch 98, step 2800, loss 32.345739, time: 3.512
training: epoch 98, step 3000, loss 32.379283, time: 3.551
training: epoch 98, step 3200, loss 32.349443, time: 3.604
training: epoch 98, step 3400, loss 32.301283, time: 3.497
training: epoch 98, step 3600, loss 32.281719, time: 3.511
training: epoch 98, step 3800, loss 32.295481, time: 3.492
training: epoch 98, step 4000, loss 32.242697, time: 3.482
training: epoch 98, step 4200, loss 32.277653, time: 3.460
training: epoch 98, step 4400, loss 32.306830, time: 3.461
training: epoch 98, step 4600, loss 32.352354, time: 3.464
training: epoch 98, step 4800, loss 32.368672, time: 3.452
training: epoch 98, step 5000, loss 32.379688, time: 3.451
training: epoch 98, step 5200, loss 32.364231, time: 3.432
training: epoch 98, step 5400, loss 32.365806, time: 3.428
training: epoch 98, step 5600, loss 32.400177, time: 3.431
training: epoch 98, step 5800, loss 32.431450, time: 3.419
training: epoch 98, step 6000, loss 32.458236, time: 3.407
training: epoch 98, step 6200, loss 32.482782, time: 3.397
training: epoch 98, step 6400, loss 32.499128, time: 3.388
training: epoch 98, step 6600, loss 32.521697, time: 3.386
training: epoch 98, step 6800, loss 32.526643, time: 3.387
training: epoch 98, step 7000, loss 32.523104, time: 3.381
training: epoch 98, step 7200, loss 32.511119, time: 3.384
training: epoch 98, step 7400, loss 32.495807, time: 3.384
training: epoch 98, step 7600, loss 32.518239, time: 3.382
training: epoch 98, step 7800, loss 32.505150, time: 3.385
training: epoch 98, step 7849, loss 32.493348, time: 0.827
validate: epoch 98, loss 35.458225, charcter error 6.388 time: 4.034
    - [Info] The checkpoint file has been updated.
training: epoch 99, step 200, loss 32.778616, time: 3.346
training: epoch 99, step 400, loss 32.187865, time: 3.381
training: epoch 99, step 600, loss 32.296867, time: 3.385
training: epoch 99, step 800, loss 32.175367, time: 3.383
training: epoch 99, step 1000, loss 32.109509, time: 3.388
training: epoch 99, step 1200, loss 32.183011, time: 3.386
training: epoch 99, step 1400, loss 32.146916, time: 3.382
training: epoch 99, step 1600, loss 32.223793, time: 3.383
training: epoch 99, step 1800, loss 32.217850, time: 3.382
training: epoch 99, step 2000, loss 32.184837, time: 3.376
training: epoch 99, step 2200, loss 32.324961, time: 3.380
training: epoch 99, step 2400, loss 32.365156, time: 3.379
training: epoch 99, step 2600, loss 32.379011, time: 3.383
training: epoch 99, step 2800, loss 32.478078, time: 3.384
training: epoch 99, step 3000, loss 32.486259, time: 3.382
training: epoch 99, step 3200, loss 32.475983, time: 3.383
training: epoch 99, step 3400, loss 32.509773, time: 3.383
training: epoch 99, step 3600, loss 32.541925, time: 3.379
training: epoch 99, step 3800, loss 32.546751, time: 3.484
training: epoch 99, step 4000, loss 32.501461, time: 3.506
training: epoch 99, step 4200, loss 32.475638, time: 3.468
training: epoch 99, step 4400, loss 32.458374, time: 3.478
training: epoch 99, step 4600, loss 32.519005, time: 3.486
training: epoch 99, step 4800, loss 32.534660, time: 3.502
training: epoch 99, step 5000, loss 32.511862, time: 3.486
training: epoch 99, step 5200, loss 32.481643, time: 3.469
training: epoch 99, step 5400, loss 32.425919, time: 3.441
training: epoch 99, step 5600, loss 32.453516, time: 3.472
training: epoch 99, step 5800, loss 32.438559, time: 3.473
training: epoch 99, step 6000, loss 32.475292, time: 3.493
training: epoch 99, step 6200, loss 32.445009, time: 3.514
training: epoch 99, step 6400, loss 32.454274, time: 3.476
training: epoch 99, step 6600, loss 32.459173, time: 3.505
training: epoch 99, step 6800, loss 32.451570, time: 3.489
training: epoch 99, step 7000, loss 32.443345, time: 3.403
training: epoch 99, step 7200, loss 32.444972, time: 3.399
training: epoch 99, step 7400, loss 32.419813, time: 3.392
training: epoch 99, step 7600, loss 32.410246, time: 3.409
training: epoch 99, step 7800, loss 32.401502, time: 3.487
training: epoch 99, step 7849, loss 32.412805, time: 0.853
validate: epoch 99, loss 35.800113, charcter error 6.456 time: 4.037
training: epoch 100, step 200, loss 31.798429, time: 3.486
training: epoch 100, step 400, loss 31.848701, time: 3.477
training: epoch 100, step 600, loss 31.956323, time: 3.449
training: epoch 100, step 800, loss 31.881394, time: 3.482
training: epoch 100, step 1000, loss 31.926869, time: 3.449
training: epoch 100, step 1200, loss 31.998359, time: 3.454
training: epoch 100, step 1400, loss 32.056354, time: 3.464
training: epoch 100, step 1600, loss 32.224439, time: 3.453
training: epoch 100, step 1800, loss 32.261133, time: 3.492
training: epoch 100, step 2000, loss 32.316716, time: 3.498
training: epoch 100, step 2200, loss 32.292305, time: 3.471
training: epoch 100, step 2400, loss 32.242071, time: 3.459
training: epoch 100, step 2600, loss 32.253976, time: 3.469
training: epoch 100, step 2800, loss 32.238488, time: 3.433
training: epoch 100, step 3000, loss 32.277862, time: 3.452
training: epoch 100, step 3200, loss 32.263157, time: 3.443
training: epoch 100, step 3400, loss 32.242200, time: 3.444
training: epoch 100, step 3600, loss 32.226052, time: 3.585
training: epoch 100, step 3800, loss 32.228673, time: 3.547
training: epoch 100, step 4000, loss 32.282833, time: 3.485
training: epoch 100, step 4200, loss 32.248613, time: 3.503
training: epoch 100, step 4400, loss 32.254701, time: 3.480
training: epoch 100, step 4600, loss 32.246418, time: 3.475
training: epoch 100, step 4800, loss 32.289674, time: 3.451
training: epoch 100, step 5000, loss 32.267992, time: 3.439
training: epoch 100, step 5200, loss 32.251223, time: 3.501
training: epoch 100, step 5400, loss 32.261238, time: 3.492
training: epoch 100, step 5600, loss 32.253440, time: 3.432
training: epoch 100, step 5800, loss 32.258956, time: 3.436
training: epoch 100, step 6000, loss 32.280553, time: 3.420
training: epoch 100, step 6200, loss 32.298782, time: 3.415
training: epoch 100, step 6400, loss 32.353146, time: 3.397
training: epoch 100, step 6600, loss 32.377478, time: 3.392
training: epoch 100, step 6800, loss 32.416027, time: 3.390
training: epoch 100, step 7000, loss 32.436304, time: 3.385
training: epoch 100, step 7200, loss 32.437187, time: 3.389
training: epoch 100, step 7400, loss 32.439884, time: 3.393
training: epoch 100, step 7600, loss 32.462294, time: 3.393
training: epoch 100, step 7800, loss 32.463434, time: 3.391
training: epoch 100, step 7849, loss 32.462916, time: 0.830
validate: epoch 100, loss 35.510598, charcter error 6.421 time: 4.034
training: epoch 101, step 200, loss 31.702158, time: 3.339
training: epoch 101, step 400, loss 32.341123, time: 3.380
training: epoch 101, step 600, loss 32.316549, time: 3.388
training: epoch 101, step 800, loss 32.324537, time: 3.386
training: epoch 101, step 1000, loss 32.224092, time: 3.386
training: epoch 101, step 1200, loss 32.387138, time: 3.390
training: epoch 101, step 1400, loss 32.279706, time: 3.385
training: epoch 101, step 1600, loss 32.281480, time: 3.387
training: epoch 101, step 1800, loss 32.268524, time: 3.386
training: epoch 101, step 2000, loss 32.219161, time: 3.386
training: epoch 101, step 2200, loss 32.378198, time: 3.389
training: epoch 101, step 2400, loss 32.524799, time: 3.390
training: epoch 101, step 2600, loss 32.501234, time: 3.391
training: epoch 101, step 2800, loss 32.472719, time: 3.393
training: epoch 101, step 3000, loss 32.493108, time: 3.394
training: epoch 101, step 3200, loss 32.436995, time: 3.388
training: epoch 101, step 3400, loss 32.426214, time: 3.387
training: epoch 101, step 3600, loss 32.457152, time: 3.391
training: epoch 101, step 3800, loss 32.419455, time: 3.388
training: epoch 101, step 4000, loss 32.443642, time: 3.391
training: epoch 101, step 4200, loss 32.459648, time: 3.388
training: epoch 101, step 4400, loss 32.524662, time: 3.388
training: epoch 101, step 4600, loss 32.510387, time: 3.389
training: epoch 101, step 4800, loss 32.508894, time: 3.385
training: epoch 101, step 5000, loss 32.525479, time: 3.387
training: epoch 101, step 5200, loss 32.528590, time: 3.389
training: epoch 101, step 5400, loss 32.571818, time: 3.388
training: epoch 101, step 5600, loss 32.579179, time: 3.389
training: epoch 101, step 5800, loss 32.568578, time: 3.390
training: epoch 101, step 6000, loss 32.529502, time: 3.388
training: epoch 101, step 6200, loss 32.531531, time: 3.387
training: epoch 101, step 6400, loss 32.536693, time: 3.390
training: epoch 101, step 6600, loss 32.563033, time: 3.392
training: epoch 101, step 6800, loss 32.536535, time: 3.390
training: epoch 101, step 7000, loss 32.535136, time: 3.391
training: epoch 101, step 7200, loss 32.517951, time: 3.392
training: epoch 101, step 7400, loss 32.498356, time: 3.387
training: epoch 101, step 7600, loss 32.473068, time: 3.388
training: epoch 101, step 7800, loss 32.475082, time: 3.390
training: epoch 101, step 7849, loss 32.481715, time: 0.831
validate: epoch 101, loss 35.524795, charcter error 6.384 time: 4.029
    - [Info] The checkpoint file has been updated.
training: epoch 102, step 200, loss 31.416618, time: 3.348
training: epoch 102, step 400, loss 31.733983, time: 3.382
training: epoch 102, step 600, loss 31.505080, time: 3.390
training: epoch 102, step 800, loss 31.520104, time: 3.390
training: epoch 102, step 1000, loss 31.440743, time: 3.390
training: epoch 102, step 1200, loss 31.661671, time: 3.390
training: epoch 102, step 1400, loss 31.733168, time: 3.388
training: epoch 102, step 1600, loss 31.888357, time: 3.392
training: epoch 102, step 1800, loss 31.981847, time: 3.391
training: epoch 102, step 2000, loss 32.000795, time: 3.390
training: epoch 102, step 2200, loss 32.032107, time: 3.389
training: epoch 102, step 2400, loss 32.026964, time: 3.389
training: epoch 102, step 2600, loss 32.081650, time: 3.391
training: epoch 102, step 2800, loss 32.102606, time: 3.394
training: epoch 102, step 3000, loss 32.081831, time: 3.391
training: epoch 102, step 3200, loss 32.080413, time: 3.390
training: epoch 102, step 3400, loss 32.120947, time: 3.391
training: epoch 102, step 3600, loss 32.137637, time: 3.393
training: epoch 102, step 3800, loss 32.227993, time: 3.393
training: epoch 102, step 4000, loss 32.283310, time: 3.391
training: epoch 102, step 4200, loss 32.278743, time: 3.390
training: epoch 102, step 4400, loss 32.242260, time: 3.389
training: epoch 102, step 4600, loss 32.271765, time: 3.392
training: epoch 102, step 4800, loss 32.282954, time: 3.394
training: epoch 102, step 5000, loss 32.269230, time: 3.392
training: epoch 102, step 5200, loss 32.277261, time: 3.391
training: epoch 102, step 5400, loss 32.308794, time: 3.393
training: epoch 102, step 5600, loss 32.355174, time: 3.392
training: epoch 102, step 5800, loss 32.360287, time: 3.394
training: epoch 102, step 6000, loss 32.347525, time: 3.390
training: epoch 102, step 6200, loss 32.347585, time: 3.392
training: epoch 102, step 6400, loss 32.351570, time: 3.395
training: epoch 102, step 6600, loss 32.354799, time: 3.393
training: epoch 102, step 6800, loss 32.340970, time: 3.393
training: epoch 102, step 7000, loss 32.321882, time: 3.394
training: epoch 102, step 7200, loss 32.310768, time: 3.396
training: epoch 102, step 7400, loss 32.349909, time: 3.398
training: epoch 102, step 7600, loss 32.344793, time: 3.393
training: epoch 102, step 7800, loss 32.318523, time: 3.396
training: epoch 102, step 7849, loss 32.317686, time: 0.832
validate: epoch 102, loss 35.455058, charcter error 6.387 time: 4.021
training: epoch 103, step 200, loss 32.819387, time: 3.346
training: epoch 103, step 400, loss 32.250839, time: 3.387
training: epoch 103, step 600, loss 31.906271, time: 3.394
training: epoch 103, step 800, loss 31.968650, time: 3.396
training: epoch 103, step 1000, loss 32.188077, time: 3.400
training: epoch 103, step 1200, loss 32.140344, time: 3.397
training: epoch 103, step 1400, loss 32.071184, time: 3.398
training: epoch 103, step 1600, loss 32.038258, time: 3.401
training: epoch 103, step 1800, loss 32.182291, time: 3.397
training: epoch 103, step 2000, loss 32.202389, time: 3.398
training: epoch 103, step 2200, loss 32.216780, time: 3.395
training: epoch 103, step 2400, loss 32.179090, time: 3.395
training: epoch 103, step 2600, loss 32.124402, time: 3.395
training: epoch 103, step 2800, loss 32.127551, time: 3.394
training: epoch 103, step 3000, loss 32.091984, time: 3.400
training: epoch 103, step 3200, loss 32.134615, time: 3.402
training: epoch 103, step 3400, loss 32.105270, time: 3.401
training: epoch 103, step 3600, loss 32.113522, time: 3.401
training: epoch 103, step 3800, loss 32.101671, time: 3.397
training: epoch 103, step 4000, loss 32.114471, time: 3.400
training: epoch 103, step 4200, loss 32.099579, time: 3.400
training: epoch 103, step 4400, loss 32.115616, time: 3.402
training: epoch 103, step 4600, loss 32.153769, time: 3.409
training: epoch 103, step 4800, loss 32.171384, time: 3.404
training: epoch 103, step 5000, loss 32.185229, time: 3.403
training: epoch 103, step 5200, loss 32.202946, time: 3.406
training: epoch 103, step 5400, loss 32.219292, time: 3.406
training: epoch 103, step 5600, loss 32.209582, time: 3.405
training: epoch 103, step 5800, loss 32.238039, time: 3.412
training: epoch 103, step 6000, loss 32.231217, time: 3.405
training: epoch 103, step 6200, loss 32.264017, time: 3.401
training: epoch 103, step 6400, loss 32.228848, time: 3.403
training: epoch 103, step 6600, loss 32.233244, time: 3.406
training: epoch 103, step 6800, loss 32.256213, time: 3.403
training: epoch 103, step 7000, loss 32.237457, time: 3.401
training: epoch 103, step 7200, loss 32.243085, time: 3.405
training: epoch 103, step 7400, loss 32.239852, time: 3.405
training: epoch 103, step 7600, loss 32.241133, time: 3.403
training: epoch 103, step 7800, loss 32.242741, time: 3.402
training: epoch 103, step 7849, loss 32.261348, time: 0.834
validate: epoch 103, loss 35.387862, charcter error 6.380 time: 4.028
    - [Info] The checkpoint file has been updated.
training: epoch 104, step 200, loss 33.323666, time: 3.358
training: epoch 104, step 400, loss 33.025268, time: 3.394
training: epoch 104, step 600, loss 32.857945, time: 3.403
training: epoch 104, step 800, loss 32.716196, time: 3.403
training: epoch 104, step 1000, loss 32.765778, time: 3.402
training: epoch 104, step 1200, loss 32.683954, time: 3.400
training: epoch 104, step 1400, loss 32.623402, time: 3.402
training: epoch 104, step 1600, loss 32.513535, time: 3.402
training: epoch 104, step 1800, loss 32.593081, time: 3.405
training: epoch 104, step 2000, loss 32.476047, time: 3.403
training: epoch 104, step 2200, loss 32.435377, time: 3.407
training: epoch 104, step 2400, loss 32.389481, time: 3.405
training: epoch 104, step 2600, loss 32.405040, time: 3.398
training: epoch 104, step 2800, loss 32.387352, time: 3.399
training: epoch 104, step 3000, loss 32.379549, time: 3.402
training: epoch 104, step 3200, loss 32.385346, time: 3.403
training: epoch 104, step 3400, loss 32.347488, time: 3.403
training: epoch 104, step 3600, loss 32.403990, time: 3.403
training: epoch 104, step 3800, loss 32.337604, time: 3.403
training: epoch 104, step 4000, loss 32.317960, time: 3.402
training: epoch 104, step 4200, loss 32.298497, time: 3.397
training: epoch 104, step 4400, loss 32.312207, time: 3.401
training: epoch 104, step 4600, loss 32.289891, time: 3.402
training: epoch 104, step 4800, loss 32.344088, time: 3.399
training: epoch 104, step 5000, loss 32.336094, time: 3.401
training: epoch 104, step 5200, loss 32.340498, time: 3.398
training: epoch 104, step 5400, loss 32.338037, time: 3.397
training: epoch 104, step 5600, loss 32.338020, time: 3.392
training: epoch 104, step 5800, loss 32.333071, time: 3.396
training: epoch 104, step 6000, loss 32.327538, time: 3.393
training: epoch 104, step 6200, loss 32.328913, time: 3.388
training: epoch 104, step 6400, loss 32.309623, time: 3.393
training: epoch 104, step 6600, loss 32.272220, time: 3.393
training: epoch 104, step 6800, loss 32.232584, time: 3.392
training: epoch 104, step 7000, loss 32.249273, time: 3.392
training: epoch 104, step 7200, loss 32.240334, time: 3.391
training: epoch 104, step 7400, loss 32.236595, time: 3.391
training: epoch 104, step 7600, loss 32.274334, time: 3.391
training: epoch 104, step 7800, loss 32.259314, time: 3.391
training: epoch 104, step 7849, loss 32.252152, time: 0.832
validate: epoch 104, loss 35.355440, charcter error 6.383 time: 4.023
training: epoch 105, step 200, loss 32.639677, time: 3.350
training: epoch 105, step 400, loss 32.688419, time: 3.391
training: epoch 105, step 600, loss 32.250098, time: 3.402
training: epoch 105, step 800, loss 32.155480, time: 3.401
training: epoch 105, step 1000, loss 32.043738, time: 3.401
training: epoch 105, step 1200, loss 32.074530, time: 3.402
training: epoch 105, step 1400, loss 32.116317, time: 3.403
training: epoch 105, step 1600, loss 32.187829, time: 3.402
training: epoch 105, step 1800, loss 32.355394, time: 3.407
training: epoch 105, step 2000, loss 32.404224, time: 3.404
training: epoch 105, step 2200, loss 32.283867, time: 3.404
training: epoch 105, step 2400, loss 32.253059, time: 3.404
training: epoch 105, step 2600, loss 32.289263, time: 3.407
training: epoch 105, step 2800, loss 32.315594, time: 3.406
training: epoch 105, step 3000, loss 32.348957, time: 3.406
training: epoch 105, step 3200, loss 32.322450, time: 3.402
training: epoch 105, step 3400, loss 32.299522, time: 3.407
training: epoch 105, step 3600, loss 32.284536, time: 3.404
training: epoch 105, step 3800, loss 32.260419, time: 3.406
training: epoch 105, step 4000, loss 32.253856, time: 3.403
training: epoch 105, step 4200, loss 32.217298, time: 3.406
training: epoch 105, step 4400, loss 32.240850, time: 3.407
training: epoch 105, step 4600, loss 32.251409, time: 3.403
training: epoch 105, step 4800, loss 32.264197, time: 3.403
training: epoch 105, step 5000, loss 32.311727, time: 3.403
training: epoch 105, step 5200, loss 32.279786, time: 3.403
training: epoch 105, step 5400, loss 32.316531, time: 3.405
training: epoch 105, step 5600, loss 32.307382, time: 3.406
training: epoch 105, step 5800, loss 32.366454, time: 3.408
training: epoch 105, step 6000, loss 32.363354, time: 3.406
training: epoch 105, step 6200, loss 32.350530, time: 3.408
training: epoch 105, step 6400, loss 32.349267, time: 3.403
training: epoch 105, step 6600, loss 32.358658, time: 3.402
training: epoch 105, step 6800, loss 32.349509, time: 3.405
training: epoch 105, step 7000, loss 32.351856, time: 3.401
training: epoch 105, step 7200, loss 32.374067, time: 3.403
training: epoch 105, step 7400, loss 32.361227, time: 3.406
training: epoch 105, step 7600, loss 32.363094, time: 3.405
training: epoch 105, step 7800, loss 32.350509, time: 3.403
training: epoch 105, step 7849, loss 32.337914, time: 0.835
validate: epoch 105, loss 35.504633, charcter error 6.383 time: 4.021
training: epoch 106, step 200, loss 32.497723, time: 3.347
training: epoch 106, step 400, loss 32.493514, time: 3.391
training: epoch 106, step 600, loss 32.329277, time: 3.400
training: epoch 106, step 800, loss 32.143282, time: 3.393
training: epoch 106, step 1000, loss 32.161866, time: 3.400
training: epoch 106, step 1200, loss 32.166965, time: 3.404
training: epoch 106, step 1400, loss 32.244185, time: 3.402
training: epoch 106, step 1600, loss 32.191820, time: 3.401
training: epoch 106, step 1800, loss 32.116224, time: 3.399
training: epoch 106, step 2000, loss 32.121900, time: 3.400
training: epoch 106, step 2200, loss 32.133035, time: 3.401
training: epoch 106, step 2400, loss 32.061308, time: 3.397
training: epoch 106, step 2600, loss 32.020858, time: 3.399
training: epoch 106, step 2800, loss 32.004187, time: 3.398
training: epoch 106, step 3000, loss 32.090528, time: 3.400
training: epoch 106, step 3200, loss 32.063536, time: 3.404
training: epoch 106, step 3400, loss 32.109916, time: 3.399
training: epoch 106, step 3600, loss 32.163756, time: 3.400
training: epoch 106, step 3800, loss 32.156375, time: 3.398
training: epoch 106, step 4000, loss 32.154057, time: 3.403
training: epoch 106, step 4200, loss 32.176274, time: 3.405
training: epoch 106, step 4400, loss 32.205587, time: 3.401
training: epoch 106, step 4600, loss 32.174434, time: 3.399
training: epoch 106, step 4800, loss 32.193122, time: 3.400
training: epoch 106, step 5000, loss 32.187821, time: 3.400
training: epoch 106, step 5200, loss 32.216909, time: 3.399
training: epoch 106, step 5400, loss 32.249924, time: 3.393
training: epoch 106, step 5600, loss 32.233450, time: 3.391
training: epoch 106, step 5800, loss 32.239286, time: 3.397
training: epoch 106, step 6000, loss 32.210094, time: 3.401
training: epoch 106, step 6200, loss 32.199109, time: 3.398
training: epoch 106, step 6400, loss 32.184007, time: 3.396
training: epoch 106, step 6600, loss 32.198209, time: 3.401
training: epoch 106, step 6800, loss 32.242883, time: 3.396
training: epoch 106, step 7000, loss 32.269319, time: 3.398
training: epoch 106, step 7200, loss 32.270947, time: 3.397
training: epoch 106, step 7400, loss 32.254708, time: 3.398
training: epoch 106, step 7600, loss 32.268452, time: 3.400
training: epoch 106, step 7800, loss 32.258522, time: 3.400
training: epoch 106, step 7849, loss 32.266974, time: 0.833
validate: epoch 106, loss 35.389890, charcter error 6.381 time: 4.011
training: epoch 107, step 200, loss 32.006661, time: 3.347
training: epoch 107, step 400, loss 31.519769, time: 3.391
training: epoch 107, step 600, loss 31.652153, time: 3.397
training: epoch 107, step 800, loss 31.825136, time: 3.401
training: epoch 107, step 1000, loss 31.877713, time: 3.402
training: epoch 107, step 1200, loss 32.021739, time: 3.397
training: epoch 107, step 1400, loss 32.157108, time: 3.401
training: epoch 107, step 1600, loss 32.210301, time: 3.401
training: epoch 107, step 1800, loss 32.355079, time: 3.399
training: epoch 107, step 2000, loss 32.352305, time: 3.392
training: epoch 107, step 2200, loss 32.303620, time: 3.400
training: epoch 107, step 2400, loss 32.275134, time: 3.400
training: epoch 107, step 2600, loss 32.269935, time: 3.403
training: epoch 107, step 2800, loss 32.295700, time: 3.400
training: epoch 107, step 3000, loss 32.226777, time: 3.400
training: epoch 107, step 3200, loss 32.233264, time: 3.397
training: epoch 107, step 3400, loss 32.257361, time: 3.399
training: epoch 107, step 3600, loss 32.174721, time: 3.394
training: epoch 107, step 3800, loss 32.242148, time: 3.393
training: epoch 107, step 4000, loss 32.263061, time: 3.394
training: epoch 107, step 4200, loss 32.304826, time: 3.396
training: epoch 107, step 4400, loss 32.299260, time: 3.399
training: epoch 107, step 4600, loss 32.296993, time: 3.395
training: epoch 107, step 4800, loss 32.305710, time: 3.394
training: epoch 107, step 5000, loss 32.294581, time: 3.393
training: epoch 107, step 5200, loss 32.268620, time: 3.392
training: epoch 107, step 5400, loss 32.279274, time: 3.394
training: epoch 107, step 5600, loss 32.268753, time: 3.395
training: epoch 107, step 5800, loss 32.228675, time: 3.392
training: epoch 107, step 6000, loss 32.257974, time: 3.393
training: epoch 107, step 6200, loss 32.254705, time: 3.393
training: epoch 107, step 6400, loss 32.251121, time: 3.390
training: epoch 107, step 6600, loss 32.266071, time: 3.391
training: epoch 107, step 6800, loss 32.288159, time: 3.393
training: epoch 107, step 7000, loss 32.302924, time: 3.392
training: epoch 107, step 7200, loss 32.269922, time: 3.393
training: epoch 107, step 7400, loss 32.250310, time: 3.394
training: epoch 107, step 7600, loss 32.234042, time: 3.391
training: epoch 107, step 7800, loss 32.255106, time: 3.391
training: epoch 107, step 7849, loss 32.251830, time: 0.830
validate: epoch 107, loss 35.762814, charcter error 6.442 time: 4.021
training: epoch 108, step 200, loss 32.609366, time: 3.346
training: epoch 108, step 400, loss 31.923311, time: 3.383
training: epoch 108, step 600, loss 31.822937, time: 3.393
training: epoch 108, step 800, loss 31.964008, time: 3.391
training: epoch 108, step 1000, loss 32.196346, time: 3.394
training: epoch 108, step 1200, loss 32.352764, time: 3.390
training: epoch 108, step 1400, loss 32.279024, time: 3.386
training: epoch 108, step 1600, loss 32.361490, time: 3.389
training: epoch 108, step 1800, loss 32.335010, time: 3.388
training: epoch 108, step 2000, loss 32.307273, time: 3.386
training: epoch 108, step 2200, loss 32.275259, time: 3.394
training: epoch 108, step 2400, loss 32.276737, time: 3.393
training: epoch 108, step 2600, loss 32.265943, time: 3.392
training: epoch 108, step 2800, loss 32.279857, time: 3.389
training: epoch 108, step 3000, loss 32.249821, time: 3.392
training: epoch 108, step 3200, loss 32.217841, time: 3.393
training: epoch 108, step 3400, loss 32.198221, time: 3.393
training: epoch 108, step 3600, loss 32.234276, time: 3.393
training: epoch 108, step 3800, loss 32.188958, time: 3.392
training: epoch 108, step 4000, loss 32.182174, time: 3.394
training: epoch 108, step 4200, loss 32.180926, time: 3.506
training: epoch 108, step 4400, loss 32.180699, time: 3.516
training: epoch 108, step 4600, loss 32.139724, time: 3.555
training: epoch 108, step 4800, loss 32.119378, time: 3.555
training: epoch 108, step 5000, loss 32.168730, time: 3.541
training: epoch 108, step 5200, loss 32.166038, time: 3.547
training: epoch 108, step 5400, loss 32.174062, time: 3.548
training: epoch 108, step 5600, loss 32.211364, time: 3.536
training: epoch 108, step 5800, loss 32.226055, time: 3.572
training: epoch 108, step 6000, loss 32.233742, time: 3.531
training: epoch 108, step 6200, loss 32.224839, time: 3.492
training: epoch 108, step 6400, loss 32.221187, time: 3.580
training: epoch 108, step 6600, loss 32.222745, time: 3.595
training: epoch 108, step 6800, loss 32.260166, time: 3.553
training: epoch 108, step 7000, loss 32.296565, time: 3.510
training: epoch 108, step 7200, loss 32.298272, time: 3.512
training: epoch 108, step 7400, loss 32.294588, time: 3.491
training: epoch 108, step 7600, loss 32.269948, time: 3.472
training: epoch 108, step 7800, loss 32.251691, time: 3.474
training: epoch 108, step 7849, loss 32.255316, time: 0.855
validate: epoch 108, loss 35.597202, charcter error 6.406 time: 4.034
training: epoch 109, step 200, loss 32.669933, time: 3.431
training: epoch 109, step 400, loss 31.984690, time: 3.462
training: epoch 109, step 600, loss 32.048118, time: 3.450
training: epoch 109, step 800, loss 31.992482, time: 3.441
training: epoch 109, step 1000, loss 32.035316, time: 3.448
training: epoch 109, step 1200, loss 32.152109, time: 3.429
training: epoch 109, step 1400, loss 32.153184, time: 3.427
training: epoch 109, step 1600, loss 32.085814, time: 3.431
training: epoch 109, step 1800, loss 32.172886, time: 3.420
training: epoch 109, step 2000, loss 32.127523, time: 3.420
training: epoch 109, step 2200, loss 32.003959, time: 3.417
training: epoch 109, step 2400, loss 32.033083, time: 3.418
training: epoch 109, step 2600, loss 31.985640, time: 3.414
training: epoch 109, step 2800, loss 31.958880, time: 3.408
training: epoch 109, step 3000, loss 31.972930, time: 3.410
training: epoch 109, step 3200, loss 31.977077, time: 3.404
training: epoch 109, step 3400, loss 32.046308, time: 3.407
training: epoch 109, step 3600, loss 32.042058, time: 3.402
training: epoch 109, step 3800, loss 32.030598, time: 3.408
training: epoch 109, step 4000, loss 32.030126, time: 3.406
training: epoch 109, step 4200, loss 32.012722, time: 3.395
training: epoch 109, step 4400, loss 32.025093, time: 3.395
training: epoch 109, step 4600, loss 32.021070, time: 3.395
training: epoch 109, step 4800, loss 32.031127, time: 3.392
training: epoch 109, step 5000, loss 32.098088, time: 3.394
training: epoch 109, step 5200, loss 32.104318, time: 3.393
training: epoch 109, step 5400, loss 32.100538, time: 3.396
training: epoch 109, step 5600, loss 32.146406, time: 3.390
training: epoch 109, step 5800, loss 32.129407, time: 3.389
training: epoch 109, step 6000, loss 32.132512, time: 3.394
training: epoch 109, step 6200, loss 32.147577, time: 3.392
training: epoch 109, step 6400, loss 32.151554, time: 3.389
training: epoch 109, step 6600, loss 32.187352, time: 3.393
training: epoch 109, step 6800, loss 32.181927, time: 3.392
training: epoch 109, step 7000, loss 32.171937, time: 3.396
training: epoch 109, step 7200, loss 32.159920, time: 3.394
training: epoch 109, step 7400, loss 32.183180, time: 3.422
training: epoch 109, step 7600, loss 32.180919, time: 3.488
training: epoch 109, step 7800, loss 32.198622, time: 3.504
training: epoch 109, step 7849, loss 32.204460, time: 0.858
validate: epoch 109, loss 35.452057, charcter error 6.385 time: 4.037
training: epoch 110, step 200, loss 31.819733, time: 3.484
training: epoch 110, step 400, loss 32.175514, time: 3.542
training: epoch 110, step 600, loss 32.450829, time: 3.505
training: epoch 110, step 800, loss 32.640412, time: 3.502
training: epoch 110, step 1000, loss 32.755365, time: 3.492
training: epoch 110, step 1200, loss 32.580002, time: 3.479
training: epoch 110, step 1400, loss 32.564729, time: 3.507
training: epoch 110, step 1600, loss 32.609678, time: 3.510
training: epoch 110, step 1800, loss 32.487168, time: 3.523
training: epoch 110, step 2000, loss 32.368613, time: 3.533
training: epoch 110, step 2200, loss 32.244304, time: 3.522
training: epoch 110, step 2400, loss 32.245911, time: 3.520
training: epoch 110, step 2600, loss 32.235691, time: 3.487
training: epoch 110, step 2800, loss 32.294321, time: 3.388
training: epoch 110, step 3000, loss 32.279346, time: 3.391
training: epoch 110, step 3200, loss 32.324830, time: 3.407
training: epoch 110, step 3400, loss 32.230644, time: 3.413
training: epoch 110, step 3600, loss 32.216318, time: 3.490
training: epoch 110, step 3800, loss 32.252885, time: 3.558
training: epoch 110, step 4000, loss 32.218016, time: 3.554
training: epoch 110, step 4200, loss 32.195690, time: 3.492
training: epoch 110, step 4400, loss 32.174945, time: 3.512
training: epoch 110, step 4600, loss 32.153544, time: 3.471
training: epoch 110, step 4800, loss 32.122245, time: 3.481
training: epoch 110, step 5000, loss 32.144955, time: 3.480
training: epoch 110, step 5200, loss 32.127947, time: 3.492
training: epoch 110, step 5400, loss 32.125980, time: 3.509
training: epoch 110, step 5600, loss 32.189199, time: 3.480
training: epoch 110, step 5800, loss 32.176912, time: 3.499
training: epoch 110, step 6000, loss 32.185370, time: 3.522
training: epoch 110, step 6200, loss 32.159091, time: 3.498
training: epoch 110, step 6400, loss 32.145697, time: 3.479
training: epoch 110, step 6600, loss 32.145242, time: 3.481
training: epoch 110, step 6800, loss 32.126224, time: 3.464
training: epoch 110, step 7000, loss 32.125115, time: 3.498
training: epoch 110, step 7200, loss 32.101391, time: 3.472
training: epoch 110, step 7400, loss 32.098870, time: 3.513
training: epoch 110, step 7600, loss 32.114861, time: 3.634
training: epoch 110, step 7800, loss 32.123851, time: 3.571
training: epoch 110, step 7849, loss 32.121676, time: 0.861
validate: epoch 110, loss 35.839925, charcter error 6.471 time: 4.040
training: epoch 111, step 200, loss 32.425019, time: 3.503
training: epoch 111, step 400, loss 31.858295, time: 3.529
training: epoch 111, step 600, loss 32.198161, time: 3.518
training: epoch 111, step 800, loss 31.990244, time: 3.500
training: epoch 111, step 1000, loss 31.999798, time: 3.470
training: epoch 111, step 1200, loss 31.932587, time: 3.536
training: epoch 111, step 1400, loss 31.931441, time: 3.505
training: epoch 111, step 1600, loss 31.988880, time: 3.493
training: epoch 111, step 1800, loss 31.980371, time: 3.503
training: epoch 111, step 2000, loss 31.973941, time: 3.469
training: epoch 111, step 2200, loss 32.021828, time: 3.465
training: epoch 111, step 2400, loss 31.953138, time: 3.466
training: epoch 111, step 2600, loss 31.991925, time: 3.460
training: epoch 111, step 2800, loss 32.063974, time: 3.463
training: epoch 111, step 3000, loss 32.010595, time: 3.455
training: epoch 111, step 3200, loss 32.020535, time: 3.435
training: epoch 111, step 3400, loss 32.035223, time: 3.436
training: epoch 111, step 3600, loss 32.083163, time: 3.443
training: epoch 111, step 3800, loss 32.052692, time: 3.428
training: epoch 111, step 4000, loss 32.039642, time: 3.423
training: epoch 111, step 4200, loss 32.017195, time: 3.422
training: epoch 111, step 4400, loss 32.045152, time: 3.419
training: epoch 111, step 4600, loss 32.061626, time: 3.416
training: epoch 111, step 4800, loss 32.044308, time: 3.411
training: epoch 111, step 5000, loss 32.034732, time: 3.410
training: epoch 111, step 5200, loss 32.062909, time: 3.413
training: epoch 111, step 5400, loss 32.079003, time: 3.413
training: epoch 111, step 5600, loss 32.089135, time: 3.405
training: epoch 111, step 5800, loss 32.066334, time: 3.406
training: epoch 111, step 6000, loss 32.096417, time: 3.410
training: epoch 111, step 6200, loss 32.103327, time: 3.407
training: epoch 111, step 6400, loss 32.088686, time: 3.410
training: epoch 111, step 6600, loss 32.111505, time: 3.408
training: epoch 111, step 6800, loss 32.112951, time: 3.407
training: epoch 111, step 7000, loss 32.103199, time: 3.404
training: epoch 111, step 7200, loss 32.092336, time: 3.409
training: epoch 111, step 7400, loss 32.075893, time: 3.407
training: epoch 111, step 7600, loss 32.053926, time: 3.401
training: epoch 111, step 7800, loss 32.060165, time: 3.405
training: epoch 111, step 7849, loss 32.059691, time: 0.835
validate: epoch 111, loss 35.481066, charcter error 6.405 time: 4.030
training: epoch 112, step 200, loss 31.755551, time: 3.346
training: epoch 112, step 400, loss 31.962101, time: 3.395
training: epoch 112, step 600, loss 31.796634, time: 3.401
training: epoch 112, step 800, loss 31.754625, time: 3.398
training: epoch 112, step 1000, loss 31.829059, time: 3.398
training: epoch 112, step 1200, loss 31.718504, time: 3.396
training: epoch 112, step 1400, loss 31.910213, time: 3.400
training: epoch 112, step 1600, loss 31.918437, time: 3.398
training: epoch 112, step 1800, loss 32.049738, time: 3.398
training: epoch 112, step 2000, loss 32.077948, time: 3.400
training: epoch 112, step 2200, loss 32.084217, time: 3.402
training: epoch 112, step 2400, loss 32.191764, time: 3.401
training: epoch 112, step 2600, loss 32.229474, time: 3.396
training: epoch 112, step 2800, loss 32.182532, time: 3.400
training: epoch 112, step 3000, loss 32.199928, time: 3.400
training: epoch 112, step 3200, loss 32.141259, time: 3.399
training: epoch 112, step 3400, loss 32.152420, time: 3.403
training: epoch 112, step 3600, loss 32.066116, time: 3.394
training: epoch 112, step 3800, loss 31.995577, time: 3.393
training: epoch 112, step 4000, loss 32.051190, time: 3.399
training: epoch 112, step 4200, loss 32.012327, time: 3.397
training: epoch 112, step 4400, loss 32.016727, time: 3.399
training: epoch 112, step 4600, loss 31.993375, time: 3.400
training: epoch 112, step 4800, loss 32.010749, time: 3.398
training: epoch 112, step 5000, loss 32.029490, time: 3.398
training: epoch 112, step 5200, loss 32.035476, time: 3.402
training: epoch 112, step 5400, loss 32.070722, time: 3.403
training: epoch 112, step 5600, loss 32.080411, time: 3.398
training: epoch 112, step 5800, loss 32.055865, time: 3.400
training: epoch 112, step 6000, loss 32.089492, time: 3.399
training: epoch 112, step 6200, loss 32.070091, time: 3.403
training: epoch 112, step 6400, loss 32.078603, time: 3.402
training: epoch 112, step 6600, loss 32.067780, time: 3.402
training: epoch 112, step 6800, loss 32.085041, time: 3.401
training: epoch 112, step 7000, loss 32.046707, time: 3.396
training: epoch 112, step 7200, loss 32.051713, time: 3.396
training: epoch 112, step 7400, loss 32.047225, time: 3.399
training: epoch 112, step 7600, loss 32.067013, time: 3.403
training: epoch 112, step 7800, loss 32.075414, time: 3.400
training: epoch 112, step 7849, loss 32.081278, time: 0.832
validate: epoch 112, loss 35.431995, charcter error 6.381 time: 4.024
training: epoch 113, step 200, loss 31.208368, time: 3.350
training: epoch 113, step 400, loss 31.467320, time: 3.392
training: epoch 113, step 600, loss 31.446350, time: 3.401
training: epoch 113, step 800, loss 31.659886, time: 3.405
training: epoch 113, step 1000, loss 31.828045, time: 3.403
training: epoch 113, step 1200, loss 31.940990, time: 3.409
training: epoch 113, step 1400, loss 31.897863, time: 3.405
training: epoch 113, step 1600, loss 31.935769, time: 3.408
training: epoch 113, step 1800, loss 31.916937, time: 3.406
training: epoch 113, step 2000, loss 31.946726, time: 3.403
training: epoch 113, step 2200, loss 31.934869, time: 3.407
training: epoch 113, step 2400, loss 31.937299, time: 3.406
training: epoch 113, step 2600, loss 31.836917, time: 3.406
training: epoch 113, step 2800, loss 31.876700, time: 3.408
training: epoch 113, step 3000, loss 31.901265, time: 3.405
training: epoch 113, step 3200, loss 31.922706, time: 3.400
training: epoch 113, step 3400, loss 31.910448, time: 3.403
training: epoch 113, step 3600, loss 31.913180, time: 3.402
training: epoch 113, step 3800, loss 31.929644, time: 3.400
training: epoch 113, step 4000, loss 31.921977, time: 3.402
training: epoch 113, step 4200, loss 31.897526, time: 3.406
training: epoch 113, step 4400, loss 31.926264, time: 3.408
training: epoch 113, step 4600, loss 31.954383, time: 3.410
training: epoch 113, step 4800, loss 31.956603, time: 3.406
training: epoch 113, step 5000, loss 31.989750, time: 3.406
training: epoch 113, step 5200, loss 31.989897, time: 3.407
training: epoch 113, step 5400, loss 31.975512, time: 3.407
training: epoch 113, step 5600, loss 31.981420, time: 3.411
training: epoch 113, step 5800, loss 31.966929, time: 3.409
training: epoch 113, step 6000, loss 31.991655, time: 3.406
training: epoch 113, step 6200, loss 31.985914, time: 3.406
training: epoch 113, step 6400, loss 31.979559, time: 3.406
training: epoch 113, step 6600, loss 31.992038, time: 3.405
training: epoch 113, step 6800, loss 31.996238, time: 3.410
training: epoch 113, step 7000, loss 32.006965, time: 3.403
training: epoch 113, step 7200, loss 32.002953, time: 3.403
training: epoch 113, step 7400, loss 32.015067, time: 3.405
training: epoch 113, step 7600, loss 31.975629, time: 3.403
training: epoch 113, step 7800, loss 31.991788, time: 3.397
training: epoch 113, step 7849, loss 31.995523, time: 0.833
validate: epoch 113, loss 35.638377, charcter error 6.403 time: 4.023
training: epoch 114, step 200, loss 31.766394, time: 3.353
training: epoch 114, step 400, loss 31.956321, time: 3.399
training: epoch 114, step 600, loss 31.848149, time: 3.408
training: epoch 114, step 800, loss 32.049207, time: 3.401
training: epoch 114, step 1000, loss 31.943940, time: 3.401
training: epoch 114, step 1200, loss 31.856225, time: 3.405
training: epoch 114, step 1400, loss 31.774895, time: 3.409
training: epoch 114, step 1600, loss 31.887445, time: 3.410
training: epoch 114, step 1800, loss 31.757320, time: 3.404
training: epoch 114, step 2000, loss 31.772996, time: 3.410
training: epoch 114, step 2200, loss 31.799517, time: 3.411
training: epoch 114, step 2400, loss 31.888982, time: 3.408
training: epoch 114, step 2600, loss 31.934828, time: 3.406
training: epoch 114, step 2800, loss 31.959377, time: 3.407
training: epoch 114, step 3000, loss 31.924588, time: 3.406
training: epoch 114, step 3200, loss 31.909762, time: 3.406
training: epoch 114, step 3400, loss 31.883666, time: 3.410
training: epoch 114, step 3600, loss 31.867777, time: 3.410
training: epoch 114, step 3800, loss 31.877330, time: 3.405
training: epoch 114, step 4000, loss 31.909626, time: 3.408
training: epoch 114, step 4200, loss 31.879859, time: 3.404
training: epoch 114, step 4400, loss 31.842700, time: 3.407
training: epoch 114, step 4600, loss 31.868284, time: 3.407
training: epoch 114, step 4800, loss 31.885644, time: 3.407
training: epoch 114, step 5000, loss 31.881581, time: 3.407
training: epoch 114, step 5200, loss 31.892236, time: 3.400
training: epoch 114, step 5400, loss 31.891507, time: 3.403
training: epoch 114, step 5600, loss 31.908485, time: 3.405
training: epoch 114, step 5800, loss 31.949337, time: 3.404
training: epoch 114, step 6000, loss 31.976197, time: 3.403
training: epoch 114, step 6200, loss 31.999137, time: 3.407
training: epoch 114, step 6400, loss 31.976426, time: 3.405
training: epoch 114, step 6600, loss 31.972031, time: 3.405
training: epoch 114, step 6800, loss 31.961532, time: 3.402
training: epoch 114, step 7000, loss 31.948035, time: 3.403
training: epoch 114, step 7200, loss 31.983728, time: 3.406
training: epoch 114, step 7400, loss 31.981034, time: 3.403
training: epoch 114, step 7600, loss 31.946198, time: 3.403
training: epoch 114, step 7800, loss 31.939437, time: 3.404
training: epoch 114, step 7849, loss 31.939153, time: 0.836
validate: epoch 114, loss 35.291442, charcter error 6.348 time: 4.016
    - [Info] The checkpoint file has been updated.
training: epoch 115, step 200, loss 32.850582, time: 3.357
training: epoch 115, step 400, loss 32.806506, time: 3.394
training: epoch 115, step 600, loss 32.631238, time: 3.398
training: epoch 115, step 800, loss 32.630041, time: 3.396
training: epoch 115, step 1000, loss 32.483138, time: 3.402
training: epoch 115, step 1200, loss 32.620827, time: 3.401
training: epoch 115, step 1400, loss 32.511153, time: 3.400
training: epoch 115, step 1600, loss 32.508364, time: 3.401
training: epoch 115, step 1800, loss 32.418706, time: 3.397
training: epoch 115, step 2000, loss 32.318116, time: 3.397
training: epoch 115, step 2200, loss 32.373768, time: 3.400
training: epoch 115, step 2400, loss 32.378956, time: 3.396
training: epoch 115, step 2600, loss 32.366662, time: 3.393
training: epoch 115, step 2800, loss 32.309917, time: 3.395
training: epoch 115, step 3000, loss 32.242105, time: 3.397
training: epoch 115, step 3200, loss 32.231217, time: 3.396
training: epoch 115, step 3400, loss 32.220009, time: 3.391
training: epoch 115, step 3600, loss 32.178694, time: 3.395
training: epoch 115, step 3800, loss 32.188195, time: 3.394
training: epoch 115, step 4000, loss 32.199483, time: 3.391
training: epoch 115, step 4200, loss 32.246915, time: 3.390
training: epoch 115, step 4400, loss 32.194143, time: 3.391
training: epoch 115, step 4600, loss 32.201036, time: 3.391
training: epoch 115, step 4800, loss 32.159447, time: 3.392
training: epoch 115, step 5000, loss 32.170049, time: 3.393
training: epoch 115, step 5200, loss 32.199678, time: 3.391
training: epoch 115, step 5400, loss 32.212051, time: 3.392
training: epoch 115, step 5600, loss 32.193955, time: 3.393
training: epoch 115, step 5800, loss 32.185923, time: 3.396
training: epoch 115, step 6000, loss 32.185848, time: 3.395
training: epoch 115, step 6200, loss 32.176321, time: 3.395
training: epoch 115, step 6400, loss 32.150690, time: 3.392
training: epoch 115, step 6600, loss 32.111988, time: 3.390
training: epoch 115, step 6800, loss 32.097281, time: 3.392
training: epoch 115, step 7000, loss 32.095148, time: 3.389
training: epoch 115, step 7200, loss 32.092837, time: 3.399
training: epoch 115, step 7400, loss 32.083328, time: 3.397
training: epoch 115, step 7600, loss 32.088411, time: 3.394
training: epoch 115, step 7800, loss 32.067499, time: 3.394
training: epoch 115, step 7849, loss 32.073979, time: 0.832
validate: epoch 115, loss 35.597030, charcter error 6.398 time: 4.018
training: epoch 116, step 200, loss 30.869583, time: 3.342
training: epoch 116, step 400, loss 31.457476, time: 3.385
training: epoch 116, step 600, loss 31.724201, time: 3.390
training: epoch 116, step 800, loss 31.757019, time: 3.393
training: epoch 116, step 1000, loss 31.731626, time: 3.395
training: epoch 116, step 1200, loss 31.798642, time: 3.392
training: epoch 116, step 1400, loss 31.841472, time: 3.390
training: epoch 116, step 1600, loss 31.756677, time: 3.392
training: epoch 116, step 1800, loss 31.817614, time: 3.388
training: epoch 116, step 2000, loss 31.749353, time: 3.390
training: epoch 116, step 2200, loss 31.803186, time: 3.401
training: epoch 116, step 2400, loss 31.728428, time: 3.386
training: epoch 116, step 2600, loss 31.693893, time: 3.398
training: epoch 116, step 2800, loss 31.775771, time: 3.390
training: epoch 116, step 3000, loss 31.834826, time: 3.393
training: epoch 116, step 3200, loss 31.865664, time: 3.399
training: epoch 116, step 3400, loss 31.885131, time: 3.389
training: epoch 116, step 3600, loss 31.838643, time: 3.393
training: epoch 116, step 3800, loss 31.812180, time: 3.394
training: epoch 116, step 4000, loss 31.860124, time: 3.402
training: epoch 116, step 4200, loss 31.795608, time: 3.393
training: epoch 116, step 4400, loss 31.741843, time: 3.398
training: epoch 116, step 4600, loss 31.793703, time: 3.398
training: epoch 116, step 4800, loss 31.798268, time: 3.400
training: epoch 116, step 5000, loss 31.820790, time: 3.396
training: epoch 116, step 5200, loss 31.830981, time: 3.393
training: epoch 116, step 5400, loss 31.857631, time: 3.393
training: epoch 116, step 5600, loss 31.864816, time: 3.389
training: epoch 116, step 5800, loss 31.888370, time: 3.394
training: epoch 116, step 6000, loss 31.890734, time: 3.394
training: epoch 116, step 6200, loss 31.879043, time: 3.391
training: epoch 116, step 6400, loss 31.886536, time: 3.392
training: epoch 116, step 6600, loss 31.889111, time: 3.389
training: epoch 116, step 6800, loss 31.892115, time: 3.390
training: epoch 116, step 7000, loss 31.917681, time: 3.393
training: epoch 116, step 7200, loss 31.926575, time: 3.388
training: epoch 116, step 7400, loss 31.951110, time: 3.398
training: epoch 116, step 7600, loss 31.943551, time: 3.393
training: epoch 116, step 7800, loss 31.948681, time: 3.391
training: epoch 116, step 7849, loss 31.953501, time: 0.830
validate: epoch 116, loss 35.465349, charcter error 6.364 time: 4.025
training: epoch 117, step 200, loss 31.927568, time: 3.349
training: epoch 117, step 400, loss 31.951188, time: 3.391
training: epoch 117, step 600, loss 32.114759, time: 3.396
training: epoch 117, step 800, loss 31.981027, time: 3.394
training: epoch 117, step 1000, loss 31.991670, time: 3.396
training: epoch 117, step 1200, loss 32.157240, time: 3.395
training: epoch 117, step 1400, loss 32.081563, time: 3.396
training: epoch 117, step 1600, loss 31.991303, time: 3.391
training: epoch 117, step 1800, loss 32.025713, time: 3.392
training: epoch 117, step 2000, loss 32.080896, time: 3.397
training: epoch 117, step 2200, loss 32.072816, time: 3.393
training: epoch 117, step 2400, loss 32.117297, time: 3.394
training: epoch 117, step 2600, loss 32.119264, time: 3.396
training: epoch 117, step 2800, loss 32.106051, time: 3.394
training: epoch 117, step 3000, loss 32.131856, time: 3.397
training: epoch 117, step 3200, loss 32.067449, time: 3.391
training: epoch 117, step 3400, loss 32.081791, time: 3.394
training: epoch 117, step 3600, loss 32.019487, time: 3.389
training: epoch 117, step 3800, loss 31.996530, time: 3.391
training: epoch 117, step 4000, loss 31.992530, time: 3.394
training: epoch 117, step 4200, loss 31.991697, time: 3.392
training: epoch 117, step 4400, loss 31.960213, time: 3.392
training: epoch 117, step 4600, loss 31.966025, time: 3.394
training: epoch 117, step 4800, loss 31.975360, time: 3.390
training: epoch 117, step 5000, loss 31.981779, time: 3.391
training: epoch 117, step 5200, loss 31.951300, time: 3.389
training: epoch 117, step 5400, loss 31.987469, time: 3.396
training: epoch 117, step 5600, loss 31.958747, time: 3.391
training: epoch 117, step 5800, loss 31.985325, time: 3.394
training: epoch 117, step 6000, loss 31.999982, time: 3.394
training: epoch 117, step 6200, loss 31.989733, time: 3.393
training: epoch 117, step 6400, loss 31.984305, time: 3.391
training: epoch 117, step 6600, loss 31.996272, time: 3.394
training: epoch 117, step 6800, loss 31.991308, time: 3.391
training: epoch 117, step 7000, loss 32.004503, time: 3.393
training: epoch 117, step 7200, loss 31.999201, time: 3.391
training: epoch 117, step 7400, loss 32.003704, time: 3.393
training: epoch 117, step 7600, loss 31.974834, time: 3.395
training: epoch 117, step 7800, loss 31.955594, time: 3.393
training: epoch 117, step 7849, loss 31.958535, time: 0.833
validate: epoch 117, loss 35.263934, charcter error 6.360 time: 4.016
training: epoch 118, step 200, loss 31.402562, time: 3.336
training: epoch 118, step 400, loss 31.831940, time: 3.378
training: epoch 118, step 600, loss 31.849677, time: 3.384
training: epoch 118, step 800, loss 32.196938, time: 3.388
training: epoch 118, step 1000, loss 32.350718, time: 3.384
training: epoch 118, step 1200, loss 32.302695, time: 3.383
training: epoch 118, step 1400, loss 32.278570, time: 3.388
training: epoch 118, step 1600, loss 32.108140, time: 3.392
training: epoch 118, step 1800, loss 32.155706, time: 3.391
training: epoch 118, step 2000, loss 32.174956, time: 3.387
training: epoch 118, step 2200, loss 32.213068, time: 3.387
training: epoch 118, step 2400, loss 32.147708, time: 3.390
training: epoch 118, step 2600, loss 32.116209, time: 3.387
training: epoch 118, step 2800, loss 32.154611, time: 3.391
training: epoch 118, step 3000, loss 32.153298, time: 3.390
training: epoch 118, step 3200, loss 32.099073, time: 3.391
training: epoch 118, step 3400, loss 32.044536, time: 3.387
training: epoch 118, step 3600, loss 32.047691, time: 3.387
training: epoch 118, step 3800, loss 32.077540, time: 3.386
training: epoch 118, step 4000, loss 32.015987, time: 3.389
training: epoch 118, step 4200, loss 32.022976, time: 3.386
training: epoch 118, step 4400, loss 31.997210, time: 3.387
training: epoch 118, step 4600, loss 32.036044, time: 3.392
training: epoch 118, step 4800, loss 31.971165, time: 3.386
training: epoch 118, step 5000, loss 31.922847, time: 3.387
training: epoch 118, step 5200, loss 31.925312, time: 3.392
training: epoch 118, step 5400, loss 31.902206, time: 3.390
training: epoch 118, step 5600, loss 31.914015, time: 3.388
training: epoch 118, step 5800, loss 31.914695, time: 3.391
training: epoch 118, step 6000, loss 31.889875, time: 3.392
training: epoch 118, step 6200, loss 31.863322, time: 3.388
training: epoch 118, step 6400, loss 31.870607, time: 3.391
training: epoch 118, step 6600, loss 31.872471, time: 3.389
training: epoch 118, step 6800, loss 31.881484, time: 3.389
training: epoch 118, step 7000, loss 31.891879, time: 3.391
training: epoch 118, step 7200, loss 31.888054, time: 3.387
training: epoch 118, step 7400, loss 31.904991, time: 3.396
training: epoch 118, step 7600, loss 31.905324, time: 3.435
training: epoch 118, step 7800, loss 31.914679, time: 3.469
training: epoch 118, step 7849, loss 31.916006, time: 0.867
validate: epoch 118, loss 35.320884, charcter error 6.356 time: 4.031
training: epoch 119, step 200, loss 30.778390, time: 3.613
training: epoch 119, step 400, loss 30.915222, time: 3.559
training: epoch 119, step 600, loss 31.268701, time: 3.566
training: epoch 119, step 800, loss 31.344108, time: 3.538
training: epoch 119, step 1000, loss 31.157210, time: 3.534
training: epoch 119, step 1200, loss 31.344585, time: 3.547
training: epoch 119, step 1400, loss 31.393686, time: 3.554
training: epoch 119, step 1600, loss 31.270823, time: 3.502
training: epoch 119, step 1800, loss 31.309241, time: 3.586
training: epoch 119, step 2000, loss 31.417069, time: 3.614
training: epoch 119, step 2200, loss 31.433043, time: 3.517
training: epoch 119, step 2400, loss 31.434437, time: 3.485
training: epoch 119, step 2600, loss 31.518857, time: 3.465
training: epoch 119, step 2800, loss 31.648806, time: 3.467
training: epoch 119, step 3000, loss 31.719687, time: 3.470
training: epoch 119, step 3200, loss 31.794391, time: 3.437
training: epoch 119, step 3400, loss 31.743067, time: 3.451
training: epoch 119, step 3600, loss 31.769755, time: 3.449
training: epoch 119, step 3800, loss 31.805386, time: 3.431
training: epoch 119, step 4000, loss 31.841618, time: 3.424
training: epoch 119, step 4200, loss 31.883823, time: 3.416
training: epoch 119, step 4400, loss 31.912317, time: 3.413
training: epoch 119, step 4600, loss 31.920990, time: 3.408
training: epoch 119, step 4800, loss 31.911030, time: 3.412
training: epoch 119, step 5000, loss 31.911449, time: 3.404
training: epoch 119, step 5200, loss 31.901104, time: 3.403
training: epoch 119, step 5400, loss 31.889960, time: 3.401
training: epoch 119, step 5600, loss 31.897294, time: 3.401
training: epoch 119, step 5800, loss 31.923054, time: 3.400
training: epoch 119, step 6000, loss 31.906263, time: 3.396
training: epoch 119, step 6200, loss 31.878775, time: 3.393
training: epoch 119, step 6400, loss 31.868866, time: 3.400
training: epoch 119, step 6600, loss 31.897781, time: 3.391
training: epoch 119, step 6800, loss 31.933436, time: 3.396
training: epoch 119, step 7000, loss 31.919482, time: 3.392
training: epoch 119, step 7200, loss 31.901601, time: 3.398
training: epoch 119, step 7400, loss 31.903917, time: 3.392
training: epoch 119, step 7600, loss 31.883497, time: 3.392
training: epoch 119, step 7800, loss 31.865710, time: 3.386
training: epoch 119, step 7849, loss 31.868919, time: 0.830
validate: epoch 119, loss 35.246703, charcter error 6.348 time: 4.044
training: epoch 120, step 200, loss 32.414281, time: 3.346
training: epoch 120, step 400, loss 32.458860, time: 3.386
training: epoch 120, step 600, loss 32.358264, time: 3.395
training: epoch 120, step 800, loss 32.457421, time: 3.393
training: epoch 120, step 1000, loss 32.262721, time: 3.388
training: epoch 120, step 1200, loss 32.250656, time: 3.386
training: epoch 120, step 1400, loss 32.073488, time: 3.390
training: epoch 120, step 1600, loss 31.923854, time: 3.389
training: epoch 120, step 1800, loss 31.958982, time: 3.388
training: epoch 120, step 2000, loss 31.956334, time: 3.389
training: epoch 120, step 2200, loss 31.834959, time: 3.389
training: epoch 120, step 2400, loss 31.822516, time: 3.387
training: epoch 120, step 2600, loss 31.791592, time: 3.403
training: epoch 120, step 2800, loss 31.765834, time: 3.533
training: epoch 120, step 3000, loss 31.792901, time: 3.543
training: epoch 120, step 3200, loss 31.793397, time: 3.490
training: epoch 120, step 3400, loss 31.799163, time: 3.493
training: epoch 120, step 3600, loss 31.778027, time: 3.500
training: epoch 120, step 3800, loss 31.776372, time: 3.544
training: epoch 120, step 4000, loss 31.750417, time: 3.503
training: epoch 120, step 4200, loss 31.739966, time: 3.464
training: epoch 120, step 4400, loss 31.748940, time: 3.467
training: epoch 120, step 4600, loss 31.785301, time: 3.494
training: epoch 120, step 4800, loss 31.805294, time: 3.532
training: epoch 120, step 5000, loss 31.838012, time: 3.501
training: epoch 120, step 5200, loss 31.813025, time: 3.520
training: epoch 120, step 5400, loss 31.817594, time: 3.510
training: epoch 120, step 5600, loss 31.801111, time: 3.519
training: epoch 120, step 5800, loss 31.764719, time: 3.501
training: epoch 120, step 6000, loss 31.783928, time: 3.423
training: epoch 120, step 6200, loss 31.781612, time: 3.392
training: epoch 120, step 6400, loss 31.757375, time: 3.395
training: epoch 120, step 6600, loss 31.772494, time: 3.412
training: epoch 120, step 6800, loss 31.784075, time: 3.420
training: epoch 120, step 7000, loss 31.802626, time: 3.431
training: epoch 120, step 7200, loss 31.828528, time: 3.496
training: epoch 120, step 7400, loss 31.833531, time: 3.489
training: epoch 120, step 7600, loss 31.845241, time: 3.496
training: epoch 120, step 7800, loss 31.831812, time: 3.503
training: epoch 120, step 7849, loss 31.818767, time: 0.852
validate: epoch 120, loss 35.204592, charcter error 6.348 time: 4.034
    - [Info] The checkpoint file has been updated.
training: epoch 121, step 200, loss 30.311819, time: 3.431
training: epoch 121, step 400, loss 31.495901, time: 3.495
training: epoch 121, step 600, loss 31.428352, time: 3.475
training: epoch 121, step 800, loss 31.641562, time: 3.473
training: epoch 121, step 1000, loss 31.796399, time: 3.524
training: epoch 121, step 1200, loss 31.747878, time: 3.526
training: epoch 121, step 1400, loss 31.678129, time: 3.492
training: epoch 121, step 1600, loss 31.755410, time: 3.486
training: epoch 121, step 1800, loss 31.739402, time: 3.473
training: epoch 121, step 2000, loss 31.699431, time: 3.463
training: epoch 121, step 2200, loss 31.681648, time: 3.460
training: epoch 121, step 2400, loss 31.639626, time: 3.463
training: epoch 121, step 2600, loss 31.626388, time: 3.509
training: epoch 121, step 2800, loss 31.605508, time: 3.607
training: epoch 121, step 3000, loss 31.597844, time: 3.628
training: epoch 121, step 3200, loss 31.618649, time: 3.524
training: epoch 121, step 3400, loss 31.647181, time: 3.477
training: epoch 121, step 3600, loss 31.620659, time: 3.530
training: epoch 121, step 3800, loss 31.622822, time: 3.438
training: epoch 121, step 4000, loss 31.605455, time: 3.399
training: epoch 121, step 4200, loss 31.628087, time: 3.398
training: epoch 121, step 4400, loss 31.623296, time: 3.394
training: epoch 121, step 4600, loss 31.653528, time: 3.396
training: epoch 121, step 4800, loss 31.615524, time: 3.415
training: epoch 121, step 5000, loss 31.600628, time: 3.395
training: epoch 121, step 5200, loss 31.611721, time: 3.394
training: epoch 121, step 5400, loss 31.624828, time: 3.395
training: epoch 121, step 5600, loss 31.661855, time: 3.392
training: epoch 121, step 5800, loss 31.705455, time: 3.397
training: epoch 121, step 6000, loss 31.712405, time: 3.400
training: epoch 121, step 6200, loss 31.710686, time: 3.400
training: epoch 121, step 6400, loss 31.696108, time: 3.397
training: epoch 121, step 6600, loss 31.684035, time: 3.399
training: epoch 121, step 6800, loss 31.668734, time: 3.395
training: epoch 121, step 7000, loss 31.663661, time: 3.395
training: epoch 121, step 7200, loss 31.692294, time: 3.395
training: epoch 121, step 7400, loss 31.710447, time: 3.396
training: epoch 121, step 7600, loss 31.721080, time: 3.399
training: epoch 121, step 7800, loss 31.746110, time: 3.396
training: epoch 121, step 7849, loss 31.755379, time: 0.832
validate: epoch 121, loss 36.144129, charcter error 6.531 time: 4.020
training: epoch 122, step 200, loss 32.902395, time: 3.344
training: epoch 122, step 400, loss 32.668532, time: 3.383
training: epoch 122, step 600, loss 32.434445, time: 3.389
training: epoch 122, step 800, loss 32.245487, time: 3.390
training: epoch 122, step 1000, loss 32.095357, time: 3.393
training: epoch 122, step 1200, loss 32.065513, time: 3.395
training: epoch 122, step 1400, loss 31.944270, time: 3.390
training: epoch 122, step 1600, loss 32.003686, time: 3.391
training: epoch 122, step 1800, loss 32.119605, time: 3.387
training: epoch 122, step 2000, loss 32.077408, time: 3.390
training: epoch 122, step 2200, loss 32.001565, time: 3.387
training: epoch 122, step 2400, loss 31.947316, time: 3.394
training: epoch 122, step 2600, loss 31.999248, time: 3.392
training: epoch 122, step 2800, loss 31.925497, time: 3.388
training: epoch 122, step 3000, loss 31.913562, time: 3.392
training: epoch 122, step 3200, loss 31.931555, time: 3.392
training: epoch 122, step 3400, loss 31.946656, time: 3.390
training: epoch 122, step 3600, loss 31.932065, time: 3.391
training: epoch 122, step 3800, loss 31.882760, time: 3.395
training: epoch 122, step 4000, loss 31.903980, time: 3.390
training: epoch 122, step 4200, loss 31.901913, time: 3.389
training: epoch 122, step 4400, loss 31.858811, time: 3.392
training: epoch 122, step 4600, loss 31.853846, time: 3.391
training: epoch 122, step 4800, loss 31.851573, time: 3.392
training: epoch 122, step 5000, loss 31.862813, time: 3.389
training: epoch 122, step 5200, loss 31.825558, time: 3.392
training: epoch 122, step 5400, loss 31.806295, time: 3.391
training: epoch 122, step 5600, loss 31.771574, time: 3.389
training: epoch 122, step 5800, loss 31.794250, time: 3.393
training: epoch 122, step 6000, loss 31.823290, time: 3.392
training: epoch 122, step 6200, loss 31.844136, time: 3.395
training: epoch 122, step 6400, loss 31.845846, time: 3.392
training: epoch 122, step 6600, loss 31.814582, time: 3.393
training: epoch 122, step 6800, loss 31.793281, time: 3.393
training: epoch 122, step 7000, loss 31.815503, time: 3.393
training: epoch 122, step 7200, loss 31.829052, time: 3.396
training: epoch 122, step 7400, loss 31.842293, time: 3.397
training: epoch 122, step 7600, loss 31.847771, time: 3.397
training: epoch 122, step 7800, loss 31.822430, time: 3.395
training: epoch 122, step 7849, loss 31.824773, time: 0.832
validate: epoch 122, loss 35.415766, charcter error 6.378 time: 4.023
training: epoch 123, step 200, loss 31.142030, time: 3.351
training: epoch 123, step 400, loss 31.885218, time: 3.394
training: epoch 123, step 600, loss 31.922059, time: 3.398
training: epoch 123, step 800, loss 31.908563, time: 3.401
training: epoch 123, step 1000, loss 32.028480, time: 3.400
training: epoch 123, step 1200, loss 31.969820, time: 3.400
training: epoch 123, step 1400, loss 32.036801, time: 3.400
training: epoch 123, step 1600, loss 32.049824, time: 3.402
training: epoch 123, step 1800, loss 31.981868, time: 3.395
training: epoch 123, step 2000, loss 31.923962, time: 3.399
training: epoch 123, step 2200, loss 31.915690, time: 3.399
training: epoch 123, step 2400, loss 31.903567, time: 3.401
training: epoch 123, step 2600, loss 31.888941, time: 3.398
training: epoch 123, step 2800, loss 31.854241, time: 3.399
training: epoch 123, step 3000, loss 31.850136, time: 3.405
training: epoch 123, step 3200, loss 31.827954, time: 3.400
training: epoch 123, step 3400, loss 31.844630, time: 3.399
training: epoch 123, step 3600, loss 31.861952, time: 3.399
training: epoch 123, step 3800, loss 31.846955, time: 3.400
training: epoch 123, step 4000, loss 31.796130, time: 3.402
training: epoch 123, step 4200, loss 31.787101, time: 3.400
training: epoch 123, step 4400, loss 31.798389, time: 3.402
training: epoch 123, step 4600, loss 31.822551, time: 3.399
training: epoch 123, step 4800, loss 31.839771, time: 3.401
training: epoch 123, step 5000, loss 31.882388, time: 3.401
training: epoch 123, step 5200, loss 31.907644, time: 3.401
training: epoch 123, step 5400, loss 31.931126, time: 3.405
training: epoch 123, step 5600, loss 31.931880, time: 3.404
training: epoch 123, step 5800, loss 31.919249, time: 3.404
training: epoch 123, step 6000, loss 31.908362, time: 3.406
training: epoch 123, step 6200, loss 31.894353, time: 3.399
training: epoch 123, step 6400, loss 31.884324, time: 3.397
training: epoch 123, step 6600, loss 31.871690, time: 3.403
training: epoch 123, step 6800, loss 31.878784, time: 3.400
training: epoch 123, step 7000, loss 31.889341, time: 3.407
training: epoch 123, step 7200, loss 31.880448, time: 3.403
training: epoch 123, step 7400, loss 31.888587, time: 3.405
training: epoch 123, step 7600, loss 31.861735, time: 3.401
training: epoch 123, step 7800, loss 31.865469, time: 3.402
training: epoch 123, step 7849, loss 31.868848, time: 0.831
validate: epoch 123, loss 35.525360, charcter error 6.411 time: 4.021
training: epoch 124, step 200, loss 30.810758, time: 3.348
training: epoch 124, step 400, loss 31.091948, time: 3.390
training: epoch 124, step 600, loss 31.213966, time: 3.400
training: epoch 124, step 800, loss 31.314068, time: 3.402
training: epoch 124, step 1000, loss 31.381235, time: 3.399
training: epoch 124, step 1200, loss 31.225023, time: 3.399
training: epoch 124, step 1400, loss 31.298235, time: 3.401
training: epoch 124, step 1600, loss 31.349528, time: 3.401
training: epoch 124, step 1800, loss 31.342332, time: 3.396
training: epoch 124, step 2000, loss 31.408322, time: 3.401
training: epoch 124, step 2200, loss 31.476361, time: 3.397
training: epoch 124, step 2400, loss 31.549683, time: 3.407
training: epoch 124, step 2600, loss 31.606048, time: 3.400
training: epoch 124, step 2800, loss 31.654303, time: 3.402
training: epoch 124, step 3000, loss 31.599616, time: 3.401
training: epoch 124, step 3200, loss 31.564275, time: 3.402
training: epoch 124, step 3400, loss 31.559640, time: 3.402
training: epoch 124, step 3600, loss 31.623178, time: 3.407
training: epoch 124, step 3800, loss 31.600770, time: 3.403
training: epoch 124, step 4000, loss 31.616762, time: 3.403
training: epoch 124, step 4200, loss 31.594066, time: 3.404
training: epoch 124, step 4400, loss 31.615569, time: 3.399
training: epoch 124, step 4600, loss 31.617740, time: 3.403
training: epoch 124, step 4800, loss 31.626261, time: 3.404
training: epoch 124, step 5000, loss 31.605907, time: 3.402
training: epoch 124, step 5200, loss 31.652174, time: 3.403
training: epoch 124, step 5400, loss 31.715621, time: 3.404
training: epoch 124, step 5600, loss 31.714507, time: 3.403
training: epoch 124, step 5800, loss 31.748619, time: 3.402
training: epoch 124, step 6000, loss 31.753100, time: 3.402
training: epoch 124, step 6200, loss 31.780980, time: 3.404
training: epoch 124, step 6400, loss 31.775584, time: 3.402
training: epoch 124, step 6600, loss 31.750933, time: 3.410
training: epoch 124, step 6800, loss 31.764597, time: 3.403
training: epoch 124, step 7000, loss 31.785325, time: 3.406
training: epoch 124, step 7200, loss 31.763188, time: 3.404
training: epoch 124, step 7400, loss 31.755482, time: 3.403
training: epoch 124, step 7600, loss 31.723901, time: 3.400
training: epoch 124, step 7800, loss 31.735565, time: 3.403
training: epoch 124, step 7849, loss 31.729487, time: 0.834
validate: epoch 124, loss 35.154002, charcter error 6.327 time: 4.017
    - [Info] The checkpoint file has been updated.
training: epoch 125, step 200, loss 31.585288, time: 3.361
training: epoch 125, step 400, loss 31.566215, time: 3.396
training: epoch 125, step 600, loss 31.415294, time: 3.402
training: epoch 125, step 800, loss 31.314754, time: 3.402
training: epoch 125, step 1000, loss 31.616445, time: 3.406
training: epoch 125, step 1200, loss 31.674237, time: 3.398
training: epoch 125, step 1400, loss 31.766532, time: 3.409
training: epoch 125, step 1600, loss 31.667404, time: 3.404
training: epoch 125, step 1800, loss 31.693056, time: 3.405
training: epoch 125, step 2000, loss 31.693798, time: 3.406
training: epoch 125, step 2200, loss 31.801552, time: 3.405
training: epoch 125, step 2400, loss 31.823998, time: 3.403
training: epoch 125, step 2600, loss 31.896980, time: 3.408
training: epoch 125, step 2800, loss 31.928688, time: 3.406
training: epoch 125, step 3000, loss 31.966569, time: 3.407
training: epoch 125, step 3200, loss 31.976997, time: 3.403
training: epoch 125, step 3400, loss 31.949549, time: 3.401
training: epoch 125, step 3600, loss 31.907002, time: 3.402
training: epoch 125, step 3800, loss 31.885914, time: 3.399
training: epoch 125, step 4000, loss 31.895152, time: 3.398
training: epoch 125, step 4200, loss 31.913635, time: 3.406
training: epoch 125, step 4400, loss 31.889720, time: 3.403
training: epoch 125, step 4600, loss 31.857177, time: 3.398
training: epoch 125, step 4800, loss 31.880998, time: 3.399
training: epoch 125, step 5000, loss 31.868901, time: 3.393
training: epoch 125, step 5200, loss 31.830375, time: 3.397
training: epoch 125, step 5400, loss 31.808648, time: 3.394
training: epoch 125, step 5600, loss 31.831924, time: 3.399
training: epoch 125, step 5800, loss 31.832426, time: 3.394
training: epoch 125, step 6000, loss 31.848405, time: 3.392
training: epoch 125, step 6200, loss 31.891996, time: 3.399
training: epoch 125, step 6400, loss 31.888051, time: 3.396
training: epoch 125, step 6600, loss 31.891453, time: 3.394
training: epoch 125, step 6800, loss 31.873723, time: 3.392
training: epoch 125, step 7000, loss 31.853133, time: 3.396
training: epoch 125, step 7200, loss 31.870332, time: 3.393
training: epoch 125, step 7400, loss 31.885523, time: 3.393
training: epoch 125, step 7600, loss 31.874994, time: 3.397
training: epoch 125, step 7800, loss 31.879405, time: 3.394
training: epoch 125, step 7849, loss 31.889314, time: 0.832
validate: epoch 125, loss 35.438147, charcter error 6.378 time: 4.022
training: epoch 126, step 200, loss 31.172887, time: 3.346
training: epoch 126, step 400, loss 31.055115, time: 3.389
training: epoch 126, step 600, loss 31.129013, time: 3.398
training: epoch 126, step 800, loss 31.534749, time: 3.398
training: epoch 126, step 1000, loss 31.630466, time: 3.395
training: epoch 126, step 1200, loss 31.825293, time: 3.398
training: epoch 126, step 1400, loss 31.814514, time: 3.390
training: epoch 126, step 1600, loss 31.919803, time: 3.396
training: epoch 126, step 1800, loss 31.885373, time: 3.387
training: epoch 126, step 2000, loss 31.867470, time: 3.389
training: epoch 126, step 2200, loss 31.783897, time: 3.390
training: epoch 126, step 2400, loss 31.799307, time: 3.389
training: epoch 126, step 2600, loss 31.741146, time: 3.391
training: epoch 126, step 2800, loss 31.769382, time: 3.391
training: epoch 126, step 3000, loss 31.715656, time: 3.393
training: epoch 126, step 3200, loss 31.664916, time: 3.394
training: epoch 126, step 3400, loss 31.676937, time: 3.389
training: epoch 126, step 3600, loss 31.744238, time: 3.391
training: epoch 126, step 3800, loss 31.784346, time: 3.388
training: epoch 126, step 4000, loss 31.707859, time: 3.391
training: epoch 126, step 4200, loss 31.651613, time: 3.391
training: epoch 126, step 4400, loss 31.654032, time: 3.395
training: epoch 126, step 4600, loss 31.673997, time: 3.395
training: epoch 126, step 4800, loss 31.686371, time: 3.392
training: epoch 126, step 5000, loss 31.676127, time: 3.388
training: epoch 126, step 5200, loss 31.695266, time: 3.390
training: epoch 126, step 5400, loss 31.687322, time: 3.394
training: epoch 126, step 5600, loss 31.718024, time: 3.393
training: epoch 126, step 5800, loss 31.750085, time: 3.395
training: epoch 126, step 6000, loss 31.764376, time: 3.392
training: epoch 126, step 6200, loss 31.785490, time: 3.389
training: epoch 126, step 6400, loss 31.776490, time: 3.394
training: epoch 126, step 6600, loss 31.794353, time: 3.394
training: epoch 126, step 6800, loss 31.784598, time: 3.390
training: epoch 126, step 7000, loss 31.788017, time: 3.393
training: epoch 126, step 7200, loss 31.805110, time: 3.398
training: epoch 126, step 7400, loss 31.837749, time: 3.399
training: epoch 126, step 7600, loss 31.844824, time: 3.395
training: epoch 126, step 7800, loss 31.851710, time: 3.390
training: epoch 126, step 7849, loss 31.850821, time: 0.832
validate: epoch 126, loss 35.547678, charcter error 6.379 time: 4.026
training: epoch 127, step 200, loss 31.193171, time: 3.345
training: epoch 127, step 400, loss 31.365749, time: 3.384
training: epoch 127, step 600, loss 31.469007, time: 3.390
training: epoch 127, step 800, loss 31.549789, time: 3.398
training: epoch 127, step 1000, loss 31.505787, time: 3.395
training: epoch 127, step 1200, loss 31.610958, time: 3.397
training: epoch 127, step 1400, loss 31.445138, time: 3.389
training: epoch 127, step 1600, loss 31.407397, time: 3.392
training: epoch 127, step 1800, loss 31.572238, time: 3.392
training: epoch 127, step 2000, loss 31.696238, time: 3.396
training: epoch 127, step 2200, loss 31.788344, time: 3.391
training: epoch 127, step 2400, loss 31.794435, time: 3.389
training: epoch 127, step 2600, loss 31.826766, time: 3.391
training: epoch 127, step 2800, loss 31.847485, time: 3.395
training: epoch 127, step 3000, loss 31.872487, time: 3.397
training: epoch 127, step 3200, loss 31.791765, time: 3.390
training: epoch 127, step 3400, loss 31.769526, time: 3.393
training: epoch 127, step 3600, loss 31.709036, time: 3.393
training: epoch 127, step 3800, loss 31.742576, time: 3.398
training: epoch 127, step 4000, loss 31.721380, time: 3.396
training: epoch 127, step 4200, loss 31.752027, time: 3.397
training: epoch 127, step 4400, loss 31.760126, time: 3.391
training: epoch 127, step 4600, loss 31.777836, time: 3.391
training: epoch 127, step 4800, loss 31.796518, time: 3.395
training: epoch 127, step 5000, loss 31.780531, time: 3.391
training: epoch 127, step 5200, loss 31.780108, time: 3.393
training: epoch 127, step 5400, loss 31.763693, time: 3.393
training: epoch 127, step 5600, loss 31.782597, time: 3.397
training: epoch 127, step 5800, loss 31.772336, time: 3.394
training: epoch 127, step 6000, loss 31.726116, time: 3.391
training: epoch 127, step 6200, loss 31.695624, time: 3.391
training: epoch 127, step 6400, loss 31.719473, time: 3.388
training: epoch 127, step 6600, loss 31.708206, time: 3.393
training: epoch 127, step 6800, loss 31.734653, time: 3.394
training: epoch 127, step 7000, loss 31.726814, time: 3.395
training: epoch 127, step 7200, loss 31.734509, time: 3.392
training: epoch 127, step 7400, loss 31.736715, time: 3.392
training: epoch 127, step 7600, loss 31.727442, time: 3.392
training: epoch 127, step 7800, loss 31.734021, time: 3.388
training: epoch 127, step 7849, loss 31.734962, time: 0.831
validate: epoch 127, loss 35.344880, charcter error 6.343 time: 4.025
training: epoch 128, step 200, loss 30.217712, time: 3.340
training: epoch 128, step 400, loss 31.233465, time: 3.381
training: epoch 128, step 600, loss 31.735350, time: 3.387
training: epoch 128, step 800, loss 31.594284, time: 3.385
training: epoch 128, step 1000, loss 31.649274, time: 3.385
training: epoch 128, step 1200, loss 31.460587, time: 3.384
training: epoch 128, step 1400, loss 31.289639, time: 3.384
training: epoch 128, step 1600, loss 31.311579, time: 3.387
training: epoch 128, step 1800, loss 31.371127, time: 3.390
training: epoch 128, step 2000, loss 31.405958, time: 3.382
training: epoch 128, step 2200, loss 31.391152, time: 3.383
training: epoch 128, step 2400, loss 31.465729, time: 3.384
training: epoch 128, step 2600, loss 31.486431, time: 3.386
training: epoch 128, step 2800, loss 31.482816, time: 3.386
training: epoch 128, step 3000, loss 31.602775, time: 3.382
training: epoch 128, step 3200, loss 31.706095, time: 3.383
training: epoch 128, step 3400, loss 31.781799, time: 3.384
training: epoch 128, step 3600, loss 31.795658, time: 3.388
training: epoch 128, step 3800, loss 31.807925, time: 3.388
training: epoch 128, step 4000, loss 31.883117, time: 3.387
training: epoch 128, step 4200, loss 31.922123, time: 3.381
training: epoch 128, step 4400, loss 31.960093, time: 3.385
training: epoch 128, step 4600, loss 31.974833, time: 3.384
training: epoch 128, step 4800, loss 31.952059, time: 3.387
training: epoch 128, step 5000, loss 31.935966, time: 3.387
training: epoch 128, step 5200, loss 31.902087, time: 3.384
training: epoch 128, step 5400, loss 31.908222, time: 3.380
training: epoch 128, step 5600, loss 31.942047, time: 3.383
training: epoch 128, step 5800, loss 31.946119, time: 3.389
training: epoch 128, step 6000, loss 31.936423, time: 3.388
training: epoch 128, step 6200, loss 31.945114, time: 3.385
training: epoch 128, step 6400, loss 31.943062, time: 3.381
training: epoch 128, step 6600, loss 31.911753, time: 3.384
training: epoch 128, step 6800, loss 31.913073, time: 3.386
training: epoch 128, step 7000, loss 31.932333, time: 3.385
training: epoch 128, step 7200, loss 31.944061, time: 3.389
training: epoch 128, step 7400, loss 31.924761, time: 3.385
training: epoch 128, step 7600, loss 31.910749, time: 3.385
training: epoch 128, step 7800, loss 31.914230, time: 3.387
training: epoch 128, step 7849, loss 31.911580, time: 0.829
validate: epoch 128, loss 35.249452, charcter error 6.357 time: 4.017
training: epoch 129, step 200, loss 30.667457, time: 3.344
training: epoch 129, step 400, loss 31.610951, time: 3.379
training: epoch 129, step 600, loss 31.598740, time: 3.385
training: epoch 129, step 800, loss 31.572723, time: 3.392
training: epoch 129, step 1000, loss 31.488199, time: 3.387
training: epoch 129, step 1200, loss 31.566957, time: 3.387
training: epoch 129, step 1400, loss 31.512663, time: 3.389
training: epoch 129, step 1600, loss 31.515276, time: 3.387
training: epoch 129, step 1800, loss 31.485925, time: 3.391
training: epoch 129, step 2000, loss 31.492471, time: 3.390
training: epoch 129, step 2200, loss 31.474673, time: 3.391
training: epoch 129, step 2400, loss 31.458389, time: 3.391
training: epoch 129, step 2600, loss 31.461377, time: 3.392
training: epoch 129, step 2800, loss 31.508071, time: 3.393
training: epoch 129, step 3000, loss 31.541066, time: 3.421
training: epoch 129, step 3200, loss 31.481113, time: 3.462
training: epoch 129, step 3400, loss 31.563368, time: 3.511
training: epoch 129, step 3600, loss 31.580316, time: 3.541
training: epoch 129, step 3800, loss 31.599221, time: 3.543
training: epoch 129, step 4000, loss 31.607182, time: 3.549
training: epoch 129, step 4200, loss 31.621043, time: 3.524
training: epoch 129, step 4400, loss 31.640661, time: 3.534
training: epoch 129, step 4600, loss 31.677230, time: 3.520
training: epoch 129, step 4800, loss 31.681085, time: 3.552
training: epoch 129, step 5000, loss 31.666410, time: 3.528
training: epoch 129, step 5200, loss 31.668350, time: 3.491
training: epoch 129, step 5400, loss 31.659257, time: 3.564
training: epoch 129, step 5600, loss 31.674619, time: 3.575
training: epoch 129, step 5800, loss 31.692180, time: 3.474
training: epoch 129, step 6000, loss 31.701783, time: 3.480
training: epoch 129, step 6200, loss 31.728821, time: 3.475
training: epoch 129, step 6400, loss 31.719966, time: 3.440
training: epoch 129, step 6600, loss 31.690865, time: 3.459
training: epoch 129, step 6800, loss 31.710477, time: 3.451
training: epoch 129, step 7000, loss 31.685234, time: 3.430
training: epoch 129, step 7200, loss 31.688198, time: 3.438
training: epoch 129, step 7400, loss 31.669799, time: 3.430
training: epoch 129, step 7600, loss 31.678570, time: 3.425
training: epoch 129, step 7800, loss 31.668029, time: 3.428
training: epoch 129, step 7849, loss 31.665463, time: 0.838
validate: epoch 129, loss 35.480750, charcter error 6.397 time: 4.038
training: epoch 130, step 200, loss 31.926550, time: 3.369
training: epoch 130, step 400, loss 32.002628, time: 3.400
training: epoch 130, step 600, loss 31.811483, time: 3.394
training: epoch 130, step 800, loss 31.536757, time: 3.407
training: epoch 130, step 1000, loss 31.449559, time: 3.405
training: epoch 130, step 1200, loss 31.701315, time: 3.399
training: epoch 130, step 1400, loss 31.765404, time: 3.394
training: epoch 130, step 1600, loss 31.709683, time: 3.394
training: epoch 130, step 1800, loss 31.568810, time: 3.395
training: epoch 130, step 2000, loss 31.668944, time: 3.389
training: epoch 130, step 2200, loss 31.669547, time: 3.389
training: epoch 130, step 2400, loss 31.656746, time: 3.392
training: epoch 130, step 2600, loss 31.643174, time: 3.392
training: epoch 130, step 2800, loss 31.680507, time: 3.390
training: epoch 130, step 3000, loss 31.713097, time: 3.389
training: epoch 130, step 3200, loss 31.740242, time: 3.391
training: epoch 130, step 3400, loss 31.777026, time: 3.391
training: epoch 130, step 3600, loss 31.726518, time: 3.389
training: epoch 130, step 3800, loss 31.762750, time: 3.388
training: epoch 130, step 4000, loss 31.794912, time: 3.386
training: epoch 130, step 4200, loss 31.781099, time: 3.384
training: epoch 130, step 4400, loss 31.764054, time: 3.386
training: epoch 130, step 4600, loss 31.791651, time: 3.385
training: epoch 130, step 4800, loss 31.756497, time: 3.388
training: epoch 130, step 5000, loss 31.751190, time: 3.388
training: epoch 130, step 5200, loss 31.741098, time: 3.385
training: epoch 130, step 5400, loss 31.782623, time: 3.395
training: epoch 130, step 5600, loss 31.786842, time: 3.385
training: epoch 130, step 5800, loss 31.789703, time: 3.385
training: epoch 130, step 6000, loss 31.788100, time: 3.381
training: epoch 130, step 6200, loss 31.768155, time: 3.393
training: epoch 130, step 6400, loss 31.777354, time: 3.494
training: epoch 130, step 6600, loss 31.803842, time: 3.515
training: epoch 130, step 6800, loss 31.839263, time: 3.487
training: epoch 130, step 7000, loss 31.815310, time: 3.496
training: epoch 130, step 7200, loss 31.802609, time: 3.487
training: epoch 130, step 7400, loss 31.793901, time: 3.518
training: epoch 130, step 7600, loss 31.787533, time: 3.495
training: epoch 130, step 7800, loss 31.777832, time: 3.468
training: epoch 130, step 7849, loss 31.784884, time: 0.850
validate: epoch 130, loss 35.331653, charcter error 6.364 time: 4.034
training: epoch 131, step 200, loss 33.386789, time: 3.471
training: epoch 131, step 400, loss 33.228847, time: 3.541
training: epoch 131, step 600, loss 32.825456, time: 3.533
training: epoch 131, step 800, loss 32.367005, time: 3.500
training: epoch 131, step 1000, loss 32.459493, time: 3.504
training: epoch 131, step 1200, loss 32.201177, time: 3.537
training: epoch 131, step 1400, loss 32.221817, time: 3.465
training: epoch 131, step 1600, loss 32.142199, time: 3.391
training: epoch 131, step 1800, loss 31.996977, time: 3.392
training: epoch 131, step 2000, loss 31.922881, time: 3.397
training: epoch 131, step 2200, loss 31.892388, time: 3.417
training: epoch 131, step 2400, loss 31.848139, time: 3.424
training: epoch 131, step 2600, loss 31.847424, time: 3.463
training: epoch 131, step 2800, loss 31.729906, time: 3.515
training: epoch 131, step 3000, loss 31.826231, time: 3.521
training: epoch 131, step 3200, loss 31.850287, time: 3.478
training: epoch 131, step 3400, loss 31.842084, time: 3.462
training: epoch 131, step 3600, loss 31.773284, time: 3.471
training: epoch 131, step 3800, loss 31.767383, time: 3.451
training: epoch 131, step 4000, loss 31.743111, time: 3.482
training: epoch 131, step 4200, loss 31.701833, time: 3.491
training: epoch 131, step 4400, loss 31.711766, time: 3.455
training: epoch 131, step 4600, loss 31.677494, time: 3.474
training: epoch 131, step 4800, loss 31.713709, time: 3.486
training: epoch 131, step 5000, loss 31.701949, time: 3.471
training: epoch 131, step 5200, loss 31.707299, time: 3.469
training: epoch 131, step 5400, loss 31.687253, time: 3.484
training: epoch 131, step 5600, loss 31.696106, time: 3.461
training: epoch 131, step 5800, loss 31.722925, time: 3.474
training: epoch 131, step 6000, loss 31.751604, time: 3.493
training: epoch 131, step 6200, loss 31.715683, time: 3.460
training: epoch 131, step 6400, loss 31.709143, time: 3.637
training: epoch 131, step 6600, loss 31.715164, time: 3.519
training: epoch 131, step 6800, loss 31.696895, time: 3.494
training: epoch 131, step 7000, loss 31.685353, time: 3.511
training: epoch 131, step 7200, loss 31.660427, time: 3.479
training: epoch 131, step 7400, loss 31.689624, time: 3.469
training: epoch 131, step 7600, loss 31.678921, time: 3.529
training: epoch 131, step 7800, loss 31.728362, time: 3.519
training: epoch 131, step 7849, loss 31.720169, time: 0.845
validate: epoch 131, loss 35.418512, charcter error 6.355 time: 4.045
training: epoch 132, step 200, loss 30.751704, time: 3.456
training: epoch 132, step 400, loss 30.354331, time: 3.465
training: epoch 132, step 600, loss 30.724193, time: 3.494
training: epoch 132, step 800, loss 30.872385, time: 3.463
training: epoch 132, step 1000, loss 31.268300, time: 3.441
training: epoch 132, step 1200, loss 31.207532, time: 3.447
training: epoch 132, step 1400, loss 31.143299, time: 3.441
training: epoch 132, step 1600, loss 31.196645, time: 3.428
training: epoch 132, step 1800, loss 31.178653, time: 3.437
training: epoch 132, step 2000, loss 31.318813, time: 3.423
training: epoch 132, step 2200, loss 31.305455, time: 3.427
training: epoch 132, step 2400, loss 31.348254, time: 3.423
training: epoch 132, step 2600, loss 31.386756, time: 3.410
training: epoch 132, step 2800, loss 31.432016, time: 3.416
training: epoch 132, step 3000, loss 31.484593, time: 3.413
training: epoch 132, step 3200, loss 31.500720, time: 3.412
training: epoch 132, step 3400, loss 31.517468, time: 3.410
training: epoch 132, step 3600, loss 31.505659, time: 3.413
training: epoch 132, step 3800, loss 31.536884, time: 3.405
training: epoch 132, step 4000, loss 31.541181, time: 3.410
training: epoch 132, step 4200, loss 31.524548, time: 3.406
training: epoch 132, step 4400, loss 31.537242, time: 3.404
training: epoch 132, step 4600, loss 31.572934, time: 3.404
training: epoch 132, step 4800, loss 31.563175, time: 3.405
training: epoch 132, step 5000, loss 31.511122, time: 3.401
training: epoch 132, step 5200, loss 31.544272, time: 3.405
training: epoch 132, step 5400, loss 31.561630, time: 3.406
training: epoch 132, step 5600, loss 31.559765, time: 3.400
training: epoch 132, step 5800, loss 31.560614, time: 3.399
training: epoch 132, step 6000, loss 31.565604, time: 3.396
training: epoch 132, step 6200, loss 31.575018, time: 3.399
training: epoch 132, step 6400, loss 31.556287, time: 3.393
training: epoch 132, step 6600, loss 31.569648, time: 3.399
training: epoch 132, step 6800, loss 31.590097, time: 3.397
training: epoch 132, step 7000, loss 31.603113, time: 3.399
training: epoch 132, step 7200, loss 31.611423, time: 3.402
training: epoch 132, step 7400, loss 31.616404, time: 3.401
training: epoch 132, step 7600, loss 31.603055, time: 3.397
training: epoch 132, step 7800, loss 31.624003, time: 3.399
training: epoch 132, step 7849, loss 31.628501, time: 0.832
validate: epoch 132, loss 35.474392, charcter error 6.376 time: 4.023
training: epoch 133, step 200, loss 31.657246, time: 3.346
training: epoch 133, step 400, loss 32.084422, time: 3.388
training: epoch 133, step 600, loss 32.060091, time: 3.398
training: epoch 133, step 800, loss 31.858473, time: 3.399
training: epoch 133, step 1000, loss 31.848592, time: 3.400
training: epoch 133, step 1200, loss 31.609059, time: 3.397
training: epoch 133, step 1400, loss 31.557874, time: 3.397
training: epoch 133, step 1600, loss 31.575498, time: 3.401
training: epoch 133, step 1800, loss 31.560909, time: 3.399
training: epoch 133, step 2000, loss 31.595220, time: 3.399
training: epoch 133, step 2200, loss 31.759423, time: 3.396
training: epoch 133, step 2400, loss 31.815147, time: 3.393
training: epoch 133, step 2600, loss 31.847944, time: 3.394
training: epoch 133, step 2800, loss 31.852719, time: 3.393
training: epoch 133, step 3000, loss 31.738548, time: 3.395
training: epoch 133, step 3200, loss 31.779176, time: 3.396
training: epoch 133, step 3400, loss 31.805659, time: 3.394
training: epoch 133, step 3600, loss 31.833446, time: 3.398
training: epoch 133, step 3800, loss 31.803713, time: 3.393
training: epoch 133, step 4000, loss 31.807326, time: 3.396
training: epoch 133, step 4200, loss 31.854280, time: 3.394
training: epoch 133, step 4400, loss 31.857367, time: 3.390
training: epoch 133, step 4600, loss 31.879054, time: 3.391
training: epoch 133, step 4800, loss 31.846866, time: 3.395
training: epoch 133, step 5000, loss 31.822525, time: 3.396
training: epoch 133, step 5200, loss 31.789069, time: 3.398
training: epoch 133, step 5400, loss 31.805636, time: 3.396
training: epoch 133, step 5600, loss 31.775278, time: 3.394
training: epoch 133, step 5800, loss 31.744548, time: 3.395
training: epoch 133, step 6000, loss 31.743324, time: 3.393
training: epoch 133, step 6200, loss 31.748056, time: 3.395
training: epoch 133, step 6400, loss 31.718437, time: 3.396
training: epoch 133, step 6600, loss 31.751379, time: 3.398
training: epoch 133, step 6800, loss 31.733656, time: 3.398
training: epoch 133, step 7000, loss 31.689204, time: 3.396
training: epoch 133, step 7200, loss 31.656450, time: 3.397
training: epoch 133, step 7400, loss 31.644966, time: 3.399
training: epoch 133, step 7600, loss 31.646053, time: 3.399
training: epoch 133, step 7800, loss 31.666152, time: 3.399
training: epoch 133, step 7849, loss 31.671878, time: 0.833
validate: epoch 133, loss 35.205234, charcter error 6.348 time: 4.019
training: epoch 134, step 200, loss 32.759186, time: 3.343
training: epoch 134, step 400, loss 31.544390, time: 3.390
training: epoch 134, step 600, loss 31.756342, time: 3.393
training: epoch 134, step 800, loss 31.776905, time: 3.396
training: epoch 134, step 1000, loss 31.673102, time: 3.396
training: epoch 134, step 1200, loss 31.545639, time: 3.394
training: epoch 134, step 1400, loss 31.525931, time: 3.397
training: epoch 134, step 1600, loss 31.364349, time: 3.397
training: epoch 134, step 1800, loss 31.349668, time: 3.398
training: epoch 134, step 2000, loss 31.452746, time: 3.397
training: epoch 134, step 2200, loss 31.428289, time: 3.397
training: epoch 134, step 2400, loss 31.411910, time: 3.393
training: epoch 134, step 2600, loss 31.401719, time: 3.396
training: epoch 134, step 2800, loss 31.447748, time: 3.396
training: epoch 134, step 3000, loss 31.483616, time: 3.399
training: epoch 134, step 3200, loss 31.527081, time: 3.401
training: epoch 134, step 3400, loss 31.503384, time: 3.400
training: epoch 134, step 3600, loss 31.520854, time: 3.398
training: epoch 134, step 3800, loss 31.542183, time: 3.396
training: epoch 134, step 4000, loss 31.496189, time: 3.397
training: epoch 134, step 4200, loss 31.462316, time: 3.397
training: epoch 134, step 4400, loss 31.496811, time: 3.399
training: epoch 134, step 4600, loss 31.527185, time: 3.403
training: epoch 134, step 4800, loss 31.550019, time: 3.403
training: epoch 134, step 5000, loss 31.548870, time: 3.398
training: epoch 134, step 5200, loss 31.527594, time: 3.398
training: epoch 134, step 5400, loss 31.539992, time: 3.398
training: epoch 134, step 5600, loss 31.545847, time: 3.400
training: epoch 134, step 5800, loss 31.540751, time: 3.396
training: epoch 134, step 6000, loss 31.572214, time: 3.400
training: epoch 134, step 6200, loss 31.575797, time: 3.403
training: epoch 134, step 6400, loss 31.594918, time: 3.392
training: epoch 134, step 6600, loss 31.599943, time: 3.395
training: epoch 134, step 6800, loss 31.591798, time: 3.398
training: epoch 134, step 7000, loss 31.602939, time: 3.399
training: epoch 134, step 7200, loss 31.607904, time: 3.405
training: epoch 134, step 7400, loss 31.604734, time: 3.403
training: epoch 134, step 7600, loss 31.590299, time: 3.402
training: epoch 134, step 7800, loss 31.579711, time: 3.396
training: epoch 134, step 7849, loss 31.577545, time: 0.832
validate: epoch 134, loss 35.138283, charcter error 6.320 time: 4.023
    - [Info] The checkpoint file has been updated.
training: epoch 135, step 200, loss 31.754602, time: 3.356
training: epoch 135, step 400, loss 31.420712, time: 3.393
training: epoch 135, step 600, loss 31.561831, time: 3.399
training: epoch 135, step 800, loss 31.719129, time: 3.400
training: epoch 135, step 1000, loss 31.521972, time: 3.403
training: epoch 135, step 1200, loss 31.558444, time: 3.405
training: epoch 135, step 1400, loss 31.458016, time: 3.406
training: epoch 135, step 1600, loss 31.598852, time: 3.396
training: epoch 135, step 1800, loss 31.662704, time: 3.396
training: epoch 135, step 2000, loss 31.661834, time: 3.400
training: epoch 135, step 2200, loss 31.655203, time: 3.404
training: epoch 135, step 2400, loss 31.666032, time: 3.404
training: epoch 135, step 2600, loss 31.706386, time: 3.400
training: epoch 135, step 2800, loss 31.653073, time: 3.408
training: epoch 135, step 3000, loss 31.624136, time: 3.400
training: epoch 135, step 3200, loss 31.611809, time: 3.406
training: epoch 135, step 3400, loss 31.595045, time: 3.405
training: epoch 135, step 3600, loss 31.623100, time: 3.396
training: epoch 135, step 3800, loss 31.615112, time: 3.406
training: epoch 135, step 4000, loss 31.652342, time: 3.403
training: epoch 135, step 4200, loss 31.626697, time: 3.397
training: epoch 135, step 4400, loss 31.613566, time: 3.403
training: epoch 135, step 4600, loss 31.553571, time: 3.400
training: epoch 135, step 4800, loss 31.583468, time: 3.403
training: epoch 135, step 5000, loss 31.587458, time: 3.399
training: epoch 135, step 5200, loss 31.583919, time: 3.400
training: epoch 135, step 5400, loss 31.559470, time: 3.396
training: epoch 135, step 5600, loss 31.569791, time: 3.396
training: epoch 135, step 5800, loss 31.556849, time: 3.400
training: epoch 135, step 6000, loss 31.583572, time: 3.399
training: epoch 135, step 6200, loss 31.581503, time: 3.395
training: epoch 135, step 6400, loss 31.581839, time: 3.389
training: epoch 135, step 6600, loss 31.572920, time: 3.397
training: epoch 135, step 6800, loss 31.579708, time: 3.398
training: epoch 135, step 7000, loss 31.566046, time: 3.395
training: epoch 135, step 7200, loss 31.537763, time: 3.396
training: epoch 135, step 7400, loss 31.547885, time: 3.396
training: epoch 135, step 7600, loss 31.547269, time: 3.389
training: epoch 135, step 7800, loss 31.551665, time: 3.393
training: epoch 135, step 7849, loss 31.541850, time: 0.831
validate: epoch 135, loss 35.368552, charcter error 6.367 time: 4.022
training: epoch 136, step 200, loss 31.398966, time: 3.341
training: epoch 136, step 400, loss 31.388027, time: 3.383
training: epoch 136, step 600, loss 31.614987, time: 3.395
training: epoch 136, step 800, loss 31.580978, time: 3.393
training: epoch 136, step 1000, loss 31.320392, time: 3.393
training: epoch 136, step 1200, loss 31.287553, time: 3.389
training: epoch 136, step 1400, loss 31.312806, time: 3.391
training: epoch 136, step 1600, loss 31.358632, time: 3.394
training: epoch 136, step 1800, loss 31.426069, time: 3.393
training: epoch 136, step 2000, loss 31.413075, time: 3.388
training: epoch 136, step 2200, loss 31.437971, time: 3.392
training: epoch 136, step 2400, loss 31.518937, time: 3.393
training: epoch 136, step 2600, loss 31.497358, time: 3.388
training: epoch 136, step 2800, loss 31.523545, time: 3.389
training: epoch 136, step 3000, loss 31.610255, time: 3.392
training: epoch 136, step 3200, loss 31.562585, time: 3.392
training: epoch 136, step 3400, loss 31.605348, time: 3.395
training: epoch 136, step 3600, loss 31.575247, time: 3.391
training: epoch 136, step 3800, loss 31.617812, time: 3.391
training: epoch 136, step 4000, loss 31.692559, time: 3.389
training: epoch 136, step 4200, loss 31.703089, time: 3.386
training: epoch 136, step 4400, loss 31.700803, time: 3.387
training: epoch 136, step 4600, loss 31.690343, time: 3.387
training: epoch 136, step 4800, loss 31.636147, time: 3.384
training: epoch 136, step 5000, loss 31.648122, time: 3.389
training: epoch 136, step 5200, loss 31.668336, time: 3.392
training: epoch 136, step 5400, loss 31.656176, time: 3.384
training: epoch 136, step 5600, loss 31.660381, time: 3.386
training: epoch 136, step 5800, loss 31.686076, time: 3.387
training: epoch 136, step 6000, loss 31.691686, time: 3.389
training: epoch 136, step 6200, loss 31.690126, time: 3.394
training: epoch 136, step 6400, loss 31.684677, time: 3.393
training: epoch 136, step 6600, loss 31.660248, time: 3.386
training: epoch 136, step 6800, loss 31.670965, time: 3.391
training: epoch 136, step 7000, loss 31.683097, time: 3.394
training: epoch 136, step 7200, loss 31.680994, time: 3.394
training: epoch 136, step 7400, loss 31.663928, time: 3.389
training: epoch 136, step 7600, loss 31.677536, time: 3.389
training: epoch 136, step 7800, loss 31.677902, time: 3.388
training: epoch 136, step 7849, loss 31.661455, time: 0.832
validate: epoch 136, loss 35.450328, charcter error 6.386 time: 4.019
training: epoch 137, step 200, loss 31.287095, time: 3.347
training: epoch 137, step 400, loss 31.779910, time: 3.389
training: epoch 137, step 600, loss 31.716183, time: 3.391
training: epoch 137, step 800, loss 31.854346, time: 3.390
training: epoch 137, step 1000, loss 31.944725, time: 3.393
training: epoch 137, step 1200, loss 31.903147, time: 3.392
training: epoch 137, step 1400, loss 31.671891, time: 3.395
training: epoch 137, step 1600, loss 31.601389, time: 3.391
training: epoch 137, step 1800, loss 31.639916, time: 3.389
training: epoch 137, step 2000, loss 31.710034, time: 3.394
training: epoch 137, step 2200, loss 31.799041, time: 3.397
training: epoch 137, step 2400, loss 31.750234, time: 3.391
training: epoch 137, step 2600, loss 31.774793, time: 3.395
training: epoch 137, step 2800, loss 31.717946, time: 3.391
training: epoch 137, step 3000, loss 31.732587, time: 3.396
training: epoch 137, step 3200, loss 31.721335, time: 3.397
training: epoch 137, step 3400, loss 31.698689, time: 3.396
training: epoch 137, step 3600, loss 31.720152, time: 3.391
training: epoch 137, step 3800, loss 31.652489, time: 3.395
training: epoch 137, step 4000, loss 31.621102, time: 3.391
training: epoch 137, step 4200, loss 31.600910, time: 3.386
training: epoch 137, step 4400, loss 31.629949, time: 3.393
training: epoch 137, step 4600, loss 31.622600, time: 3.391
training: epoch 137, step 4800, loss 31.666882, time: 3.385
training: epoch 137, step 5000, loss 31.664590, time: 3.393
training: epoch 137, step 5200, loss 31.619932, time: 3.387
training: epoch 137, step 5400, loss 31.569152, time: 3.390
training: epoch 137, step 5600, loss 31.582965, time: 3.389
training: epoch 137, step 5800, loss 31.574462, time: 3.391
training: epoch 137, step 6000, loss 31.550359, time: 3.388
training: epoch 137, step 6200, loss 31.565283, time: 3.391
training: epoch 137, step 6400, loss 31.552224, time: 3.387
training: epoch 137, step 6600, loss 31.582654, time: 3.388
training: epoch 137, step 6800, loss 31.620384, time: 3.393
training: epoch 137, step 7000, loss 31.602617, time: 3.389
training: epoch 137, step 7200, loss 31.583178, time: 3.390
training: epoch 137, step 7400, loss 31.567737, time: 3.387
training: epoch 137, step 7600, loss 31.551286, time: 3.383
training: epoch 137, step 7800, loss 31.529982, time: 3.391
training: epoch 137, step 7849, loss 31.535897, time: 0.830
validate: epoch 137, loss 35.610964, charcter error 6.389 time: 4.028
training: epoch 138, step 200, loss 32.249114, time: 3.342
training: epoch 138, step 400, loss 31.679303, time: 3.382
training: epoch 138, step 600, loss 31.809427, time: 3.384
training: epoch 138, step 800, loss 31.815711, time: 3.388
training: epoch 138, step 1000, loss 31.717030, time: 3.391
training: epoch 138, step 1200, loss 31.678537, time: 3.385
training: epoch 138, step 1400, loss 31.711078, time: 3.382
training: epoch 138, step 1600, loss 31.715590, time: 3.388
training: epoch 138, step 1800, loss 31.676013, time: 3.380
training: epoch 138, step 2000, loss 31.832453, time: 3.394
training: epoch 138, step 2200, loss 31.826065, time: 3.390
training: epoch 138, step 2400, loss 31.800089, time: 3.389
training: epoch 138, step 2600, loss 31.784897, time: 3.389
training: epoch 138, step 2800, loss 31.790225, time: 3.391
training: epoch 138, step 3000, loss 31.699815, time: 3.390
training: epoch 138, step 3200, loss 31.652442, time: 3.387
training: epoch 138, step 3400, loss 31.561022, time: 3.388
training: epoch 138, step 3600, loss 31.570074, time: 3.390
training: epoch 138, step 3800, loss 31.569466, time: 3.393
training: epoch 138, step 4000, loss 31.554845, time: 3.390
training: epoch 138, step 4200, loss 31.542137, time: 3.388
training: epoch 138, step 4400, loss 31.557089, time: 3.383
training: epoch 138, step 4600, loss 31.509259, time: 3.386
training: epoch 138, step 4800, loss 31.491278, time: 3.388
training: epoch 138, step 5000, loss 31.519408, time: 3.388
training: epoch 138, step 5200, loss 31.516099, time: 3.387
training: epoch 138, step 5400, loss 31.527251, time: 3.385
training: epoch 138, step 5600, loss 31.501428, time: 3.384
training: epoch 138, step 5800, loss 31.471179, time: 3.385
training: epoch 138, step 6000, loss 31.525388, time: 3.386
training: epoch 138, step 6200, loss 31.539166, time: 3.389
training: epoch 138, step 6400, loss 31.555889, time: 3.387
training: epoch 138, step 6600, loss 31.580687, time: 3.388
training: epoch 138, step 6800, loss 31.553550, time: 3.392
training: epoch 138, step 7000, loss 31.535480, time: 3.388
training: epoch 138, step 7200, loss 31.546272, time: 3.387
training: epoch 138, step 7400, loss 31.530696, time: 3.384
training: epoch 138, step 7600, loss 31.526022, time: 3.388
training: epoch 138, step 7800, loss 31.506093, time: 3.383
training: epoch 138, step 7849, loss 31.504190, time: 0.830
validate: epoch 138, loss 35.509597, charcter error 6.378 time: 4.020
training: epoch 139, step 200, loss 32.203478, time: 3.340
training: epoch 139, step 400, loss 31.847278, time: 3.380
training: epoch 139, step 600, loss 31.836701, time: 3.389
training: epoch 139, step 800, loss 31.780713, time: 3.386
training: epoch 139, step 1000, loss 31.766433, time: 3.384
training: epoch 139, step 1200, loss 31.708623, time: 3.384
training: epoch 139, step 1400, loss 31.685668, time: 3.388
training: epoch 139, step 1600, loss 31.642136, time: 3.388
training: epoch 139, step 1800, loss 31.740431, time: 3.388
training: epoch 139, step 2000, loss 31.571772, time: 3.388
training: epoch 139, step 2200, loss 31.630770, time: 3.382
training: epoch 139, step 2400, loss 31.524782, time: 3.383
training: epoch 139, step 2600, loss 31.508479, time: 3.397
training: epoch 139, step 2800, loss 31.495194, time: 3.386
training: epoch 139, step 3000, loss 31.479826, time: 3.385
training: epoch 139, step 3200, loss 31.472254, time: 3.385
training: epoch 139, step 3400, loss 31.503372, time: 3.382
training: epoch 139, step 3600, loss 31.544105, time: 3.391
training: epoch 139, step 3800, loss 31.507523, time: 3.393
training: epoch 139, step 4000, loss 31.486099, time: 3.397
training: epoch 139, step 4200, loss 31.472591, time: 3.391
training: epoch 139, step 4400, loss 31.447966, time: 3.394
training: epoch 139, step 4600, loss 31.424905, time: 3.385
training: epoch 139, step 4800, loss 31.429649, time: 3.392
training: epoch 139, step 5000, loss 31.449630, time: 3.397
training: epoch 139, step 5200, loss 31.435763, time: 3.395
training: epoch 139, step 5400, loss 31.453142, time: 3.406
training: epoch 139, step 5600, loss 31.474083, time: 3.398
training: epoch 139, step 5800, loss 31.473974, time: 3.396
training: epoch 139, step 6000, loss 31.472423, time: 3.398
training: epoch 139, step 6200, loss 31.467677, time: 3.422
training: epoch 139, step 6400, loss 31.437138, time: 3.394
training: epoch 139, step 6600, loss 31.456791, time: 3.447
training: epoch 139, step 6800, loss 31.429468, time: 3.491
training: epoch 139, step 7000, loss 31.447865, time: 3.564
training: epoch 139, step 7200, loss 31.452865, time: 3.594
training: epoch 139, step 7400, loss 31.457483, time: 3.546
training: epoch 139, step 7600, loss 31.469233, time: 3.544
training: epoch 139, step 7800, loss 31.475606, time: 3.576
training: epoch 139, step 7849, loss 31.484796, time: 0.873
validate: epoch 139, loss 36.017566, charcter error 6.492 time: 4.039
training: epoch 140, step 200, loss 33.245049, time: 3.546
training: epoch 140, step 400, loss 32.644359, time: 3.541
training: epoch 140, step 600, loss 32.004813, time: 3.567
training: epoch 140, step 800, loss 31.827463, time: 3.534
training: epoch 140, step 1000, loss 31.692118, time: 3.510
training: epoch 140, step 1200, loss 31.484020, time: 3.601
training: epoch 140, step 1400, loss 31.395864, time: 3.560
training: epoch 140, step 1600, loss 31.402536, time: 3.488
training: epoch 140, step 1800, loss 31.484486, time: 3.474
training: epoch 140, step 2000, loss 31.447675, time: 3.497
training: epoch 140, step 2200, loss 31.461254, time: 3.486
training: epoch 140, step 2400, loss 31.445573, time: 3.453
training: epoch 140, step 2600, loss 31.417119, time: 3.464
training: epoch 140, step 2800, loss 31.392385, time: 3.453
training: epoch 140, step 3000, loss 31.414229, time: 3.439
training: epoch 140, step 3200, loss 31.453811, time: 3.440
training: epoch 140, step 3400, loss 31.424178, time: 3.442
training: epoch 140, step 3600, loss 31.464279, time: 3.431
training: epoch 140, step 3800, loss 31.450269, time: 3.441
training: epoch 140, step 4000, loss 31.455926, time: 3.423
training: epoch 140, step 4200, loss 31.453652, time: 3.406
training: epoch 140, step 4400, loss 31.444167, time: 3.415
training: epoch 140, step 4600, loss 31.472421, time: 3.413
training: epoch 140, step 4800, loss 31.441585, time: 3.406
training: epoch 140, step 5000, loss 31.462013, time: 3.402
training: epoch 140, step 5200, loss 31.419362, time: 3.402
training: epoch 140, step 5400, loss 31.443267, time: 3.408
training: epoch 140, step 5600, loss 31.482118, time: 3.399
training: epoch 140, step 5800, loss 31.497493, time: 3.397
training: epoch 140, step 6000, loss 31.506313, time: 3.393
training: epoch 140, step 6200, loss 31.480871, time: 3.396
training: epoch 140, step 6400, loss 31.479413, time: 3.398
training: epoch 140, step 6600, loss 31.458288, time: 3.396
training: epoch 140, step 6800, loss 31.449537, time: 3.398
training: epoch 140, step 7000, loss 31.472884, time: 3.387
training: epoch 140, step 7200, loss 31.478331, time: 3.391
training: epoch 140, step 7400, loss 31.484107, time: 3.386
training: epoch 140, step 7600, loss 31.448636, time: 3.385
training: epoch 140, step 7800, loss 31.464989, time: 3.391
training: epoch 140, step 7849, loss 31.463243, time: 0.831
validate: epoch 140, loss 35.365602, charcter error 6.341 time: 4.039
training: epoch 141, step 200, loss 30.475210, time: 3.343
training: epoch 141, step 400, loss 31.019250, time: 3.385
training: epoch 141, step 600, loss 31.446534, time: 3.388
training: epoch 141, step 800, loss 31.609773, time: 3.391
training: epoch 141, step 1000, loss 31.728779, time: 3.392
training: epoch 141, step 1200, loss 31.728605, time: 3.386
training: epoch 141, step 1400, loss 31.711638, time: 3.391
training: epoch 141, step 1600, loss 31.793026, time: 3.391
training: epoch 141, step 1800, loss 31.802776, time: 3.405
training: epoch 141, step 2000, loss 31.727310, time: 3.603
training: epoch 141, step 2200, loss 31.671586, time: 3.505
training: epoch 141, step 2400, loss 31.702652, time: 3.508
training: epoch 141, step 2600, loss 31.654082, time: 3.510
training: epoch 141, step 2800, loss 31.668886, time: 3.498
training: epoch 141, step 3000, loss 31.696722, time: 3.535
training: epoch 141, step 3200, loss 31.670137, time: 3.501
training: epoch 141, step 3400, loss 31.640326, time: 3.478
training: epoch 141, step 3600, loss 31.680946, time: 3.452
training: epoch 141, step 3800, loss 31.668897, time: 3.481
training: epoch 141, step 4000, loss 31.637293, time: 3.522
training: epoch 141, step 4200, loss 31.614374, time: 3.504
training: epoch 141, step 4400, loss 31.526782, time: 3.516
training: epoch 141, step 4600, loss 31.498342, time: 3.499
training: epoch 141, step 4800, loss 31.475581, time: 3.506
training: epoch 141, step 5000, loss 31.478833, time: 3.519
training: epoch 141, step 5200, loss 31.516498, time: 3.439
training: epoch 141, step 5400, loss 31.505628, time: 3.389
training: epoch 141, step 5600, loss 31.479746, time: 3.391
training: epoch 141, step 5800, loss 31.514382, time: 3.397
training: epoch 141, step 6000, loss 31.504391, time: 3.406
training: epoch 141, step 6200, loss 31.500526, time: 3.413
training: epoch 141, step 6400, loss 31.488265, time: 3.560
training: epoch 141, step 6600, loss 31.470505, time: 3.503
training: epoch 141, step 6800, loss 31.483699, time: 3.494
training: epoch 141, step 7000, loss 31.474430, time: 3.487
training: epoch 141, step 7200, loss 31.468290, time: 3.469
training: epoch 141, step 7400, loss 31.468774, time: 3.466
training: epoch 141, step 7600, loss 31.447120, time: 3.480
training: epoch 141, step 7800, loss 31.452575, time: 3.459
training: epoch 141, step 7849, loss 31.448795, time: 0.849
validate: epoch 141, loss 35.287245, charcter error 6.352 time: 4.038
training: epoch 142, step 200, loss 31.731227, time: 3.495
training: epoch 142, step 400, loss 31.721786, time: 3.498
training: epoch 142, step 600, loss 31.528627, time: 3.490
training: epoch 142, step 800, loss 31.465965, time: 3.479
training: epoch 142, step 1000, loss 31.441620, time: 3.483
training: epoch 142, step 1200, loss 31.308309, time: 3.475
training: epoch 142, step 1400, loss 31.257370, time: 3.480
training: epoch 142, step 1600, loss 31.257072, time: 3.651
training: epoch 142, step 1800, loss 31.236218, time: 3.646
training: epoch 142, step 2000, loss 31.246141, time: 3.549
training: epoch 142, step 2200, loss 31.231393, time: 3.491
training: epoch 142, step 2400, loss 31.307321, time: 3.539
training: epoch 142, step 2600, loss 31.280032, time: 3.635
training: epoch 142, step 2800, loss 31.271038, time: 3.554
training: epoch 142, step 3000, loss 31.242633, time: 3.514
training: epoch 142, step 3200, loss 31.274526, time: 3.501
training: epoch 142, step 3400, loss 31.314031, time: 3.509
training: epoch 142, step 3600, loss 31.312739, time: 3.456
training: epoch 142, step 3800, loss 31.284549, time: 3.457
training: epoch 142, step 4000, loss 31.257234, time: 3.468
training: epoch 142, step 4200, loss 31.256473, time: 3.516
training: epoch 142, step 4400, loss 31.261169, time: 3.474
training: epoch 142, step 4600, loss 31.276667, time: 3.487
training: epoch 142, step 4800, loss 31.261877, time: 3.460
training: epoch 142, step 5000, loss 31.297008, time: 3.448
training: epoch 142, step 5200, loss 31.304760, time: 3.457
training: epoch 142, step 5400, loss 31.329457, time: 3.454
training: epoch 142, step 5600, loss 31.320212, time: 3.457
training: epoch 142, step 5800, loss 31.315725, time: 3.445
training: epoch 142, step 6000, loss 31.323735, time: 3.444
training: epoch 142, step 6200, loss 31.345350, time: 3.444
training: epoch 142, step 6400, loss 31.373119, time: 3.431
training: epoch 142, step 6600, loss 31.388597, time: 3.426
training: epoch 142, step 6800, loss 31.401263, time: 3.432
training: epoch 142, step 7000, loss 31.417426, time: 3.424
training: epoch 142, step 7200, loss 31.428176, time: 3.422
training: epoch 142, step 7400, loss 31.485027, time: 3.416
training: epoch 142, step 7600, loss 31.464023, time: 3.410
training: epoch 142, step 7800, loss 31.468674, time: 3.403
training: epoch 142, step 7849, loss 31.470841, time: 0.835
validate: epoch 142, loss 35.440311, charcter error 6.369 time: 4.036
training: epoch 143, step 200, loss 31.276971, time: 3.364
training: epoch 143, step 400, loss 31.726684, time: 3.399
training: epoch 143, step 600, loss 31.868836, time: 3.404
training: epoch 143, step 800, loss 31.739241, time: 3.404
training: epoch 143, step 1000, loss 31.655841, time: 3.400
training: epoch 143, step 1200, loss 31.710781, time: 3.401
training: epoch 143, step 1400, loss 31.623739, time: 3.401
training: epoch 143, step 1600, loss 31.549265, time: 3.408
training: epoch 143, step 1800, loss 31.481918, time: 3.396
training: epoch 143, step 2000, loss 31.395127, time: 3.396
training: epoch 143, step 2200, loss 31.413110, time: 3.400
training: epoch 143, step 2400, loss 31.491215, time: 3.401
training: epoch 143, step 2600, loss 31.458285, time: 3.401
training: epoch 143, step 2800, loss 31.385135, time: 3.400
training: epoch 143, step 3000, loss 31.320437, time: 3.401
training: epoch 143, step 3200, loss 31.306179, time: 3.402
training: epoch 143, step 3400, loss 31.231261, time: 3.396
training: epoch 143, step 3600, loss 31.211681, time: 3.399
training: epoch 143, step 3800, loss 31.234120, time: 3.397
training: epoch 143, step 4000, loss 31.280589, time: 3.396
training: epoch 143, step 4200, loss 31.258359, time: 3.397
training: epoch 143, step 4400, loss 31.242200, time: 3.402
training: epoch 143, step 4600, loss 31.265267, time: 3.394
training: epoch 143, step 4800, loss 31.289507, time: 3.392
training: epoch 143, step 5000, loss 31.241129, time: 3.395
training: epoch 143, step 5200, loss 31.250211, time: 3.390
training: epoch 143, step 5400, loss 31.235059, time: 3.394
training: epoch 143, step 5600, loss 31.234599, time: 3.397
training: epoch 143, step 5800, loss 31.220089, time: 3.391
training: epoch 143, step 6000, loss 31.212847, time: 3.396
training: epoch 143, step 6200, loss 31.261958, time: 3.398
training: epoch 143, step 6400, loss 31.280750, time: 3.394
training: epoch 143, step 6600, loss 31.339148, time: 3.394
training: epoch 143, step 6800, loss 31.365046, time: 3.394
training: epoch 143, step 7000, loss 31.373387, time: 3.393
training: epoch 143, step 7200, loss 31.375442, time: 3.391
training: epoch 143, step 7400, loss 31.375189, time: 3.394
training: epoch 143, step 7600, loss 31.380841, time: 3.392
training: epoch 143, step 7800, loss 31.399543, time: 3.389
training: epoch 143, step 7849, loss 31.399354, time: 0.833
validate: epoch 143, loss 35.251612, charcter error 6.341 time: 4.034
training: epoch 144, step 200, loss 31.190581, time: 3.347
training: epoch 144, step 400, loss 31.110133, time: 3.399
training: epoch 144, step 600, loss 31.332584, time: 3.403
training: epoch 144, step 800, loss 31.139546, time: 3.399
training: epoch 144, step 1000, loss 31.120979, time: 3.397
training: epoch 144, step 1200, loss 31.140673, time: 3.397
training: epoch 144, step 1400, loss 31.073877, time: 3.396
training: epoch 144, step 1600, loss 31.147482, time: 3.395
training: epoch 144, step 1800, loss 31.087526, time: 3.394
training: epoch 144, step 2000, loss 31.149267, time: 3.392
training: epoch 144, step 2200, loss 31.236863, time: 3.402
training: epoch 144, step 2400, loss 31.280986, time: 3.397
training: epoch 144, step 2600, loss 31.236065, time: 3.392
training: epoch 144, step 2800, loss 31.271872, time: 3.396
training: epoch 144, step 3000, loss 31.254183, time: 3.390
training: epoch 144, step 3200, loss 31.273084, time: 3.392
training: epoch 144, step 3400, loss 31.354953, time: 3.396
training: epoch 144, step 3600, loss 31.338239, time: 3.393
training: epoch 144, step 3800, loss 31.363251, time: 3.396
training: epoch 144, step 4000, loss 31.405437, time: 3.393
training: epoch 144, step 4200, loss 31.450241, time: 3.392
training: epoch 144, step 4400, loss 31.449557, time: 3.397
training: epoch 144, step 4600, loss 31.473645, time: 3.388
training: epoch 144, step 4800, loss 31.504232, time: 3.390
training: epoch 144, step 5000, loss 31.471320, time: 3.397
training: epoch 144, step 5200, loss 31.445264, time: 3.390
training: epoch 144, step 5400, loss 31.404565, time: 3.391
training: epoch 144, step 5600, loss 31.421540, time: 3.393
training: epoch 144, step 5800, loss 31.399868, time: 3.390
training: epoch 144, step 6000, loss 31.385432, time: 3.392
training: epoch 144, step 6200, loss 31.375405, time: 3.394
training: epoch 144, step 6400, loss 31.392781, time: 3.394
training: epoch 144, step 6600, loss 31.407211, time: 3.397
training: epoch 144, step 6800, loss 31.420748, time: 3.394
training: epoch 144, step 7000, loss 31.482263, time: 3.397
training: epoch 144, step 7200, loss 31.459258, time: 3.392
training: epoch 144, step 7400, loss 31.481021, time: 3.394
training: epoch 144, step 7600, loss 31.466160, time: 3.394
training: epoch 144, step 7800, loss 31.505554, time: 3.391
training: epoch 144, step 7849, loss 31.502933, time: 0.831
validate: epoch 144, loss 35.513540, charcter error 6.367 time: 4.022
training: epoch 145, step 200, loss 31.437624, time: 3.344
training: epoch 145, step 400, loss 31.038926, time: 3.386
training: epoch 145, step 600, loss 31.282271, time: 3.392
training: epoch 145, step 800, loss 31.401229, time: 3.389
training: epoch 145, step 1000, loss 31.527236, time: 3.388
training: epoch 145, step 1200, loss 31.581400, time: 3.393
training: epoch 145, step 1400, loss 31.601491, time: 3.397
training: epoch 145, step 1600, loss 31.491501, time: 3.397
training: epoch 145, step 1800, loss 31.332105, time: 3.396
training: epoch 145, step 2000, loss 31.389369, time: 3.396
training: epoch 145, step 2200, loss 31.444756, time: 3.395
training: epoch 145, step 2400, loss 31.464158, time: 3.394
training: epoch 145, step 2600, loss 31.467841, time: 3.390
training: epoch 145, step 2800, loss 31.434794, time: 3.391
training: epoch 145, step 3000, loss 31.429806, time: 3.397
training: epoch 145, step 3200, loss 31.450470, time: 3.398
training: epoch 145, step 3400, loss 31.517632, time: 3.398
training: epoch 145, step 3600, loss 31.503449, time: 3.396
training: epoch 145, step 3800, loss 31.488419, time: 3.389
training: epoch 145, step 4000, loss 31.502708, time: 3.390
training: epoch 145, step 4200, loss 31.441335, time: 3.391
training: epoch 145, step 4400, loss 31.440195, time: 3.390
training: epoch 145, step 4600, loss 31.394708, time: 3.395
training: epoch 145, step 4800, loss 31.369272, time: 3.393
training: epoch 145, step 5000, loss 31.335313, time: 3.391
training: epoch 145, step 5200, loss 31.341359, time: 3.393
training: epoch 145, step 5400, loss 31.376766, time: 3.394
training: epoch 145, step 5600, loss 31.375085, time: 3.393
training: epoch 145, step 5800, loss 31.356964, time: 3.397
training: epoch 145, step 6000, loss 31.370246, time: 3.395
training: epoch 145, step 6200, loss 31.359529, time: 3.394
training: epoch 145, step 6400, loss 31.395909, time: 3.387
training: epoch 145, step 6600, loss 31.364318, time: 3.392
training: epoch 145, step 6800, loss 31.418376, time: 3.391
training: epoch 145, step 7000, loss 31.440204, time: 3.388
training: epoch 145, step 7200, loss 31.463838, time: 3.392
training: epoch 145, step 7400, loss 31.465932, time: 3.398
training: epoch 145, step 7600, loss 31.470039, time: 3.402
training: epoch 145, step 7800, loss 31.480899, time: 3.408
training: epoch 145, step 7849, loss 31.479437, time: 0.833
validate: epoch 145, loss 35.400703, charcter error 6.359 time: 4.021
training: epoch 146, step 200, loss 32.206964, time: 3.350
training: epoch 146, step 400, loss 31.547159, time: 3.387
training: epoch 146, step 600, loss 31.038990, time: 3.394
training: epoch 146, step 800, loss 31.585181, time: 3.394
training: epoch 146, step 1000, loss 31.569439, time: 3.392
training: epoch 146, step 1200, loss 31.522510, time: 3.390
training: epoch 146, step 1400, loss 31.551606, time: 3.389
training: epoch 146, step 1600, loss 31.418936, time: 3.392
training: epoch 146, step 1800, loss 31.409200, time: 3.387
training: epoch 146, step 2000, loss 31.424371, time: 3.387
training: epoch 146, step 2200, loss 31.338248, time: 3.388
training: epoch 146, step 2400, loss 31.358507, time: 3.390
training: epoch 146, step 2600, loss 31.310732, time: 3.390
training: epoch 146, step 2800, loss 31.333818, time: 3.390
training: epoch 146, step 3000, loss 31.333374, time: 3.388
training: epoch 146, step 3200, loss 31.372959, time: 3.390
training: epoch 146, step 3400, loss 31.367293, time: 3.384
training: epoch 146, step 3600, loss 31.390215, time: 3.384
training: epoch 146, step 3800, loss 31.364073, time: 3.389
training: epoch 146, step 4000, loss 31.372102, time: 3.384
training: epoch 146, step 4200, loss 31.386466, time: 3.383
training: epoch 146, step 4400, loss 31.374007, time: 3.386
training: epoch 146, step 4600, loss 31.362052, time: 3.383
training: epoch 146, step 4800, loss 31.372970, time: 3.386
training: epoch 146, step 5000, loss 31.383531, time: 3.384
training: epoch 146, step 5200, loss 31.364759, time: 3.385
training: epoch 146, step 5400, loss 31.356404, time: 3.387
training: epoch 146, step 5600, loss 31.349815, time: 3.383
training: epoch 146, step 5800, loss 31.361707, time: 3.386
training: epoch 146, step 6000, loss 31.352356, time: 3.386
training: epoch 146, step 6200, loss 31.324687, time: 3.387
training: epoch 146, step 6400, loss 31.326174, time: 3.382
training: epoch 146, step 6600, loss 31.303805, time: 3.385
training: epoch 146, step 6800, loss 31.283582, time: 3.382
training: epoch 146, step 7000, loss 31.320535, time: 3.383
training: epoch 146, step 7200, loss 31.317562, time: 3.381
training: epoch 146, step 7400, loss 31.341489, time: 3.385
training: epoch 146, step 7600, loss 31.338193, time: 3.385
training: epoch 146, step 7800, loss 31.360737, time: 3.388
training: epoch 146, step 7849, loss 31.356391, time: 0.830
validate: epoch 146, loss 35.301121, charcter error 6.336 time: 4.025
training: epoch 147, step 200, loss 31.893882, time: 3.338
training: epoch 147, step 400, loss 31.295344, time: 3.379
training: epoch 147, step 600, loss 31.141710, time: 3.384
training: epoch 147, step 800, loss 31.370428, time: 3.390
training: epoch 147, step 1000, loss 31.317122, time: 3.388
training: epoch 147, step 1200, loss 31.236500, time: 3.387
training: epoch 147, step 1400, loss 31.249142, time: 3.389
training: epoch 147, step 1600, loss 31.361840, time: 3.390
training: epoch 147, step 1800, loss 31.387194, time: 3.389
training: epoch 147, step 2000, loss 31.390587, time: 3.387
training: epoch 147, step 2200, loss 31.438499, time: 3.387
training: epoch 147, step 2400, loss 31.289816, time: 3.387
training: epoch 147, step 2600, loss 31.306997, time: 3.392
training: epoch 147, step 2800, loss 31.228983, time: 3.390
training: epoch 147, step 3000, loss 31.196169, time: 3.390
training: epoch 147, step 3200, loss 31.191176, time: 3.388
training: epoch 147, step 3400, loss 31.215382, time: 3.392
training: epoch 147, step 3600, loss 31.240643, time: 3.393
training: epoch 147, step 3800, loss 31.233853, time: 3.395
training: epoch 147, step 4000, loss 31.230044, time: 3.394
training: epoch 147, step 4200, loss 31.294116, time: 3.392
training: epoch 147, step 4400, loss 31.284399, time: 3.387
training: epoch 147, step 4600, loss 31.310542, time: 3.388
training: epoch 147, step 4800, loss 31.303847, time: 3.390
training: epoch 147, step 5000, loss 31.319663, time: 3.391
training: epoch 147, step 5200, loss 31.304766, time: 3.391
training: epoch 147, step 5400, loss 31.330318, time: 3.389
training: epoch 147, step 5600, loss 31.360810, time: 3.391
training: epoch 147, step 5800, loss 31.393315, time: 3.389
training: epoch 147, step 6000, loss 31.398808, time: 3.389
training: epoch 147, step 6200, loss 31.375140, time: 3.390
training: epoch 147, step 6400, loss 31.347003, time: 3.383
training: epoch 147, step 6600, loss 31.325269, time: 3.387
training: epoch 147, step 6800, loss 31.320040, time: 3.391
training: epoch 147, step 7000, loss 31.321764, time: 3.390
training: epoch 147, step 7200, loss 31.293014, time: 3.389
training: epoch 147, step 7400, loss 31.298264, time: 3.392
training: epoch 147, step 7600, loss 31.284672, time: 3.387
training: epoch 147, step 7800, loss 31.289115, time: 3.387
training: epoch 147, step 7849, loss 31.280563, time: 0.831
validate: epoch 147, loss 35.092731, charcter error 6.302 time: 4.020
    - [Info] The checkpoint file has been updated.
training: epoch 148, step 200, loss 30.350298, time: 3.346
training: epoch 148, step 400, loss 30.085808, time: 3.384
training: epoch 148, step 600, loss 30.513815, time: 3.388
training: epoch 148, step 800, loss 30.567724, time: 3.388
training: epoch 148, step 1000, loss 31.180719, time: 3.387
training: epoch 148, step 1200, loss 31.335808, time: 3.389
training: epoch 148, step 1400, loss 31.274082, time: 3.386
training: epoch 148, step 1600, loss 31.151193, time: 3.385
training: epoch 148, step 1800, loss 31.075335, time: 3.383
training: epoch 148, step 2000, loss 31.115635, time: 3.384
training: epoch 148, step 2200, loss 31.142016, time: 3.387
training: epoch 148, step 2400, loss 31.158445, time: 3.385
training: epoch 148, step 2600, loss 31.212208, time: 3.385
training: epoch 148, step 2800, loss 31.213711, time: 3.387
training: epoch 148, step 3000, loss 31.191349, time: 3.385
training: epoch 148, step 3200, loss 31.128999, time: 3.387
training: epoch 148, step 3400, loss 31.085006, time: 3.390
training: epoch 148, step 3600, loss 31.053167, time: 3.390
training: epoch 148, step 3800, loss 31.049091, time: 3.389
training: epoch 148, step 4000, loss 31.027879, time: 3.388
training: epoch 148, step 4200, loss 31.015105, time: 3.386
training: epoch 148, step 4400, loss 31.025258, time: 3.384
training: epoch 148, step 4600, loss 31.101352, time: 3.388
training: epoch 148, step 4800, loss 31.130452, time: 3.386
training: epoch 148, step 5000, loss 31.115610, time: 3.389
training: epoch 148, step 5200, loss 31.166743, time: 3.390
training: epoch 148, step 5400, loss 31.201210, time: 3.392
training: epoch 148, step 5600, loss 31.209724, time: 3.398
training: epoch 148, step 5800, loss 31.218152, time: 3.390
training: epoch 148, step 6000, loss 31.266959, time: 3.395
training: epoch 148, step 6200, loss 31.244019, time: 3.385
training: epoch 148, step 6400, loss 31.287931, time: 3.389
training: epoch 148, step 6600, loss 31.281456, time: 3.387
training: epoch 148, step 6800, loss 31.264570, time: 3.386
training: epoch 148, step 7000, loss 31.288248, time: 3.393
training: epoch 148, step 7200, loss 31.285477, time: 3.390
training: epoch 148, step 7400, loss 31.284506, time: 3.388
training: epoch 148, step 7600, loss 31.304013, time: 3.387
training: epoch 148, step 7800, loss 31.312472, time: 3.393
training: epoch 148, step 7849, loss 31.313060, time: 0.842
validate: epoch 148, loss 35.227746, charcter error 6.334 time: 4.019
training: epoch 149, step 200, loss 31.074750, time: 3.354
training: epoch 149, step 400, loss 31.010105, time: 3.388
training: epoch 149, step 600, loss 30.903313, time: 3.393
training: epoch 149, step 800, loss 31.139716, time: 3.396
training: epoch 149, step 1000, loss 31.127104, time: 3.394
training: epoch 149, step 1200, loss 31.164639, time: 3.398
training: epoch 149, step 1400, loss 31.235436, time: 3.396
training: epoch 149, step 1600, loss 31.253688, time: 3.394
training: epoch 149, step 1800, loss 31.182060, time: 3.393
training: epoch 149, step 2000, loss 31.195711, time: 3.394
training: epoch 149, step 2200, loss 31.156383, time: 3.396
training: epoch 149, step 2400, loss 31.217169, time: 3.394
training: epoch 149, step 2600, loss 31.239107, time: 3.390
training: epoch 149, step 2800, loss 31.212584, time: 3.389
training: epoch 149, step 3000, loss 31.180233, time: 3.394
training: epoch 149, step 3200, loss 31.180238, time: 3.392
training: epoch 149, step 3400, loss 31.159682, time: 3.392
training: epoch 149, step 3600, loss 31.160436, time: 3.393
training: epoch 149, step 3800, loss 31.069053, time: 3.392
training: epoch 149, step 4000, loss 31.052901, time: 3.392
training: epoch 149, step 4200, loss 31.078577, time: 3.394
training: epoch 149, step 4400, loss 31.105340, time: 3.389
training: epoch 149, step 4600, loss 31.146056, time: 3.395
training: epoch 149, step 4800, loss 31.121636, time: 3.389
training: epoch 149, step 5000, loss 31.185692, time: 3.393
training: epoch 149, step 5200, loss 31.174433, time: 3.394
training: epoch 149, step 5400, loss 31.173344, time: 3.391
training: epoch 149, step 5600, loss 31.178979, time: 3.390
training: epoch 149, step 5800, loss 31.167957, time: 3.386
training: epoch 149, step 6000, loss 31.154786, time: 3.389
training: epoch 149, step 6200, loss 31.178026, time: 3.399
training: epoch 149, step 6400, loss 31.208853, time: 3.394
training: epoch 149, step 6600, loss 31.207208, time: 3.391
training: epoch 149, step 6800, loss 31.227576, time: 3.391
training: epoch 149, step 7000, loss 31.227853, time: 3.394
training: epoch 149, step 7200, loss 31.253930, time: 3.398
training: epoch 149, step 7400, loss 31.212054, time: 3.398
training: epoch 149, step 7600, loss 31.211753, time: 3.398
training: epoch 149, step 7800, loss 31.222130, time: 3.400
training: epoch 149, step 7849, loss 31.221252, time: 0.832
validate: epoch 149, loss 35.134769, charcter error 6.320 time: 4.027
training: epoch 150, step 200, loss 31.303475, time: 3.345
training: epoch 150, step 400, loss 30.903609, time: 3.390
training: epoch 150, step 600, loss 30.831048, time: 3.388
training: epoch 150, step 800, loss 31.001812, time: 3.395
training: epoch 150, step 1000, loss 30.833776, time: 3.393
training: epoch 150, step 1200, loss 30.786848, time: 3.396
training: epoch 150, step 1400, loss 30.967240, time: 3.394
training: epoch 150, step 1600, loss 31.062820, time: 3.391
training: epoch 150, step 1800, loss 31.066378, time: 3.392
training: epoch 150, step 2000, loss 31.018439, time: 3.429
training: epoch 150, step 2200, loss 31.036974, time: 3.527
training: epoch 150, step 2400, loss 30.994968, time: 3.532
training: epoch 150, step 2600, loss 30.957612, time: 3.535
training: epoch 150, step 2800, loss 31.020627, time: 3.572
training: epoch 150, step 3000, loss 30.982780, time: 3.528
training: epoch 150, step 3200, loss 30.945711, time: 3.545
training: epoch 150, step 3400, loss 30.952305, time: 3.551
training: epoch 150, step 3600, loss 30.945772, time: 3.543
training: epoch 150, step 3800, loss 30.968483, time: 3.546
training: epoch 150, step 4000, loss 31.031740, time: 3.527
training: epoch 150, step 4200, loss 31.027008, time: 3.552
training: epoch 150, step 4400, loss 31.025974, time: 3.573
training: epoch 150, step 4600, loss 31.038467, time: 3.583
training: epoch 150, step 4800, loss 31.071278, time: 3.544
training: epoch 150, step 5000, loss 31.035121, time: 3.537
training: epoch 150, step 5200, loss 31.067628, time: 3.479
training: epoch 150, step 5400, loss 31.057532, time: 3.448
training: epoch 150, step 5600, loss 31.033058, time: 3.476
training: epoch 150, step 5800, loss 31.044678, time: 3.452
training: epoch 150, step 6000, loss 31.006720, time: 3.441
training: epoch 150, step 6200, loss 31.038501, time: 3.442
training: epoch 150, step 6400, loss 31.065647, time: 3.435
training: epoch 150, step 6600, loss 31.051368, time: 3.435
training: epoch 150, step 6800, loss 31.068580, time: 3.418
training: epoch 150, step 7000, loss 31.111241, time: 3.417
training: epoch 150, step 7200, loss 31.150572, time: 3.422
training: epoch 150, step 7400, loss 31.188773, time: 3.418
training: epoch 150, step 7600, loss 31.195356, time: 3.423
training: epoch 150, step 7800, loss 31.217376, time: 3.413
training: epoch 150, step 7849, loss 31.234140, time: 0.838
validate: epoch 150, loss 35.238638, charcter error 6.327 time: 4.046
training: epoch 151, step 200, loss 30.519386, time: 3.360
training: epoch 151, step 400, loss 30.492215, time: 3.401
training: epoch 151, step 600, loss 30.957276, time: 3.406
training: epoch 151, step 800, loss 30.916619, time: 3.516
training: epoch 151, step 1000, loss 30.895592, time: 3.777
training: epoch 151, step 1200, loss 30.822376, time: 3.902
training: epoch 151, step 1400, loss 30.643518, time: 3.850
training: epoch 151, step 1600, loss 30.646873, time: 3.802
training: epoch 151, step 1800, loss 30.693880, time: 3.777
training: epoch 151, step 2000, loss 30.715480, time: 3.755
training: epoch 151, step 2200, loss 30.785544, time: 3.758
training: epoch 151, step 2400, loss 30.830781, time: 3.753
training: epoch 151, step 2600, loss 30.809564, time: 3.565
training: epoch 151, step 2800, loss 30.813138, time: 3.523
training: epoch 151, step 3000, loss 30.797053, time: 3.510
training: epoch 151, step 3200, loss 30.823409, time: 3.495
training: epoch 151, step 3400, loss 30.836970, time: 3.484
training: epoch 151, step 3600, loss 30.826967, time: 3.472
training: epoch 151, step 3800, loss 30.856543, time: 3.466
training: epoch 151, step 4000, loss 30.903405, time: 3.476
training: epoch 151, step 4200, loss 30.895081, time: 3.447
training: epoch 151, step 4400, loss 30.905516, time: 3.444
training: epoch 151, step 4600, loss 30.899166, time: 3.427
training: epoch 151, step 4800, loss 30.912439, time: 3.424
training: epoch 151, step 5000, loss 30.909124, time: 3.399
training: epoch 151, step 5200, loss 31.013863, time: 3.490
training: epoch 151, step 5400, loss 31.017354, time: 3.558
training: epoch 151, step 5600, loss 31.044773, time: 3.532
training: epoch 151, step 5800, loss 31.107544, time: 3.516
training: epoch 151, step 6000, loss 31.109327, time: 3.522
training: epoch 151, step 6200, loss 31.099386, time: 3.565
training: epoch 151, step 6400, loss 31.101953, time: 3.626
training: epoch 151, step 6600, loss 31.084706, time: 3.619
training: epoch 151, step 6800, loss 31.115151, time: 3.611
training: epoch 151, step 7000, loss 31.151531, time: 3.590
training: epoch 151, step 7200, loss 31.154813, time: 3.574
training: epoch 151, step 7400, loss 31.174574, time: 3.574
training: epoch 151, step 7600, loss 31.191827, time: 3.555
training: epoch 151, step 7800, loss 31.202665, time: 3.547
training: epoch 151, step 7849, loss 31.220585, time: 0.877
validate: epoch 151, loss 35.174387, charcter error 6.317 time: 4.040
training: epoch 152, step 200, loss 30.659394, time: 3.604
training: epoch 152, step 400, loss 31.115215, time: 3.619
training: epoch 152, step 600, loss 30.642868, time: 3.698
training: epoch 152, step 800, loss 30.804417, time: 3.617
training: epoch 152, step 1000, loss 30.976715, time: 3.559
training: epoch 152, step 1200, loss 31.131187, time: 3.560
training: epoch 152, step 1400, loss 31.071850, time: 3.530
training: epoch 152, step 1600, loss 31.022825, time: 3.538
training: epoch 152, step 1800, loss 31.020356, time: 3.508
training: epoch 152, step 2000, loss 31.037660, time: 3.503
training: epoch 152, step 2200, loss 31.089003, time: 3.399
training: epoch 152, step 2400, loss 31.044840, time: 3.394
training: epoch 152, step 2600, loss 31.098064, time: 3.423
training: epoch 152, step 2800, loss 31.158879, time: 3.420
training: epoch 152, step 3000, loss 31.177954, time: 3.413
training: epoch 152, step 3200, loss 31.153374, time: 3.438
training: epoch 152, step 3400, loss 31.118612, time: 3.521
training: epoch 152, step 3600, loss 31.107110, time: 3.509
training: epoch 152, step 3800, loss 31.088829, time: 3.496
training: epoch 152, step 4000, loss 31.092442, time: 3.491
training: epoch 152, step 4200, loss 31.119497, time: 3.479
training: epoch 152, step 4400, loss 31.119869, time: 3.463
training: epoch 152, step 4600, loss 31.143143, time: 3.475
training: epoch 152, step 4800, loss 31.135008, time: 3.454
training: epoch 152, step 5000, loss 31.126242, time: 3.471
training: epoch 152, step 5200, loss 31.158204, time: 3.483
training: epoch 152, step 5400, loss 31.158158, time: 3.489
training: epoch 152, step 5600, loss 31.148933, time: 3.490
training: epoch 152, step 5800, loss 31.134054, time: 3.463
training: epoch 152, step 6000, loss 31.125510, time: 3.487
training: epoch 152, step 6200, loss 31.135024, time: 3.507
training: epoch 152, step 6400, loss 31.137315, time: 3.487
training: epoch 152, step 6600, loss 31.115715, time: 3.716
training: epoch 152, step 6800, loss 31.112662, time: 3.530
training: epoch 152, step 7000, loss 31.107483, time: 3.529
training: epoch 152, step 7200, loss 31.115911, time: 3.676
training: epoch 152, step 7400, loss 31.139632, time: 3.605
training: epoch 152, step 7600, loss 31.140141, time: 3.537
training: epoch 152, step 7800, loss 31.183178, time: 3.507
training: epoch 152, step 7849, loss 31.199033, time: 0.858
validate: epoch 152, loss 35.384217, charcter error 6.346 time: 4.043
training: epoch 153, step 200, loss 30.977987, time: 3.471
training: epoch 153, step 400, loss 31.308659, time: 3.481
training: epoch 153, step 600, loss 31.070943, time: 3.475
training: epoch 153, step 800, loss 30.939342, time: 3.567
training: epoch 153, step 1000, loss 30.842953, time: 3.509
training: epoch 153, step 1200, loss 30.981917, time: 3.501
training: epoch 153, step 1400, loss 31.192496, time: 3.504
training: epoch 153, step 1600, loss 31.031704, time: 3.472
training: epoch 153, step 1800, loss 31.057377, time: 3.507
training: epoch 153, step 2000, loss 31.075534, time: 3.476
training: epoch 153, step 2200, loss 31.024991, time: 3.457
training: epoch 153, step 2400, loss 31.021130, time: 3.460
training: epoch 153, step 2600, loss 30.993846, time: 3.449
training: epoch 153, step 2800, loss 31.020615, time: 3.454
training: epoch 153, step 3000, loss 31.114767, time: 3.444
training: epoch 153, step 3200, loss 31.069277, time: 3.430
training: epoch 153, step 3400, loss 31.070351, time: 3.440
training: epoch 153, step 3600, loss 31.094917, time: 3.436
training: epoch 153, step 3800, loss 31.099404, time: 3.425
training: epoch 153, step 4000, loss 31.117443, time: 3.423
training: epoch 153, step 4200, loss 31.120441, time: 3.421
training: epoch 153, step 4400, loss 31.125172, time: 3.430
training: epoch 153, step 4600, loss 31.134226, time: 3.418
training: epoch 153, step 4800, loss 31.163566, time: 3.413
training: epoch 153, step 5000, loss 31.124676, time: 3.403
training: epoch 153, step 5200, loss 31.130303, time: 3.417
training: epoch 153, step 5400, loss 31.140699, time: 3.405
training: epoch 153, step 5600, loss 31.156686, time: 3.407
training: epoch 153, step 5800, loss 31.151953, time: 3.408
training: epoch 153, step 6000, loss 31.135210, time: 3.409
training: epoch 153, step 6200, loss 31.121983, time: 3.404
training: epoch 153, step 6400, loss 31.100513, time: 3.402
training: epoch 153, step 6600, loss 31.118089, time: 3.400
training: epoch 153, step 6800, loss 31.121064, time: 3.407
training: epoch 153, step 7000, loss 31.097656, time: 3.409
training: epoch 153, step 7200, loss 31.098444, time: 3.410
training: epoch 153, step 7400, loss 31.095770, time: 3.414
training: epoch 153, step 7600, loss 31.094387, time: 3.408
training: epoch 153, step 7800, loss 31.121669, time: 3.409
training: epoch 153, step 7849, loss 31.118115, time: 0.836
validate: epoch 153, loss 35.224813, charcter error 6.338 time: 4.020
training: epoch 154, step 200, loss 31.575600, time: 3.341
training: epoch 154, step 400, loss 31.348689, time: 3.382
training: epoch 154, step 600, loss 31.435716, time: 3.393
training: epoch 154, step 800, loss 31.237546, time: 3.394
training: epoch 154, step 1000, loss 31.209311, time: 3.388
training: epoch 154, step 1200, loss 31.049882, time: 3.392
training: epoch 154, step 1400, loss 31.021081, time: 3.398
training: epoch 154, step 1600, loss 31.114946, time: 3.404
training: epoch 154, step 1800, loss 31.061726, time: 3.401
training: epoch 154, step 2000, loss 31.098163, time: 3.402
training: epoch 154, step 2200, loss 31.164174, time: 3.391
training: epoch 154, step 2400, loss 31.182585, time: 3.394
training: epoch 154, step 2600, loss 31.187957, time: 3.392
training: epoch 154, step 2800, loss 31.213663, time: 3.400
training: epoch 154, step 3000, loss 31.185014, time: 3.399
training: epoch 154, step 3200, loss 31.221369, time: 3.397
training: epoch 154, step 3400, loss 31.213044, time: 3.396
training: epoch 154, step 3600, loss 31.200249, time: 3.392
training: epoch 154, step 3800, loss 31.142797, time: 3.390
training: epoch 154, step 4000, loss 31.096707, time: 3.399
training: epoch 154, step 4200, loss 31.068485, time: 3.397
training: epoch 154, step 4400, loss 31.052479, time: 3.390
training: epoch 154, step 4600, loss 31.046919, time: 3.391
training: epoch 154, step 4800, loss 31.067110, time: 3.386
training: epoch 154, step 5000, loss 31.107421, time: 3.399
training: epoch 154, step 5200, loss 31.112279, time: 3.398
training: epoch 154, step 5400, loss 31.089351, time: 3.388
training: epoch 154, step 5600, loss 31.107301, time: 3.387
training: epoch 154, step 5800, loss 31.087710, time: 3.388
training: epoch 154, step 6000, loss 31.078168, time: 3.390
training: epoch 154, step 6200, loss 31.137384, time: 3.387
training: epoch 154, step 6400, loss 31.134926, time: 3.392
training: epoch 154, step 6600, loss 31.128012, time: 3.396
training: epoch 154, step 6800, loss 31.127146, time: 3.397
training: epoch 154, step 7000, loss 31.141568, time: 3.390
training: epoch 154, step 7200, loss 31.143361, time: 3.391
training: epoch 154, step 7400, loss 31.149448, time: 3.396
training: epoch 154, step 7600, loss 31.168925, time: 3.390
training: epoch 154, step 7800, loss 31.149389, time: 3.390
training: epoch 154, step 7849, loss 31.135221, time: 0.831
validate: epoch 154, loss 35.183425, charcter error 6.308 time: 4.020
training: epoch 155, step 200, loss 31.049391, time: 3.347
training: epoch 155, step 400, loss 30.639195, time: 3.381
training: epoch 155, step 600, loss 30.776599, time: 3.391
training: epoch 155, step 800, loss 30.911796, time: 3.402
training: epoch 155, step 1000, loss 30.677423, time: 3.395
training: epoch 155, step 1200, loss 30.832500, time: 3.393
training: epoch 155, step 1400, loss 30.850802, time: 3.397
training: epoch 155, step 1600, loss 30.836381, time: 3.394
training: epoch 155, step 1800, loss 30.869265, time: 3.390
training: epoch 155, step 2000, loss 30.910671, time: 3.401
training: epoch 155, step 2200, loss 30.930013, time: 3.396
training: epoch 155, step 2400, loss 30.970306, time: 3.391
training: epoch 155, step 2600, loss 30.952792, time: 3.394
training: epoch 155, step 2800, loss 30.975791, time: 3.395
training: epoch 155, step 3000, loss 30.972690, time: 3.395
training: epoch 155, step 3200, loss 30.988291, time: 3.394
training: epoch 155, step 3400, loss 31.037419, time: 3.399
training: epoch 155, step 3600, loss 31.038733, time: 3.399
training: epoch 155, step 3800, loss 31.096503, time: 3.404
training: epoch 155, step 4000, loss 31.144617, time: 3.399
training: epoch 155, step 4200, loss 31.115086, time: 3.394
training: epoch 155, step 4400, loss 31.084721, time: 3.393
training: epoch 155, step 4600, loss 31.085794, time: 3.393
training: epoch 155, step 4800, loss 31.068422, time: 3.399
training: epoch 155, step 5000, loss 31.079771, time: 3.397
training: epoch 155, step 5200, loss 31.066345, time: 3.400
training: epoch 155, step 5400, loss 31.069372, time: 3.400
training: epoch 155, step 5600, loss 31.060313, time: 3.397
training: epoch 155, step 5800, loss 31.050376, time: 3.394
training: epoch 155, step 6000, loss 31.055068, time: 3.395
training: epoch 155, step 6200, loss 31.046244, time: 3.397
training: epoch 155, step 6400, loss 31.067210, time: 3.396
training: epoch 155, step 6600, loss 31.087594, time: 3.394
training: epoch 155, step 6800, loss 31.087529, time: 3.398
training: epoch 155, step 7000, loss 31.076210, time: 3.402
training: epoch 155, step 7200, loss 31.043053, time: 3.394
training: epoch 155, step 7400, loss 31.040789, time: 3.396
training: epoch 155, step 7600, loss 31.080031, time: 3.395
training: epoch 155, step 7800, loss 31.097529, time: 3.397
training: epoch 155, step 7849, loss 31.087505, time: 0.834
validate: epoch 155, loss 35.204193, charcter error 6.308 time: 4.032
training: epoch 156, step 200, loss 31.734141, time: 3.351
training: epoch 156, step 400, loss 31.556457, time: 3.390
training: epoch 156, step 600, loss 31.691410, time: 3.400
training: epoch 156, step 800, loss 31.543660, time: 3.404
training: epoch 156, step 1000, loss 31.406691, time: 3.402
training: epoch 156, step 1200, loss 31.272070, time: 3.399
training: epoch 156, step 1400, loss 31.214880, time: 3.401
training: epoch 156, step 1600, loss 31.209590, time: 3.400
training: epoch 156, step 1800, loss 31.151146, time: 3.400
training: epoch 156, step 2000, loss 31.194226, time: 3.401
training: epoch 156, step 2200, loss 31.196442, time: 3.404
training: epoch 156, step 2400, loss 31.266353, time: 3.400
training: epoch 156, step 2600, loss 31.287675, time: 3.401
training: epoch 156, step 2800, loss 31.239341, time: 3.401
training: epoch 156, step 3000, loss 31.161338, time: 3.403
training: epoch 156, step 3200, loss 31.205573, time: 3.403
training: epoch 156, step 3400, loss 31.218668, time: 3.402
training: epoch 156, step 3600, loss 31.175071, time: 3.397
training: epoch 156, step 3800, loss 31.150673, time: 3.391
training: epoch 156, step 4000, loss 31.153800, time: 3.394
training: epoch 156, step 4200, loss 31.168456, time: 3.392
training: epoch 156, step 4400, loss 31.188991, time: 3.395
training: epoch 156, step 4600, loss 31.140363, time: 3.394
training: epoch 156, step 4800, loss 31.130794, time: 3.394
training: epoch 156, step 5000, loss 31.098319, time: 3.390
training: epoch 156, step 5200, loss 31.104394, time: 3.394
training: epoch 156, step 5400, loss 31.099779, time: 3.395
training: epoch 156, step 5600, loss 31.127368, time: 3.393
training: epoch 156, step 5800, loss 31.133191, time: 3.395
training: epoch 156, step 6000, loss 31.134906, time: 3.395
training: epoch 156, step 6200, loss 31.156995, time: 3.394
training: epoch 156, step 6400, loss 31.170458, time: 3.394
training: epoch 156, step 6600, loss 31.148545, time: 3.394
training: epoch 156, step 6800, loss 31.105287, time: 3.393
training: epoch 156, step 7000, loss 31.136003, time: 3.392
training: epoch 156, step 7200, loss 31.131553, time: 3.395
training: epoch 156, step 7400, loss 31.135364, time: 3.392
training: epoch 156, step 7600, loss 31.124473, time: 3.396
training: epoch 156, step 7800, loss 31.108707, time: 3.395
training: epoch 156, step 7849, loss 31.110744, time: 0.832
validate: epoch 156, loss 35.844753, charcter error 6.424 time: 4.021
training: epoch 157, step 200, loss 31.381063, time: 3.346
training: epoch 157, step 400, loss 31.121694, time: 3.387
training: epoch 157, step 600, loss 30.984644, time: 3.397
training: epoch 157, step 800, loss 31.202165, time: 3.393
training: epoch 157, step 1000, loss 30.876818, time: 3.393
training: epoch 157, step 1200, loss 30.866739, time: 3.393
training: epoch 157, step 1400, loss 30.915991, time: 3.398
training: epoch 157, step 1600, loss 31.005049, time: 3.397
training: epoch 157, step 1800, loss 30.920941, time: 3.399
training: epoch 157, step 2000, loss 30.892644, time: 3.398
training: epoch 157, step 2200, loss 30.976334, time: 3.392
training: epoch 157, step 2400, loss 30.927585, time: 3.395
training: epoch 157, step 2600, loss 30.937957, time: 3.392
training: epoch 157, step 2800, loss 30.887908, time: 3.393
training: epoch 157, step 3000, loss 30.851331, time: 3.396
training: epoch 157, step 3200, loss 30.866905, time: 3.392
training: epoch 157, step 3400, loss 30.855720, time: 3.391
training: epoch 157, step 3600, loss 30.848847, time: 3.395
training: epoch 157, step 3800, loss 30.866401, time: 3.393
training: epoch 157, step 4000, loss 30.857625, time: 3.393
training: epoch 157, step 4200, loss 30.854507, time: 3.394
training: epoch 157, step 4400, loss 30.881681, time: 3.393
training: epoch 157, step 4600, loss 30.873306, time: 3.396
training: epoch 157, step 4800, loss 30.930538, time: 3.393
training: epoch 157, step 5000, loss 30.995111, time: 3.391
training: epoch 157, step 5200, loss 30.968541, time: 3.391
training: epoch 157, step 5400, loss 30.991946, time: 3.393
training: epoch 157, step 5600, loss 31.016712, time: 3.392
training: epoch 157, step 5800, loss 31.036666, time: 3.394
training: epoch 157, step 6000, loss 31.006574, time: 3.392
training: epoch 157, step 6200, loss 31.005277, time: 3.394
training: epoch 157, step 6400, loss 31.020497, time: 3.395
training: epoch 157, step 6600, loss 31.006366, time: 3.393
training: epoch 157, step 6800, loss 31.007573, time: 3.394
training: epoch 157, step 7000, loss 31.016358, time: 3.396
training: epoch 157, step 7200, loss 31.002156, time: 3.396
training: epoch 157, step 7400, loss 31.002129, time: 3.392
training: epoch 157, step 7600, loss 31.017423, time: 3.394
training: epoch 157, step 7800, loss 31.026576, time: 3.392
training: epoch 157, step 7849, loss 31.013350, time: 0.830
validate: epoch 157, loss 35.126285, charcter error 6.302 time: 4.024
    - [Info] The checkpoint file has been updated.
training: epoch 158, step 200, loss 30.924667, time: 3.348
training: epoch 158, step 400, loss 30.828410, time: 3.379
training: epoch 158, step 600, loss 30.980437, time: 3.384
training: epoch 158, step 800, loss 31.013102, time: 3.383
training: epoch 158, step 1000, loss 31.049227, time: 3.386
training: epoch 158, step 1200, loss 30.895311, time: 3.384
training: epoch 158, step 1400, loss 30.839576, time: 3.382
training: epoch 158, step 1600, loss 30.818496, time: 3.384
training: epoch 158, step 1800, loss 30.857477, time: 3.385
training: epoch 158, step 2000, loss 30.944520, time: 3.388
training: epoch 158, step 2200, loss 30.915113, time: 3.386
training: epoch 158, step 2400, loss 30.912543, time: 3.384
training: epoch 158, step 2600, loss 30.895881, time: 3.389
training: epoch 158, step 2800, loss 30.917411, time: 3.388
training: epoch 158, step 3000, loss 30.932955, time: 3.385
training: epoch 158, step 3200, loss 30.945980, time: 3.381
training: epoch 158, step 3400, loss 30.947131, time: 3.386
training: epoch 158, step 3600, loss 30.964989, time: 3.391
training: epoch 158, step 3800, loss 31.011907, time: 3.393
training: epoch 158, step 4000, loss 31.049561, time: 3.388
training: epoch 158, step 4200, loss 31.064190, time: 3.386
training: epoch 158, step 4400, loss 31.061727, time: 3.392
training: epoch 158, step 4600, loss 31.094741, time: 3.388
training: epoch 158, step 4800, loss 31.091577, time: 3.390
training: epoch 158, step 5000, loss 31.098777, time: 3.387
training: epoch 158, step 5200, loss 31.094880, time: 3.388
training: epoch 158, step 5400, loss 31.137753, time: 3.394
training: epoch 158, step 5600, loss 31.160745, time: 3.392
training: epoch 158, step 5800, loss 31.191715, time: 3.399
training: epoch 158, step 6000, loss 31.217297, time: 3.394
training: epoch 158, step 6200, loss 31.257707, time: 3.389
training: epoch 158, step 6400, loss 31.228925, time: 3.384
training: epoch 158, step 6600, loss 31.234515, time: 3.388
training: epoch 158, step 6800, loss 31.277303, time: 3.389
training: epoch 158, step 7000, loss 31.262555, time: 3.387
training: epoch 158, step 7200, loss 31.276011, time: 3.388
training: epoch 158, step 7400, loss 31.283599, time: 3.387
training: epoch 158, step 7600, loss 31.282578, time: 3.392
training: epoch 158, step 7800, loss 31.263916, time: 3.390
training: epoch 158, step 7849, loss 31.251748, time: 0.831
validate: epoch 158, loss 35.251029, charcter error 6.339 time: 4.027
training: epoch 159, step 200, loss 31.189219, time: 3.350
training: epoch 159, step 400, loss 31.086754, time: 3.392
training: epoch 159, step 600, loss 31.150306, time: 3.391
training: epoch 159, step 800, loss 31.149239, time: 3.393
training: epoch 159, step 1000, loss 31.143996, time: 3.392
training: epoch 159, step 1200, loss 31.092628, time: 3.390
training: epoch 159, step 1400, loss 31.164276, time: 3.391
training: epoch 159, step 1600, loss 31.026153, time: 3.390
training: epoch 159, step 1800, loss 31.049193, time: 3.387
training: epoch 159, step 2000, loss 30.944339, time: 3.392
training: epoch 159, step 2200, loss 31.008999, time: 3.393
training: epoch 159, step 2400, loss 30.989492, time: 3.391
training: epoch 159, step 2600, loss 31.000328, time: 3.387
training: epoch 159, step 2800, loss 31.014934, time: 3.386
training: epoch 159, step 3000, loss 30.960613, time: 3.386
training: epoch 159, step 3200, loss 30.953706, time: 3.388
training: epoch 159, step 3400, loss 31.006265, time: 3.387
training: epoch 159, step 3600, loss 30.981816, time: 3.389
training: epoch 159, step 3800, loss 30.984361, time: 3.389
training: epoch 159, step 4000, loss 31.016756, time: 3.391
training: epoch 159, step 4200, loss 31.045257, time: 3.393
training: epoch 159, step 4400, loss 31.095534, time: 3.394
training: epoch 159, step 4600, loss 31.114628, time: 3.391
training: epoch 159, step 4800, loss 31.099054, time: 3.386
training: epoch 159, step 5000, loss 31.085942, time: 3.385
training: epoch 159, step 5200, loss 31.098468, time: 3.387
training: epoch 159, step 5400, loss 31.099052, time: 3.389
training: epoch 159, step 5600, loss 31.104059, time: 3.397
training: epoch 159, step 5800, loss 31.094821, time: 3.391
training: epoch 159, step 6000, loss 31.079644, time: 3.387
training: epoch 159, step 6200, loss 31.074881, time: 3.393
training: epoch 159, step 6400, loss 31.076396, time: 3.391
training: epoch 159, step 6600, loss 31.070234, time: 3.389
training: epoch 159, step 6800, loss 31.067937, time: 3.388
training: epoch 159, step 7000, loss 31.068558, time: 3.387
training: epoch 159, step 7200, loss 31.061465, time: 3.391
training: epoch 159, step 7400, loss 31.058174, time: 3.389
training: epoch 159, step 7600, loss 31.061084, time: 3.393
training: epoch 159, step 7800, loss 31.069060, time: 3.392
training: epoch 159, step 7849, loss 31.059511, time: 0.832
validate: epoch 159, loss 35.287306, charcter error 6.324 time: 4.021
training: epoch 160, step 200, loss 30.797027, time: 3.341
training: epoch 160, step 400, loss 31.117501, time: 3.382
training: epoch 160, step 600, loss 31.709075, time: 3.393
training: epoch 160, step 800, loss 31.734787, time: 3.392
training: epoch 160, step 1000, loss 31.506785, time: 3.391
training: epoch 160, step 1200, loss 31.332767, time: 3.389
training: epoch 160, step 1400, loss 31.285919, time: 3.389
training: epoch 160, step 1600, loss 31.294813, time: 3.386
training: epoch 160, step 1800, loss 31.160166, time: 3.388
training: epoch 160, step 2000, loss 31.204912, time: 3.387
training: epoch 160, step 2200, loss 31.147981, time: 3.385
training: epoch 160, step 2400, loss 31.117213, time: 3.391
training: epoch 160, step 2600, loss 31.157532, time: 3.395
training: epoch 160, step 2800, loss 31.189141, time: 3.391
training: epoch 160, step 3000, loss 31.152331, time: 3.392
training: epoch 160, step 3200, loss 31.093677, time: 3.387
training: epoch 160, step 3400, loss 31.045926, time: 3.392
training: epoch 160, step 3600, loss 31.073282, time: 3.388
training: epoch 160, step 3800, loss 31.104763, time: 3.383
training: epoch 160, step 4000, loss 31.094345, time: 3.381
training: epoch 160, step 4200, loss 31.083170, time: 3.384
training: epoch 160, step 4400, loss 31.123301, time: 3.392
training: epoch 160, step 4600, loss 31.120580, time: 3.394
training: epoch 160, step 4800, loss 31.145602, time: 3.393
training: epoch 160, step 5000, loss 31.175392, time: 3.396
training: epoch 160, step 5200, loss 31.162205, time: 3.503
training: epoch 160, step 5400, loss 31.152489, time: 3.535
training: epoch 160, step 5600, loss 31.146994, time: 3.563
training: epoch 160, step 5800, loss 31.129982, time: 3.564
training: epoch 160, step 6000, loss 31.133046, time: 3.554
training: epoch 160, step 6200, loss 31.120638, time: 3.537
training: epoch 160, step 6400, loss 31.148342, time: 3.513
training: epoch 160, step 6600, loss 31.167982, time: 3.552
training: epoch 160, step 6800, loss 31.181644, time: 3.526
training: epoch 160, step 7000, loss 31.183694, time: 3.538
training: epoch 160, step 7200, loss 31.181446, time: 3.527
training: epoch 160, step 7400, loss 31.177712, time: 3.556
training: epoch 160, step 7600, loss 31.173577, time: 3.606
training: epoch 160, step 7800, loss 31.148457, time: 3.536
training: epoch 160, step 7849, loss 31.134206, time: 0.868
validate: epoch 160, loss 35.195943, charcter error 6.304 time: 4.029
training: epoch 161, step 200, loss 30.739639, time: 3.501
training: epoch 161, step 400, loss 30.586264, time: 3.503
training: epoch 161, step 600, loss 30.770668, time: 3.489
training: epoch 161, step 800, loss 30.671965, time: 3.472
training: epoch 161, step 1000, loss 30.474627, time: 3.468
training: epoch 161, step 1200, loss 30.499547, time: 3.490
training: epoch 161, step 1400, loss 30.501244, time: 3.470
training: epoch 161, step 1600, loss 30.498795, time: 3.459
training: epoch 161, step 1800, loss 30.619494, time: 3.451
training: epoch 161, step 2000, loss 30.586107, time: 3.441
training: epoch 161, step 2200, loss 30.625154, time: 3.422
training: epoch 161, step 2400, loss 30.581452, time: 3.429
training: epoch 161, step 2600, loss 30.598869, time: 3.420
training: epoch 161, step 2800, loss 30.715245, time: 3.413
training: epoch 161, step 3000, loss 30.740118, time: 3.420
training: epoch 161, step 3200, loss 30.776028, time: 3.416
training: epoch 161, step 3400, loss 30.758592, time: 3.413
training: epoch 161, step 3600, loss 30.737230, time: 3.406
training: epoch 161, step 3800, loss 30.745141, time: 3.397
training: epoch 161, step 4000, loss 30.798141, time: 3.396
training: epoch 161, step 4200, loss 30.818627, time: 3.396
training: epoch 161, step 4400, loss 30.853882, time: 3.401
training: epoch 161, step 4600, loss 30.891640, time: 3.401
training: epoch 161, step 4800, loss 30.899730, time: 3.397
training: epoch 161, step 5000, loss 30.922616, time: 3.397
training: epoch 161, step 5200, loss 30.903550, time: 3.398
training: epoch 161, step 5400, loss 30.912932, time: 3.393
training: epoch 161, step 5600, loss 30.923844, time: 3.393
training: epoch 161, step 5800, loss 30.954714, time: 3.392
training: epoch 161, step 6000, loss 30.951035, time: 3.393
training: epoch 161, step 6200, loss 30.947244, time: 3.393
training: epoch 161, step 6400, loss 30.941632, time: 3.387
training: epoch 161, step 6600, loss 30.959440, time: 3.393
training: epoch 161, step 6800, loss 30.943057, time: 3.391
training: epoch 161, step 7000, loss 30.966667, time: 3.391
training: epoch 161, step 7200, loss 30.960224, time: 3.390
training: epoch 161, step 7400, loss 30.963105, time: 3.389
training: epoch 161, step 7600, loss 30.946222, time: 3.390
training: epoch 161, step 7800, loss 30.961773, time: 3.390
training: epoch 161, step 7849, loss 30.963217, time: 0.829
validate: epoch 161, loss 35.258006, charcter error 6.329 time: 4.021
training: epoch 162, step 200, loss 30.219633, time: 3.345
training: epoch 162, step 400, loss 29.736061, time: 3.406
training: epoch 162, step 600, loss 29.664786, time: 3.562
training: epoch 162, step 800, loss 30.015365, time: 3.518
training: epoch 162, step 1000, loss 30.193596, time: 3.502
training: epoch 162, step 1200, loss 30.459364, time: 3.514
training: epoch 162, step 1400, loss 30.519044, time: 3.503
training: epoch 162, step 1600, loss 30.547257, time: 3.524
training: epoch 162, step 1800, loss 30.435906, time: 3.473
training: epoch 162, step 2000, loss 30.501868, time: 3.472
training: epoch 162, step 2200, loss 30.501036, time: 3.474
training: epoch 162, step 2400, loss 30.624086, time: 3.486
training: epoch 162, step 2600, loss 30.666692, time: 3.531
training: epoch 162, step 2800, loss 30.681295, time: 3.516
training: epoch 162, step 3000, loss 30.772792, time: 3.538
training: epoch 162, step 3200, loss 30.851444, time: 3.495
training: epoch 162, step 3400, loss 30.877320, time: 3.505
training: epoch 162, step 3600, loss 30.856898, time: 3.503
training: epoch 162, step 3800, loss 30.901135, time: 3.420
training: epoch 162, step 4000, loss 30.915353, time: 3.393
training: epoch 162, step 4200, loss 30.935026, time: 3.401
training: epoch 162, step 4400, loss 30.925166, time: 3.408
training: epoch 162, step 4600, loss 30.934473, time: 3.410
training: epoch 162, step 4800, loss 30.927918, time: 3.453
training: epoch 162, step 5000, loss 30.948841, time: 3.514
training: epoch 162, step 5200, loss 30.976831, time: 3.524
training: epoch 162, step 5400, loss 30.979300, time: 3.485
training: epoch 162, step 5600, loss 31.006522, time: 3.475
training: epoch 162, step 5800, loss 30.970180, time: 3.482
training: epoch 162, step 6000, loss 30.982673, time: 3.472
training: epoch 162, step 6200, loss 30.967244, time: 3.494
training: epoch 162, step 6400, loss 30.991633, time: 3.488
training: epoch 162, step 6600, loss 30.980539, time: 3.476
training: epoch 162, step 6800, loss 30.960329, time: 3.504
training: epoch 162, step 7000, loss 30.938444, time: 3.523
training: epoch 162, step 7200, loss 30.933909, time: 3.502
training: epoch 162, step 7400, loss 30.926555, time: 3.478
training: epoch 162, step 7600, loss 30.925048, time: 3.499
training: epoch 162, step 7800, loss 30.914419, time: 3.534
training: epoch 162, step 7849, loss 30.921625, time: 0.854
validate: epoch 162, loss 35.000545, charcter error 6.282 time: 4.034
    - [Info] The checkpoint file has been updated.
training: epoch 163, step 200, loss 30.133130, time: 3.433
training: epoch 163, step 400, loss 30.558585, time: 3.464
training: epoch 163, step 600, loss 30.398783, time: 3.555
training: epoch 163, step 800, loss 30.530897, time: 3.632
training: epoch 163, step 1000, loss 30.382977, time: 3.561
training: epoch 163, step 1200, loss 30.593462, time: 3.524
training: epoch 163, step 1400, loss 30.570601, time: 3.533
training: epoch 163, step 1600, loss 30.599357, time: 3.515
training: epoch 163, step 1800, loss 30.578870, time: 3.474
training: epoch 163, step 2000, loss 30.606930, time: 3.456
training: epoch 163, step 2200, loss 30.666598, time: 3.490
training: epoch 163, step 2400, loss 30.731073, time: 3.519
training: epoch 163, step 2600, loss 30.782421, time: 3.488
training: epoch 163, step 2800, loss 30.857871, time: 3.516
training: epoch 163, step 3000, loss 30.988472, time: 3.482
training: epoch 163, step 3200, loss 31.042408, time: 3.474
training: epoch 163, step 3400, loss 31.064328, time: 3.472
training: epoch 163, step 3600, loss 31.076886, time: 3.467
training: epoch 163, step 3800, loss 31.054836, time: 3.453
training: epoch 163, step 4000, loss 31.067389, time: 3.441
training: epoch 163, step 4200, loss 31.054444, time: 3.449
training: epoch 163, step 4400, loss 31.031537, time: 3.450
training: epoch 163, step 4600, loss 31.057267, time: 3.434
training: epoch 163, step 4800, loss 31.022792, time: 3.423
training: epoch 163, step 5000, loss 31.019927, time: 3.418
training: epoch 163, step 5200, loss 30.967787, time: 3.420
training: epoch 163, step 5400, loss 30.975626, time: 3.412
training: epoch 163, step 5600, loss 30.997204, time: 3.420
training: epoch 163, step 5800, loss 31.004091, time: 3.408
training: epoch 163, step 6000, loss 31.015060, time: 3.408
training: epoch 163, step 6200, loss 31.023200, time: 3.411
training: epoch 163, step 6400, loss 31.029584, time: 3.407
training: epoch 163, step 6600, loss 31.007521, time: 3.409
training: epoch 163, step 6800, loss 31.048484, time: 3.410
training: epoch 163, step 7000, loss 31.028980, time: 3.402
training: epoch 163, step 7200, loss 31.014900, time: 3.402
training: epoch 163, step 7400, loss 31.011759, time: 3.403
training: epoch 163, step 7600, loss 31.003833, time: 3.401
training: epoch 163, step 7800, loss 30.989725, time: 3.403
training: epoch 163, step 7849, loss 30.969690, time: 0.832
validate: epoch 163, loss 35.136603, charcter error 6.287 time: 4.039
training: epoch 164, step 200, loss 30.377289, time: 3.350
training: epoch 164, step 400, loss 30.610328, time: 3.389
training: epoch 164, step 600, loss 30.702308, time: 3.395
training: epoch 164, step 800, loss 30.423831, time: 3.397
training: epoch 164, step 1000, loss 30.383771, time: 3.400
training: epoch 164, step 1200, loss 30.433533, time: 3.397
training: epoch 164, step 1400, loss 30.470361, time: 3.398
training: epoch 164, step 1600, loss 30.523735, time: 3.398
training: epoch 164, step 1800, loss 30.686228, time: 3.399
training: epoch 164, step 2000, loss 30.676412, time: 3.404
training: epoch 164, step 2200, loss 30.701291, time: 3.397
training: epoch 164, step 2400, loss 30.696530, time: 3.395
training: epoch 164, step 2600, loss 30.718670, time: 3.394
training: epoch 164, step 2800, loss 30.746237, time: 3.400
training: epoch 164, step 3000, loss 30.747074, time: 3.396
training: epoch 164, step 3200, loss 30.735099, time: 3.395
training: epoch 164, step 3400, loss 30.734943, time: 3.397
training: epoch 164, step 3600, loss 30.791068, time: 3.398
training: epoch 164, step 3800, loss 30.855519, time: 3.397
training: epoch 164, step 4000, loss 30.861962, time: 3.403
training: epoch 164, step 4200, loss 30.858193, time: 3.397
training: epoch 164, step 4400, loss 30.840863, time: 3.401
training: epoch 164, step 4600, loss 30.846487, time: 3.400
training: epoch 164, step 4800, loss 30.821636, time: 3.398
training: epoch 164, step 5000, loss 30.854648, time: 3.398
training: epoch 164, step 5200, loss 30.878102, time: 3.396
training: epoch 164, step 5400, loss 30.875190, time: 3.396
training: epoch 164, step 5600, loss 30.926098, time: 3.396
training: epoch 164, step 5800, loss 30.927919, time: 3.398
training: epoch 164, step 6000, loss 30.928376, time: 3.396
training: epoch 164, step 6200, loss 30.934861, time: 3.403
training: epoch 164, step 6400, loss 30.940592, time: 3.395
training: epoch 164, step 6600, loss 30.926811, time: 3.398
training: epoch 164, step 6800, loss 30.924487, time: 3.403
training: epoch 164, step 7000, loss 30.931904, time: 3.399
training: epoch 164, step 7200, loss 30.926693, time: 3.399
training: epoch 164, step 7400, loss 30.935251, time: 3.401
training: epoch 164, step 7600, loss 30.917347, time: 3.399
training: epoch 164, step 7800, loss 30.911440, time: 3.400
training: epoch 164, step 7849, loss 30.913364, time: 0.832
validate: epoch 164, loss 35.192181, charcter error 6.287 time: 4.029
training: epoch 165, step 200, loss 30.801717, time: 3.356
training: epoch 165, step 400, loss 30.326417, time: 3.394
training: epoch 165, step 600, loss 30.302630, time: 3.403
training: epoch 165, step 800, loss 30.471886, time: 3.409
training: epoch 165, step 1000, loss 30.440964, time: 3.407
training: epoch 165, step 1200, loss 30.512426, time: 3.406
training: epoch 165, step 1400, loss 30.554586, time: 3.406
training: epoch 165, step 1600, loss 30.552168, time: 3.407
training: epoch 165, step 1800, loss 30.487905, time: 3.405
training: epoch 165, step 2000, loss 30.532399, time: 3.405
training: epoch 165, step 2200, loss 30.516474, time: 3.404
training: epoch 165, step 2400, loss 30.528867, time: 3.401
training: epoch 165, step 2600, loss 30.609152, time: 3.406
training: epoch 165, step 2800, loss 30.573020, time: 3.408
training: epoch 165, step 3000, loss 30.501743, time: 3.408
training: epoch 165, step 3200, loss 30.548134, time: 3.404
training: epoch 165, step 3400, loss 30.592120, time: 3.404
training: epoch 165, step 3600, loss 30.677131, time: 3.404
training: epoch 165, step 3800, loss 30.703821, time: 3.408
training: epoch 165, step 4000, loss 30.697310, time: 3.408
training: epoch 165, step 4200, loss 30.726370, time: 3.410
training: epoch 165, step 4400, loss 30.755025, time: 3.408
training: epoch 165, step 4600, loss 30.762503, time: 3.409
training: epoch 165, step 4800, loss 30.784765, time: 3.406
training: epoch 165, step 5000, loss 30.731119, time: 3.406
training: epoch 165, step 5200, loss 30.708232, time: 3.410
training: epoch 165, step 5400, loss 30.763576, time: 3.409
training: epoch 165, step 5600, loss 30.762026, time: 3.411
training: epoch 165, step 5800, loss 30.781578, time: 3.410
training: epoch 165, step 6000, loss 30.796035, time: 3.408
training: epoch 165, step 6200, loss 30.832592, time: 3.409
training: epoch 165, step 6400, loss 30.822811, time: 3.407
training: epoch 165, step 6600, loss 30.842375, time: 3.404
training: epoch 165, step 6800, loss 30.843234, time: 3.411
training: epoch 165, step 7000, loss 30.844138, time: 3.413
training: epoch 165, step 7200, loss 30.843913, time: 3.410
training: epoch 165, step 7400, loss 30.882884, time: 3.413
training: epoch 165, step 7600, loss 30.868369, time: 3.410
training: epoch 165, step 7800, loss 30.853679, time: 3.410
training: epoch 165, step 7849, loss 30.858984, time: 0.836
validate: epoch 165, loss 35.238086, charcter error 6.317 time: 4.018
training: epoch 166, step 200, loss 32.333643, time: 3.356
training: epoch 166, step 400, loss 31.479830, time: 3.402
training: epoch 166, step 600, loss 31.341492, time: 3.413
training: epoch 166, step 800, loss 31.031901, time: 3.413
training: epoch 166, step 1000, loss 31.010298, time: 3.413
training: epoch 166, step 1200, loss 31.082710, time: 3.410
training: epoch 166, step 1400, loss 31.005475, time: 3.413
training: epoch 166, step 1600, loss 30.903687, time: 3.410
training: epoch 166, step 1800, loss 30.865034, time: 3.413
training: epoch 166, step 2000, loss 30.769512, time: 3.413
training: epoch 166, step 2200, loss 30.731955, time: 3.410
training: epoch 166, step 2400, loss 30.777252, time: 3.410
training: epoch 166, step 2600, loss 30.853081, time: 3.411
training: epoch 166, step 2800, loss 30.801833, time: 3.411
training: epoch 166, step 3000, loss 30.794357, time: 3.410
training: epoch 166, step 3200, loss 30.867838, time: 3.413
training: epoch 166, step 3400, loss 30.807652, time: 3.412
training: epoch 166, step 3600, loss 30.874650, time: 3.412
training: epoch 166, step 3800, loss 30.874270, time: 3.411
training: epoch 166, step 4000, loss 30.922946, time: 3.410
training: epoch 166, step 4200, loss 30.958052, time: 3.412
training: epoch 166, step 4400, loss 30.939023, time: 3.408
training: epoch 166, step 4600, loss 30.908241, time: 3.411
training: epoch 166, step 4800, loss 30.911559, time: 3.410
training: epoch 166, step 5000, loss 30.914911, time: 3.413
training: epoch 166, step 5200, loss 30.902515, time: 3.410
training: epoch 166, step 5400, loss 30.891947, time: 3.413
training: epoch 166, step 5600, loss 30.874613, time: 3.413
training: epoch 166, step 5800, loss 30.877230, time: 3.412
training: epoch 166, step 6000, loss 30.844301, time: 3.409
training: epoch 166, step 6200, loss 30.856989, time: 3.411
training: epoch 166, step 6400, loss 30.885539, time: 3.410
training: epoch 166, step 6600, loss 30.913676, time: 3.409
training: epoch 166, step 6800, loss 30.914294, time: 3.406
training: epoch 166, step 7000, loss 30.947923, time: 3.413
training: epoch 166, step 7200, loss 30.938851, time: 3.412
training: epoch 166, step 7400, loss 30.931881, time: 3.408
training: epoch 166, step 7600, loss 30.944404, time: 3.406
training: epoch 166, step 7800, loss 30.961501, time: 3.410
training: epoch 166, step 7849, loss 30.962246, time: 0.837
validate: epoch 166, loss 35.311720, charcter error 6.326 time: 4.021
training: epoch 167, step 200, loss 30.978078, time: 3.355
training: epoch 167, step 400, loss 31.023178, time: 3.399
training: epoch 167, step 600, loss 31.170517, time: 3.407
training: epoch 167, step 800, loss 31.042357, time: 3.406
training: epoch 167, step 1000, loss 30.874399, time: 3.408
training: epoch 167, step 1200, loss 30.827784, time: 3.406
training: epoch 167, step 1400, loss 30.750703, time: 3.406
training: epoch 167, step 1600, loss 30.819983, time: 3.406
training: epoch 167, step 1800, loss 30.770919, time: 3.405
training: epoch 167, step 2000, loss 30.810602, time: 3.408
training: epoch 167, step 2200, loss 30.729271, time: 3.404
training: epoch 167, step 2400, loss 30.730884, time: 3.407
training: epoch 167, step 2600, loss 30.819353, time: 3.407
training: epoch 167, step 2800, loss 30.867545, time: 3.406
training: epoch 167, step 3000, loss 30.904818, time: 3.408
training: epoch 167, step 3200, loss 30.804258, time: 3.405
training: epoch 167, step 3400, loss 30.788979, time: 3.409
training: epoch 167, step 3600, loss 30.749331, time: 3.413
training: epoch 167, step 3800, loss 30.713735, time: 3.406
training: epoch 167, step 4000, loss 30.704234, time: 3.406
training: epoch 167, step 4200, loss 30.694178, time: 3.406
training: epoch 167, step 4400, loss 30.690835, time: 3.411
training: epoch 167, step 4600, loss 30.722110, time: 3.410
training: epoch 167, step 4800, loss 30.736613, time: 3.411
training: epoch 167, step 5000, loss 30.749775, time: 3.406
training: epoch 167, step 5200, loss 30.750777, time: 3.411
training: epoch 167, step 5400, loss 30.766882, time: 3.409
training: epoch 167, step 5600, loss 30.759844, time: 3.410
training: epoch 167, step 5800, loss 30.802488, time: 3.410
training: epoch 167, step 6000, loss 30.772813, time: 3.407
training: epoch 167, step 6200, loss 30.783417, time: 3.411
training: epoch 167, step 6400, loss 30.769838, time: 3.412
training: epoch 167, step 6600, loss 30.775833, time: 3.410
training: epoch 167, step 6800, loss 30.797643, time: 3.413
training: epoch 167, step 7000, loss 30.804499, time: 3.412
training: epoch 167, step 7200, loss 30.794561, time: 3.407
training: epoch 167, step 7400, loss 30.782689, time: 3.404
training: epoch 167, step 7600, loss 30.798883, time: 3.412
training: epoch 167, step 7800, loss 30.816777, time: 3.411
training: epoch 167, step 7849, loss 30.821064, time: 0.836
validate: epoch 167, loss 35.415536, charcter error 6.345 time: 4.024
training: epoch 168, step 200, loss 30.026239, time: 3.355
training: epoch 168, step 400, loss 30.386730, time: 3.399
training: epoch 168, step 600, loss 30.212065, time: 3.404
training: epoch 168, step 800, loss 30.454056, time: 3.410
training: epoch 168, step 1000, loss 30.517792, time: 3.408
training: epoch 168, step 1200, loss 30.708450, time: 3.408
training: epoch 168, step 1400, loss 30.686551, time: 3.406
training: epoch 168, step 1600, loss 30.850312, time: 3.406
training: epoch 168, step 1800, loss 30.882340, time: 3.410
training: epoch 168, step 2000, loss 30.816489, time: 3.407
training: epoch 168, step 2200, loss 30.792584, time: 3.411
training: epoch 168, step 2400, loss 30.879323, time: 3.410
training: epoch 168, step 2600, loss 30.946816, time: 3.407
training: epoch 168, step 2800, loss 30.945978, time: 3.407
training: epoch 168, step 3000, loss 30.967091, time: 3.409
training: epoch 168, step 3200, loss 30.945519, time: 3.408
training: epoch 168, step 3400, loss 30.934842, time: 3.410
training: epoch 168, step 3600, loss 30.928779, time: 3.407
training: epoch 168, step 3800, loss 30.940239, time: 3.403
training: epoch 168, step 4000, loss 30.946867, time: 3.407
training: epoch 168, step 4200, loss 30.923761, time: 3.413
training: epoch 168, step 4400, loss 30.912622, time: 3.402
training: epoch 168, step 4600, loss 30.912252, time: 3.410
training: epoch 168, step 4800, loss 30.888554, time: 3.411
training: epoch 168, step 5000, loss 30.885078, time: 3.407
training: epoch 168, step 5200, loss 30.909317, time: 3.408
training: epoch 168, step 5400, loss 30.915220, time: 3.409
training: epoch 168, step 5600, loss 30.913039, time: 3.409
training: epoch 168, step 5800, loss 30.918302, time: 3.409
training: epoch 168, step 6000, loss 30.917503, time: 3.408
training: epoch 168, step 6200, loss 30.919438, time: 3.405
training: epoch 168, step 6400, loss 30.936569, time: 3.404
training: epoch 168, step 6600, loss 30.994666, time: 3.408
training: epoch 168, step 6800, loss 30.984485, time: 3.409
training: epoch 168, step 7000, loss 30.952733, time: 3.407
training: epoch 168, step 7200, loss 30.940185, time: 3.404
training: epoch 168, step 7400, loss 30.937167, time: 3.405
training: epoch 168, step 7600, loss 30.954155, time: 3.409
training: epoch 168, step 7800, loss 30.953544, time: 3.407
training: epoch 168, step 7849, loss 30.955895, time: 0.834
validate: epoch 168, loss 35.202954, charcter error 6.304 time: 4.016
training: epoch 169, step 200, loss 30.253226, time: 3.354
training: epoch 169, step 400, loss 30.420090, time: 3.402
training: epoch 169, step 600, loss 30.296218, time: 3.408
training: epoch 169, step 800, loss 30.419119, time: 3.409
training: epoch 169, step 1000, loss 30.505092, time: 3.408
training: epoch 169, step 1200, loss 30.267861, time: 3.408
training: epoch 169, step 1400, loss 30.493775, time: 3.408
training: epoch 169, step 1600, loss 30.614980, time: 3.408
training: epoch 169, step 1800, loss 30.541249, time: 3.403
training: epoch 169, step 2000, loss 30.450266, time: 3.409
training: epoch 169, step 2200, loss 30.588398, time: 3.404
training: epoch 169, step 2400, loss 30.716262, time: 3.403
training: epoch 169, step 2600, loss 30.731059, time: 3.405
training: epoch 169, step 2800, loss 30.732665, time: 3.406
training: epoch 169, step 3000, loss 30.796543, time: 3.405
training: epoch 169, step 3200, loss 30.778249, time: 3.407
training: epoch 169, step 3400, loss 30.748103, time: 3.408
training: epoch 169, step 3600, loss 30.717167, time: 3.403
training: epoch 169, step 3800, loss 30.718212, time: 3.405
training: epoch 169, step 4000, loss 30.743871, time: 3.399
training: epoch 169, step 4200, loss 30.739848, time: 3.401
training: epoch 169, step 4400, loss 30.764302, time: 3.403
training: epoch 169, step 4600, loss 30.746054, time: 3.408
training: epoch 169, step 4800, loss 30.797513, time: 3.407
training: epoch 169, step 5000, loss 30.817977, time: 3.406
training: epoch 169, step 5200, loss 30.837504, time: 3.405
training: epoch 169, step 5400, loss 30.852587, time: 3.405
training: epoch 169, step 5600, loss 30.859893, time: 3.401
training: epoch 169, step 5800, loss 30.875809, time: 3.400
training: epoch 169, step 6000, loss 30.868944, time: 3.397
training: epoch 169, step 6200, loss 30.906850, time: 3.397
training: epoch 169, step 6400, loss 30.926911, time: 3.401
training: epoch 169, step 6600, loss 30.948351, time: 3.401
training: epoch 169, step 6800, loss 30.925267, time: 3.400
training: epoch 169, step 7000, loss 30.927552, time: 3.397
training: epoch 169, step 7200, loss 30.936162, time: 3.397
training: epoch 169, step 7400, loss 30.928006, time: 3.398
training: epoch 169, step 7600, loss 30.928150, time: 3.399
training: epoch 169, step 7800, loss 30.921229, time: 3.393
training: epoch 169, step 7849, loss 30.925059, time: 0.833
validate: epoch 169, loss 35.378936, charcter error 6.340 time: 4.016
training: epoch 170, step 200, loss 30.389141, time: 3.344
training: epoch 170, step 400, loss 30.809012, time: 3.385
training: epoch 170, step 600, loss 30.691408, time: 3.393
training: epoch 170, step 800, loss 31.023616, time: 3.393
training: epoch 170, step 1000, loss 31.081213, time: 3.394
training: epoch 170, step 1200, loss 31.175433, time: 3.394
training: epoch 170, step 1400, loss 31.150520, time: 3.396
training: epoch 170, step 1600, loss 31.092024, time: 3.392
training: epoch 170, step 1800, loss 31.138449, time: 3.396
training: epoch 170, step 2000, loss 31.073118, time: 3.392
training: epoch 170, step 2200, loss 30.958410, time: 3.391
training: epoch 170, step 2400, loss 30.869579, time: 3.392
training: epoch 170, step 2600, loss 30.945758, time: 3.393
training: epoch 170, step 2800, loss 30.959199, time: 3.396
training: epoch 170, step 3000, loss 30.968578, time: 3.392
training: epoch 170, step 3200, loss 30.960973, time: 3.397
training: epoch 170, step 3400, loss 30.910223, time: 3.389
training: epoch 170, step 3600, loss 30.879248, time: 3.387
training: epoch 170, step 3800, loss 30.906970, time: 3.389
training: epoch 170, step 4000, loss 30.914404, time: 3.386
training: epoch 170, step 4200, loss 30.916750, time: 3.387
training: epoch 170, step 4400, loss 30.885235, time: 3.390
training: epoch 170, step 4600, loss 30.878569, time: 3.392
training: epoch 170, step 4800, loss 30.876038, time: 3.392
training: epoch 170, step 5000, loss 30.906750, time: 3.392
training: epoch 170, step 5200, loss 30.898673, time: 3.391
training: epoch 170, step 5400, loss 30.909853, time: 3.391
training: epoch 170, step 5600, loss 30.907699, time: 3.390
training: epoch 170, step 5800, loss 30.915731, time: 3.390
training: epoch 170, step 6000, loss 30.933156, time: 3.388
training: epoch 170, step 6200, loss 30.932125, time: 3.387
training: epoch 170, step 6400, loss 30.961947, time: 3.392
training: epoch 170, step 6600, loss 30.942923, time: 3.391
training: epoch 170, step 6800, loss 30.958398, time: 3.391
training: epoch 170, step 7000, loss 30.971620, time: 3.388
training: epoch 170, step 7200, loss 30.974288, time: 3.392
training: epoch 170, step 7400, loss 30.963690, time: 3.391
training: epoch 170, step 7600, loss 30.982212, time: 3.391
training: epoch 170, step 7800, loss 30.982019, time: 3.393
training: epoch 170, step 7849, loss 30.983278, time: 0.832
validate: epoch 170, loss 35.415413, charcter error 6.331 time: 4.021
training: epoch 171, step 200, loss 30.390877, time: 3.349
training: epoch 171, step 400, loss 30.448935, time: 3.467
training: epoch 171, step 600, loss 30.648773, time: 3.504
training: epoch 171, step 800, loss 30.618825, time: 3.546
training: epoch 171, step 1000, loss 30.563667, time: 3.536
training: epoch 171, step 1200, loss 30.498807, time: 3.509
training: epoch 171, step 1400, loss 30.616566, time: 3.496
training: epoch 171, step 1600, loss 30.563593, time: 3.531
training: epoch 171, step 1800, loss 30.715320, time: 3.515
training: epoch 171, step 2000, loss 30.700004, time: 3.504
training: epoch 171, step 2200, loss 30.707414, time: 3.504
training: epoch 171, step 2400, loss 30.667917, time: 3.497
training: epoch 171, step 2600, loss 30.747688, time: 3.578
training: epoch 171, step 2800, loss 30.777749, time: 3.561
training: epoch 171, step 3000, loss 30.769535, time: 3.476
training: epoch 171, step 3200, loss 30.797291, time: 3.435
training: epoch 171, step 3400, loss 30.807719, time: 3.428
training: epoch 171, step 3600, loss 30.833655, time: 3.416
training: epoch 171, step 3800, loss 30.801089, time: 3.409
training: epoch 171, step 4000, loss 30.794682, time: 3.411
training: epoch 171, step 4200, loss 30.800985, time: 3.409
training: epoch 171, step 4400, loss 30.809406, time: 3.406
training: epoch 171, step 4600, loss 30.837390, time: 3.401
training: epoch 171, step 4800, loss 30.837171, time: 3.401
training: epoch 171, step 5000, loss 30.834003, time: 3.397
training: epoch 171, step 5200, loss 30.857632, time: 3.393
training: epoch 171, step 5400, loss 30.859589, time: 3.393
training: epoch 171, step 5600, loss 30.860612, time: 3.393
training: epoch 171, step 5800, loss 30.845607, time: 3.394
training: epoch 171, step 6000, loss 30.843859, time: 3.393
training: epoch 171, step 6200, loss 30.850836, time: 3.394
training: epoch 171, step 6400, loss 30.827361, time: 3.390
training: epoch 171, step 6600, loss 30.825025, time: 3.392
training: epoch 171, step 6800, loss 30.825022, time: 3.390
training: epoch 171, step 7000, loss 30.846969, time: 3.390
training: epoch 171, step 7200, loss 30.860254, time: 3.391
training: epoch 171, step 7400, loss 30.827877, time: 3.392
training: epoch 171, step 7600, loss 30.830601, time: 3.392
training: epoch 171, step 7800, loss 30.855555, time: 3.393
training: epoch 171, step 7849, loss 30.852800, time: 0.832
validate: epoch 171, loss 35.206271, charcter error 6.311 time: 4.034
training: epoch 172, step 200, loss 30.471729, time: 3.336
training: epoch 172, step 400, loss 30.702040, time: 3.377
training: epoch 172, step 600, loss 31.087233, time: 3.385
training: epoch 172, step 800, loss 31.045816, time: 3.387
training: epoch 172, step 1000, loss 31.128613, time: 3.388
training: epoch 172, step 1200, loss 31.127655, time: 3.388
training: epoch 172, step 1400, loss 31.049924, time: 3.388
training: epoch 172, step 1600, loss 31.066226, time: 3.387
training: epoch 172, step 1800, loss 31.092482, time: 3.391
training: epoch 172, step 2000, loss 31.112442, time: 3.389
training: epoch 172, step 2200, loss 31.025917, time: 3.390
training: epoch 172, step 2400, loss 31.026992, time: 3.392
training: epoch 172, step 2600, loss 30.952197, time: 3.389
training: epoch 172, step 2800, loss 30.905800, time: 3.384
training: epoch 172, step 3000, loss 30.922787, time: 3.384
training: epoch 172, step 3200, loss 30.952947, time: 3.387
training: epoch 172, step 3400, loss 30.941544, time: 3.395
training: epoch 172, step 3600, loss 30.960544, time: 3.411
training: epoch 172, step 3800, loss 30.950044, time: 3.501
training: epoch 172, step 4000, loss 30.877773, time: 3.458
training: epoch 172, step 4200, loss 30.853752, time: 3.477
training: epoch 172, step 4400, loss 30.897335, time: 3.487
training: epoch 172, step 4600, loss 30.887343, time: 3.509
training: epoch 172, step 4800, loss 30.890630, time: 3.513
training: epoch 172, step 5000, loss 30.864607, time: 3.450
training: epoch 172, step 5200, loss 30.837707, time: 3.450
training: epoch 172, step 5400, loss 30.834851, time: 3.470
training: epoch 172, step 5600, loss 30.802578, time: 3.477
training: epoch 172, step 5800, loss 30.774988, time: 3.503
training: epoch 172, step 6000, loss 30.813631, time: 3.512
training: epoch 172, step 6200, loss 30.829759, time: 3.477
training: epoch 172, step 6400, loss 30.828848, time: 3.505
training: epoch 172, step 6600, loss 30.823366, time: 3.483
training: epoch 172, step 6800, loss 30.833748, time: 3.426
training: epoch 172, step 7000, loss 30.836446, time: 3.393
training: epoch 172, step 7200, loss 30.839523, time: 3.411
training: epoch 172, step 7400, loss 30.876547, time: 3.430
training: epoch 172, step 7600, loss 30.870800, time: 3.461
training: epoch 172, step 7800, loss 30.876990, time: 3.460
training: epoch 172, step 7849, loss 30.884476, time: 0.851
validate: epoch 172, loss 35.212744, charcter error 6.297 time: 4.027
training: epoch 173, step 200, loss 30.442972, time: 3.450
training: epoch 173, step 400, loss 30.349812, time: 3.457
training: epoch 173, step 600, loss 30.502522, time: 3.455
training: epoch 173, step 800, loss 30.454759, time: 3.439
training: epoch 173, step 1000, loss 30.547331, time: 3.446
training: epoch 173, step 1200, loss 30.669226, time: 3.460
training: epoch 173, step 1400, loss 30.767268, time: 3.453
training: epoch 173, step 1600, loss 30.844499, time: 3.459
training: epoch 173, step 1800, loss 30.879163, time: 3.469
training: epoch 173, step 2000, loss 30.858127, time: 3.451
training: epoch 173, step 2200, loss 30.881259, time: 3.429
training: epoch 173, step 2400, loss 30.890358, time: 3.439
training: epoch 173, step 2600, loss 30.927523, time: 3.444
training: epoch 173, step 2800, loss 30.921573, time: 3.433
training: epoch 173, step 3000, loss 30.975108, time: 3.445
training: epoch 173, step 3200, loss 30.844140, time: 3.440
training: epoch 173, step 3400, loss 30.907075, time: 3.491
training: epoch 173, step 3600, loss 30.879217, time: 3.599
training: epoch 173, step 3800, loss 30.856738, time: 3.497
training: epoch 173, step 4000, loss 30.835224, time: 3.475
training: epoch 173, step 4200, loss 30.800439, time: 3.489
training: epoch 173, step 4400, loss 30.798645, time: 3.473
training: epoch 173, step 4600, loss 30.816145, time: 3.451
training: epoch 173, step 4800, loss 30.781020, time: 3.448
training: epoch 173, step 5000, loss 30.832741, time: 3.459
training: epoch 173, step 5200, loss 30.831137, time: 3.479
training: epoch 173, step 5400, loss 30.821322, time: 3.448
training: epoch 173, step 5600, loss 30.776062, time: 3.432
training: epoch 173, step 5800, loss 30.791502, time: 3.423
training: epoch 173, step 6000, loss 30.778291, time: 3.408
training: epoch 173, step 6200, loss 30.786577, time: 3.408
training: epoch 173, step 6400, loss 30.795870, time: 3.403
training: epoch 173, step 6600, loss 30.772633, time: 3.401
training: epoch 173, step 6800, loss 30.801885, time: 3.398
training: epoch 173, step 7000, loss 30.790933, time: 3.394
training: epoch 173, step 7200, loss 30.786465, time: 3.394
training: epoch 173, step 7400, loss 30.799595, time: 3.394
training: epoch 173, step 7600, loss 30.813799, time: 3.392
training: epoch 173, step 7800, loss 30.830986, time: 3.396
training: epoch 173, step 7849, loss 30.831863, time: 0.832
validate: epoch 173, loss 35.399794, charcter error 6.338 time: 4.041
training: epoch 174, step 200, loss 31.352979, time: 3.348
training: epoch 174, step 400, loss 31.121760, time: 3.386
training: epoch 174, step 600, loss 31.133078, time: 3.392
training: epoch 174, step 800, loss 30.783262, time: 3.392
training: epoch 174, step 1000, loss 30.811082, time: 3.394
training: epoch 174, step 1200, loss 30.770403, time: 3.392
training: epoch 174, step 1400, loss 30.608682, time: 3.391
training: epoch 174, step 1600, loss 30.485299, time: 3.391
training: epoch 174, step 1800, loss 30.706269, time: 3.394
training: epoch 174, step 2000, loss 30.592939, time: 3.392
training: epoch 174, step 2200, loss 30.604295, time: 3.393
training: epoch 174, step 2400, loss 30.602421, time: 3.399
training: epoch 174, step 2600, loss 30.637461, time: 3.395
training: epoch 174, step 2800, loss 30.658727, time: 3.394
training: epoch 174, step 3000, loss 30.618295, time: 3.399
training: epoch 174, step 3200, loss 30.577990, time: 3.394
training: epoch 174, step 3400, loss 30.619526, time: 3.398
training: epoch 174, step 3600, loss 30.658097, time: 3.401
training: epoch 174, step 3800, loss 30.690971, time: 3.400
training: epoch 174, step 4000, loss 30.698982, time: 3.396
training: epoch 174, step 4200, loss 30.727341, time: 3.399
training: epoch 174, step 4400, loss 30.772512, time: 3.401
training: epoch 174, step 4600, loss 30.782033, time: 3.402
training: epoch 174, step 4800, loss 30.799773, time: 3.405
training: epoch 174, step 5000, loss 30.775800, time: 3.397
training: epoch 174, step 5200, loss 30.744066, time: 3.397
training: epoch 174, step 5400, loss 30.804102, time: 3.405
training: epoch 174, step 5600, loss 30.805118, time: 3.398
training: epoch 174, step 5800, loss 30.809733, time: 3.403
training: epoch 174, step 6000, loss 30.781887, time: 3.404
training: epoch 174, step 6200, loss 30.787236, time: 3.409
training: epoch 174, step 6400, loss 30.799189, time: 3.409
training: epoch 174, step 6600, loss 30.799261, time: 3.403
training: epoch 174, step 6800, loss 30.787934, time: 3.403
training: epoch 174, step 7000, loss 30.768304, time: 3.404
training: epoch 174, step 7200, loss 30.761226, time: 3.403
training: epoch 174, step 7400, loss 30.768839, time: 3.413
training: epoch 174, step 7600, loss 30.756837, time: 3.408
training: epoch 174, step 7800, loss 30.757603, time: 3.407
training: epoch 174, step 7849, loss 30.748777, time: 0.836
validate: epoch 174, loss 35.091389, charcter error 6.293 time: 4.023
training: epoch 175, step 200, loss 29.583832, time: 3.351
training: epoch 175, step 400, loss 30.432682, time: 3.399
training: epoch 175, step 600, loss 30.600651, time: 3.404
training: epoch 175, step 800, loss 30.926152, time: 3.409
training: epoch 175, step 1000, loss 30.915337, time: 3.408
training: epoch 175, step 1200, loss 30.943919, time: 3.409
training: epoch 175, step 1400, loss 30.926654, time: 3.406
training: epoch 175, step 1600, loss 31.073727, time: 3.405
training: epoch 175, step 1800, loss 31.068463, time: 3.404
training: epoch 175, step 2000, loss 31.035640, time: 3.403
training: epoch 175, step 2200, loss 31.014089, time: 3.403
training: epoch 175, step 2400, loss 30.995580, time: 3.400
training: epoch 175, step 2600, loss 31.031584, time: 3.406
training: epoch 175, step 2800, loss 31.068856, time: 3.409
training: epoch 175, step 3000, loss 31.028262, time: 3.405
training: epoch 175, step 3200, loss 31.093891, time: 3.406
training: epoch 175, step 3400, loss 31.131566, time: 3.407
training: epoch 175, step 3600, loss 31.059610, time: 3.404
training: epoch 175, step 3800, loss 31.041413, time: 3.403
training: epoch 175, step 4000, loss 31.009376, time: 3.403
training: epoch 175, step 4200, loss 31.033002, time: 3.407
training: epoch 175, step 4400, loss 31.015924, time: 3.407
training: epoch 175, step 4600, loss 30.975137, time: 3.406
training: epoch 175, step 4800, loss 30.942408, time: 3.404
training: epoch 175, step 5000, loss 30.901416, time: 3.406
training: epoch 175, step 5200, loss 30.906898, time: 3.407
training: epoch 175, step 5400, loss 30.921814, time: 3.405
training: epoch 175, step 5600, loss 30.903378, time: 3.412
training: epoch 175, step 5800, loss 30.897851, time: 3.413
training: epoch 175, step 6000, loss 30.888148, time: 3.414
training: epoch 175, step 6200, loss 30.869706, time: 3.406
training: epoch 175, step 6400, loss 30.852417, time: 3.405
training: epoch 175, step 6600, loss 30.852057, time: 3.411
training: epoch 175, step 6800, loss 30.848569, time: 3.414
training: epoch 175, step 7000, loss 30.857650, time: 3.416
training: epoch 175, step 7200, loss 30.861773, time: 3.414
training: epoch 175, step 7400, loss 30.837742, time: 3.413
training: epoch 175, step 7600, loss 30.853544, time: 3.413
training: epoch 175, step 7800, loss 30.850589, time: 3.417
training: epoch 175, step 7849, loss 30.858747, time: 0.836
validate: epoch 175, loss 35.111829, charcter error 6.289 time: 4.027
training: epoch 176, step 200, loss 30.717524, time: 3.360
training: epoch 176, step 400, loss 30.609314, time: 3.404
training: epoch 176, step 600, loss 30.678900, time: 3.400
training: epoch 176, step 800, loss 30.522996, time: 3.403
training: epoch 176, step 1000, loss 30.729535, time: 3.410
training: epoch 176, step 1200, loss 30.725649, time: 3.410
training: epoch 176, step 1400, loss 30.698129, time: 3.406
training: epoch 176, step 1600, loss 30.750855, time: 3.403
training: epoch 176, step 1800, loss 30.733248, time: 3.400
training: epoch 176, step 2000, loss 30.743824, time: 3.402
training: epoch 176, step 2200, loss 30.670622, time: 3.403
training: epoch 176, step 2400, loss 30.662174, time: 3.411
training: epoch 176, step 2600, loss 30.680922, time: 3.405
training: epoch 176, step 2800, loss 30.695837, time: 3.408
training: epoch 176, step 3000, loss 30.709066, time: 3.413
training: epoch 176, step 3200, loss 30.692740, time: 3.413
training: epoch 176, step 3400, loss 30.703352, time: 3.413
training: epoch 176, step 3600, loss 30.697398, time: 3.413
training: epoch 176, step 3800, loss 30.740679, time: 3.413
training: epoch 176, step 4000, loss 30.686733, time: 3.413
training: epoch 176, step 4200, loss 30.696720, time: 3.413
training: epoch 176, step 4400, loss 30.720311, time: 3.413
training: epoch 176, step 4600, loss 30.727192, time: 3.412
training: epoch 176, step 4800, loss 30.729528, time: 3.411
training: epoch 176, step 5000, loss 30.746952, time: 3.406
training: epoch 176, step 5200, loss 30.756518, time: 3.407
training: epoch 176, step 5400, loss 30.744832, time: 3.408
training: epoch 176, step 5600, loss 30.728475, time: 3.413
training: epoch 176, step 5800, loss 30.711674, time: 3.414
training: epoch 176, step 6000, loss 30.695342, time: 3.413
training: epoch 176, step 6200, loss 30.684749, time: 3.414
training: epoch 176, step 6400, loss 30.690918, time: 3.410
training: epoch 176, step 6600, loss 30.675567, time: 3.405
training: epoch 176, step 6800, loss 30.664992, time: 3.409
training: epoch 176, step 7000, loss 30.684247, time: 3.413
training: epoch 176, step 7200, loss 30.680527, time: 3.413
training: epoch 176, step 7400, loss 30.693938, time: 3.413
training: epoch 176, step 7600, loss 30.698946, time: 3.413
training: epoch 176, step 7800, loss 30.683012, time: 3.413
training: epoch 176, step 7849, loss 30.687775, time: 0.837
validate: epoch 176, loss 35.119394, charcter error 6.307 time: 4.022
training: epoch 177, step 200, loss 30.487973, time: 3.359
training: epoch 177, step 400, loss 30.722420, time: 3.405
training: epoch 177, step 600, loss 31.087860, time: 3.413
training: epoch 177, step 800, loss 30.926715, time: 3.413
training: epoch 177, step 1000, loss 30.695177, time: 3.411
training: epoch 177, step 1200, loss 30.562513, time: 3.412
training: epoch 177, step 1400, loss 30.519362, time: 3.413
training: epoch 177, step 1600, loss 30.625340, time: 3.413
training: epoch 177, step 1800, loss 30.659900, time: 3.413
training: epoch 177, step 2000, loss 30.765536, time: 3.411
training: epoch 177, step 2200, loss 30.837398, time: 3.413
training: epoch 177, step 2400, loss 30.865433, time: 3.413
training: epoch 177, step 2600, loss 30.844315, time: 3.413
training: epoch 177, step 2800, loss 30.789725, time: 3.413
training: epoch 177, step 3000, loss 30.765602, time: 3.409
training: epoch 177, step 3200, loss 30.778147, time: 3.412
training: epoch 177, step 3400, loss 30.790090, time: 3.413
training: epoch 177, step 3600, loss 30.774061, time: 3.413
training: epoch 177, step 3800, loss 30.742349, time: 3.406
training: epoch 177, step 4000, loss 30.727755, time: 3.405
training: epoch 177, step 4200, loss 30.723237, time: 3.408
training: epoch 177, step 4400, loss 30.742953, time: 3.413
training: epoch 177, step 4600, loss 30.725708, time: 3.403
training: epoch 177, step 4800, loss 30.770940, time: 3.402
training: epoch 177, step 5000, loss 30.746224, time: 3.400
training: epoch 177, step 5200, loss 30.729126, time: 3.402
training: epoch 177, step 5400, loss 30.762373, time: 3.411
training: epoch 177, step 5600, loss 30.751087, time: 3.407
training: epoch 177, step 5800, loss 30.794562, time: 3.403
training: epoch 177, step 6000, loss 30.771644, time: 3.405
training: epoch 177, step 6200, loss 30.768659, time: 3.405
training: epoch 177, step 6400, loss 30.781916, time: 3.402
training: epoch 177, step 6600, loss 30.769904, time: 3.408
training: epoch 177, step 6800, loss 30.781971, time: 3.403
training: epoch 177, step 7000, loss 30.782789, time: 3.407
training: epoch 177, step 7200, loss 30.772041, time: 3.400
training: epoch 177, step 7400, loss 30.768545, time: 3.399
training: epoch 177, step 7600, loss 30.773338, time: 3.403
training: epoch 177, step 7800, loss 30.764364, time: 3.401
training: epoch 177, step 7849, loss 30.767319, time: 0.836
validate: epoch 177, loss 35.272760, charcter error 6.297 time: 4.026
training: epoch 178, step 200, loss 30.908584, time: 3.350
training: epoch 178, step 400, loss 30.669500, time: 3.394
training: epoch 178, step 600, loss 30.441493, time: 3.408
training: epoch 178, step 800, loss 30.498736, time: 3.399
training: epoch 178, step 1000, loss 30.457205, time: 3.396
training: epoch 178, step 1200, loss 30.267942, time: 3.397
training: epoch 178, step 1400, loss 30.384536, time: 3.396
training: epoch 178, step 1600, loss 30.342483, time: 3.395
training: epoch 178, step 1800, loss 30.410815, time: 3.400
training: epoch 178, step 2000, loss 30.512236, time: 3.401
training: epoch 178, step 2200, loss 30.522854, time: 3.398
training: epoch 178, step 2400, loss 30.562480, time: 3.406
training: epoch 178, step 2600, loss 30.610441, time: 3.399
training: epoch 178, step 2800, loss 30.635461, time: 3.403
training: epoch 178, step 3000, loss 30.684725, time: 3.404
training: epoch 178, step 3200, loss 30.658433, time: 3.399
training: epoch 178, step 3400, loss 30.648486, time: 3.399
training: epoch 178, step 3600, loss 30.662569, time: 3.395
training: epoch 178, step 3800, loss 30.651124, time: 3.398
training: epoch 178, step 4000, loss 30.626431, time: 3.401
training: epoch 178, step 4200, loss 30.642013, time: 3.396
training: epoch 178, step 4400, loss 30.659417, time: 3.398
training: epoch 178, step 4600, loss 30.665639, time: 3.403
training: epoch 178, step 4800, loss 30.706943, time: 3.406
training: epoch 178, step 5000, loss 30.720944, time: 3.402
training: epoch 178, step 5200, loss 30.741571, time: 3.401
training: epoch 178, step 5400, loss 30.713210, time: 3.399
training: epoch 178, step 5600, loss 30.733799, time: 3.396
training: epoch 178, step 5800, loss 30.738278, time: 3.403
training: epoch 178, step 6000, loss 30.730069, time: 3.398
training: epoch 178, step 6200, loss 30.756233, time: 3.397
training: epoch 178, step 6400, loss 30.793391, time: 3.400
training: epoch 178, step 6600, loss 30.798390, time: 3.399
training: epoch 178, step 6800, loss 30.808618, time: 3.397
training: epoch 178, step 7000, loss 30.779533, time: 3.398
training: epoch 178, step 7200, loss 30.761331, time: 3.395
training: epoch 178, step 7400, loss 30.750474, time: 3.400
training: epoch 178, step 7600, loss 30.740634, time: 3.400
training: epoch 178, step 7800, loss 30.742532, time: 3.396
training: epoch 178, step 7849, loss 30.757093, time: 0.832
validate: epoch 178, loss 36.013861, charcter error 6.452 time: 4.014
training: epoch 179, step 200, loss 31.245413, time: 3.350
training: epoch 179, step 400, loss 30.723294, time: 3.391
training: epoch 179, step 600, loss 31.042782, time: 3.400
training: epoch 179, step 800, loss 31.181092, time: 3.402
training: epoch 179, step 1000, loss 31.058230, time: 3.406
training: epoch 179, step 1200, loss 30.944257, time: 3.408
training: epoch 179, step 1400, loss 30.811571, time: 3.404
training: epoch 179, step 1600, loss 30.784490, time: 3.403
training: epoch 179, step 1800, loss 30.737637, time: 3.398
training: epoch 179, step 2000, loss 30.772401, time: 3.398
training: epoch 179, step 2200, loss 30.770840, time: 3.399
training: epoch 179, step 2400, loss 30.777132, time: 3.399
training: epoch 179, step 2600, loss 30.757751, time: 3.397
training: epoch 179, step 2800, loss 30.717910, time: 3.399
training: epoch 179, step 3000, loss 30.716421, time: 3.397
training: epoch 179, step 3200, loss 30.668029, time: 3.399
training: epoch 179, step 3400, loss 30.763863, time: 3.398
training: epoch 179, step 3600, loss 30.756882, time: 3.398
training: epoch 179, step 3800, loss 30.734424, time: 3.400
training: epoch 179, step 4000, loss 30.758158, time: 3.399
training: epoch 179, step 4200, loss 30.858399, time: 3.400
training: epoch 179, step 4400, loss 30.816463, time: 3.398
training: epoch 179, step 4600, loss 30.828298, time: 3.397
training: epoch 179, step 4800, loss 30.824228, time: 3.397
training: epoch 179, step 5000, loss 30.820992, time: 3.402
training: epoch 179, step 5200, loss 30.831881, time: 3.399
training: epoch 179, step 5400, loss 30.807602, time: 3.396
training: epoch 179, step 5600, loss 30.806634, time: 3.401
training: epoch 179, step 5800, loss 30.815115, time: 3.405
training: epoch 179, step 6000, loss 30.826206, time: 3.400
training: epoch 179, step 6200, loss 30.811825, time: 3.400
training: epoch 179, step 6400, loss 30.805118, time: 3.398
training: epoch 179, step 6600, loss 30.774280, time: 3.398
training: epoch 179, step 6800, loss 30.774009, time: 3.399
training: epoch 179, step 7000, loss 30.753223, time: 3.396
training: epoch 179, step 7200, loss 30.767745, time: 3.398
training: epoch 179, step 7400, loss 30.761829, time: 3.400
training: epoch 179, step 7600, loss 30.769568, time: 3.399
training: epoch 179, step 7800, loss 30.766874, time: 3.396
training: epoch 179, step 7849, loss 30.771934, time: 0.832
validate: epoch 179, loss 35.352635, charcter error 6.316 time: 4.026
training: epoch 180, step 200, loss 29.841800, time: 3.347
training: epoch 180, step 400, loss 29.932977, time: 3.390
training: epoch 180, step 600, loss 30.180382, time: 3.397
training: epoch 180, step 800, loss 30.526729, time: 3.395
training: epoch 180, step 1000, loss 31.030574, time: 3.395
training: epoch 180, step 1200, loss 30.847738, time: 3.390
training: epoch 180, step 1400, loss 30.828435, time: 3.395
training: epoch 180, step 1600, loss 30.903916, time: 3.392
training: epoch 180, step 1800, loss 30.909510, time: 3.393
training: epoch 180, step 2000, loss 30.896265, time: 3.394
training: epoch 180, step 2200, loss 30.930565, time: 3.395
training: epoch 180, step 2400, loss 30.853937, time: 3.396
training: epoch 180, step 2600, loss 30.901110, time: 3.397
training: epoch 180, step 2800, loss 30.900304, time: 3.398
training: epoch 180, step 3000, loss 30.922607, time: 3.399
training: epoch 180, step 3200, loss 30.892280, time: 3.403
training: epoch 180, step 3400, loss 30.901414, time: 3.403
training: epoch 180, step 3600, loss 30.909103, time: 3.406
training: epoch 180, step 3800, loss 30.846548, time: 3.402
training: epoch 180, step 4000, loss 30.804824, time: 3.398
training: epoch 180, step 4200, loss 30.804143, time: 3.400
training: epoch 180, step 4400, loss 30.799445, time: 3.398
training: epoch 180, step 4600, loss 30.839820, time: 3.398
training: epoch 180, step 4800, loss 30.831606, time: 3.397
training: epoch 180, step 5000, loss 30.832876, time: 3.397
training: epoch 180, step 5200, loss 30.834161, time: 3.397
training: epoch 180, step 5400, loss 30.852000, time: 3.400
training: epoch 180, step 5600, loss 30.857307, time: 3.402
training: epoch 180, step 5800, loss 30.859328, time: 3.400
training: epoch 180, step 6000, loss 30.806026, time: 3.392
training: epoch 180, step 6200, loss 30.799093, time: 3.392
training: epoch 180, step 6400, loss 30.779948, time: 3.397
training: epoch 180, step 6600, loss 30.757549, time: 3.397
training: epoch 180, step 6800, loss 30.707670, time: 3.396
training: epoch 180, step 7000, loss 30.714700, time: 3.413
training: epoch 180, step 7200, loss 30.703566, time: 3.406
training: epoch 180, step 7400, loss 30.662920, time: 3.400
training: epoch 180, step 7600, loss 30.683405, time: 3.399
training: epoch 180, step 7800, loss 30.711791, time: 3.397
training: epoch 180, step 7849, loss 30.705978, time: 0.832
validate: epoch 180, loss 35.356458, charcter error 6.315 time: 4.026
training: epoch 181, step 200, loss 30.278247, time: 3.347
training: epoch 181, step 400, loss 31.097423, time: 3.395
training: epoch 181, step 600, loss 31.096945, time: 3.405
training: epoch 181, step 800, loss 31.229413, time: 3.401
training: epoch 181, step 1000, loss 31.232173, time: 3.393
training: epoch 181, step 1200, loss 31.111631, time: 3.394
training: epoch 181, step 1400, loss 31.073408, time: 3.395
training: epoch 181, step 1600, loss 30.929917, time: 3.393
training: epoch 181, step 1800, loss 30.878435, time: 3.396
training: epoch 181, step 2000, loss 30.847481, time: 3.393
training: epoch 181, step 2200, loss 30.825069, time: 3.393
training: epoch 181, step 2400, loss 30.813378, time: 3.395
training: epoch 181, step 2600, loss 30.753148, time: 3.397
training: epoch 181, step 2800, loss 30.678310, time: 3.396
training: epoch 181, step 3000, loss 30.648239, time: 3.395
training: epoch 181, step 3200, loss 30.616822, time: 3.399
training: epoch 181, step 3400, loss 30.630761, time: 3.399
training: epoch 181, step 3600, loss 30.644615, time: 3.401
training: epoch 181, step 3800, loss 30.627143, time: 3.407
training: epoch 181, step 4000, loss 30.602217, time: 3.521
training: epoch 181, step 4200, loss 30.621199, time: 3.520
training: epoch 181, step 4400, loss 30.597564, time: 3.567
training: epoch 181, step 4600, loss 30.634389, time: 3.549
training: epoch 181, step 4800, loss 30.637757, time: 3.540
training: epoch 181, step 5000, loss 30.675481, time: 3.534
training: epoch 181, step 5200, loss 30.698469, time: 3.536
training: epoch 181, step 5400, loss 30.679037, time: 3.536
training: epoch 181, step 5600, loss 30.655420, time: 3.525
training: epoch 181, step 5800, loss 30.666449, time: 3.527
training: epoch 181, step 6000, loss 30.678185, time: 3.511
training: epoch 181, step 6200, loss 30.660187, time: 3.607
training: epoch 181, step 6400, loss 30.653941, time: 3.552
training: epoch 181, step 6600, loss 30.643394, time: 3.489
training: epoch 181, step 6800, loss 30.656824, time: 3.499
training: epoch 181, step 7000, loss 30.622728, time: 3.466
training: epoch 181, step 7200, loss 30.632469, time: 3.463
training: epoch 181, step 7400, loss 30.640507, time: 3.437
training: epoch 181, step 7600, loss 30.649916, time: 3.420
training: epoch 181, step 7800, loss 30.643866, time: 3.410
training: epoch 181, step 7849, loss 30.624685, time: 0.836
validate: epoch 181, loss 35.248707, charcter error 6.304 time: 4.041
training: epoch 182, step 200, loss 30.997874, time: 3.355
training: epoch 182, step 400, loss 30.695950, time: 3.391
training: epoch 182, step 600, loss 30.716473, time: 3.402
training: epoch 182, step 800, loss 30.817745, time: 3.392
training: epoch 182, step 1000, loss 30.723574, time: 3.392
training: epoch 182, step 1200, loss 30.679650, time: 3.391
training: epoch 182, step 1400, loss 30.541763, time: 3.397
training: epoch 182, step 1600, loss 30.542974, time: 3.397
training: epoch 182, step 1800, loss 30.667022, time: 3.394
training: epoch 182, step 2000, loss 30.662404, time: 3.391
training: epoch 182, step 2200, loss 30.713539, time: 3.384
training: epoch 182, step 2400, loss 30.745071, time: 3.388
training: epoch 182, step 2600, loss 30.771631, time: 3.387
training: epoch 182, step 2800, loss 30.701883, time: 3.387
training: epoch 182, step 3000, loss 30.711999, time: 3.387
training: epoch 182, step 3200, loss 30.737293, time: 3.386
training: epoch 182, step 3400, loss 30.697838, time: 3.388
training: epoch 182, step 3600, loss 30.687244, time: 3.389
training: epoch 182, step 3800, loss 30.703081, time: 3.385
training: epoch 182, step 4000, loss 30.676167, time: 3.381
training: epoch 182, step 4200, loss 30.659576, time: 3.381
training: epoch 182, step 4400, loss 30.680915, time: 3.382
training: epoch 182, step 4600, loss 30.652943, time: 3.386
training: epoch 182, step 4800, loss 30.596769, time: 3.389
training: epoch 182, step 5000, loss 30.619566, time: 3.386
training: epoch 182, step 5200, loss 30.646199, time: 3.385
training: epoch 182, step 5400, loss 30.660535, time: 3.381
training: epoch 182, step 5600, loss 30.662984, time: 3.389
training: epoch 182, step 5800, loss 30.621940, time: 3.389
training: epoch 182, step 6000, loss 30.612564, time: 3.381
training: epoch 182, step 6200, loss 30.654139, time: 3.383
training: epoch 182, step 6400, loss 30.670247, time: 3.383
training: epoch 182, step 6600, loss 30.663933, time: 3.380
training: epoch 182, step 6800, loss 30.624793, time: 3.386
training: epoch 182, step 7000, loss 30.629568, time: 3.384
training: epoch 182, step 7200, loss 30.626294, time: 3.395
training: epoch 182, step 7400, loss 30.615437, time: 3.513
training: epoch 182, step 7600, loss 30.637484, time: 3.469
training: epoch 182, step 7800, loss 30.629109, time: 3.474
training: epoch 182, step 7849, loss 30.624705, time: 0.854
validate: epoch 182, loss 35.114599, charcter error 6.291 time: 4.039
training: epoch 183, step 200, loss 30.502989, time: 3.538
training: epoch 183, step 400, loss 30.912075, time: 3.492
training: epoch 183, step 600, loss 31.030120, time: 3.471
training: epoch 183, step 800, loss 30.993239, time: 3.468
training: epoch 183, step 1000, loss 31.056005, time: 3.486
training: epoch 183, step 1200, loss 30.981689, time: 3.548
training: epoch 183, step 1400, loss 30.903258, time: 3.485
training: epoch 183, step 1600, loss 30.800746, time: 3.512
training: epoch 183, step 1800, loss 30.807763, time: 3.497
training: epoch 183, step 2000, loss 30.686604, time: 3.486
training: epoch 183, step 2200, loss 30.661611, time: 3.469
training: epoch 183, step 2400, loss 30.675076, time: 3.399
training: epoch 183, step 2600, loss 30.685069, time: 3.390
training: epoch 183, step 2800, loss 30.662859, time: 3.413
training: epoch 183, step 3000, loss 30.689036, time: 3.417
training: epoch 183, step 3200, loss 30.692537, time: 3.488
training: epoch 183, step 3400, loss 30.690247, time: 3.482
training: epoch 183, step 3600, loss 30.687324, time: 3.492
training: epoch 183, step 3800, loss 30.675690, time: 3.481
training: epoch 183, step 4000, loss 30.669717, time: 3.464
training: epoch 183, step 4200, loss 30.702488, time: 3.457
training: epoch 183, step 4400, loss 30.660183, time: 3.462
training: epoch 183, step 4600, loss 30.653447, time: 3.473
training: epoch 183, step 4800, loss 30.652011, time: 3.460
training: epoch 183, step 5000, loss 30.621327, time: 3.470
training: epoch 183, step 5200, loss 30.617593, time: 3.454
training: epoch 183, step 5400, loss 30.613832, time: 3.474
training: epoch 183, step 5600, loss 30.607744, time: 3.464
training: epoch 183, step 5800, loss 30.599385, time: 3.476
training: epoch 183, step 6000, loss 30.608395, time: 3.451
training: epoch 183, step 6200, loss 30.614176, time: 3.453
training: epoch 183, step 6400, loss 30.619135, time: 3.434
training: epoch 183, step 6600, loss 30.605139, time: 3.664
training: epoch 183, step 6800, loss 30.582365, time: 3.552
training: epoch 183, step 7000, loss 30.589402, time: 3.500
training: epoch 183, step 7200, loss 30.627263, time: 3.516
training: epoch 183, step 7400, loss 30.639412, time: 3.506
training: epoch 183, step 7600, loss 30.658658, time: 3.503
training: epoch 183, step 7800, loss 30.654773, time: 3.523
training: epoch 183, step 7849, loss 30.648140, time: 0.863
validate: epoch 183, loss 35.233911, charcter error 6.314 time: 4.043
training: epoch 184, step 200, loss 29.836836, time: 3.456
training: epoch 184, step 400, loss 29.705020, time: 3.461
training: epoch 184, step 600, loss 29.621322, time: 3.528
training: epoch 184, step 800, loss 29.919025, time: 3.519
training: epoch 184, step 1000, loss 30.044411, time: 3.472
training: epoch 184, step 1200, loss 30.122344, time: 3.447
training: epoch 184, step 1400, loss 29.980541, time: 3.424
training: epoch 184, step 1600, loss 30.085961, time: 3.430
training: epoch 184, step 1800, loss 30.120728, time: 3.425
training: epoch 184, step 2000, loss 30.107619, time: 3.426
training: epoch 184, step 2200, loss 30.068948, time: 3.406
training: epoch 184, step 2400, loss 30.067530, time: 3.406
training: epoch 184, step 2600, loss 30.135977, time: 3.404
training: epoch 184, step 2800, loss 30.185033, time: 3.398
training: epoch 184, step 3000, loss 30.125215, time: 3.398
training: epoch 184, step 3200, loss 30.241431, time: 3.396
training: epoch 184, step 3400, loss 30.302771, time: 3.399
training: epoch 184, step 3600, loss 30.277370, time: 3.396
training: epoch 184, step 3800, loss 30.321529, time: 3.395
training: epoch 184, step 4000, loss 30.375350, time: 3.394
training: epoch 184, step 4200, loss 30.432444, time: 3.396
training: epoch 184, step 4400, loss 30.422618, time: 3.393
training: epoch 184, step 4600, loss 30.410030, time: 3.397
training: epoch 184, step 4800, loss 30.449616, time: 3.392
training: epoch 184, step 5000, loss 30.451958, time: 3.389
training: epoch 184, step 5200, loss 30.461872, time: 3.387
training: epoch 184, step 5400, loss 30.447720, time: 3.391
training: epoch 184, step 5600, loss 30.436804, time: 3.390
training: epoch 184, step 5800, loss 30.435871, time: 3.387
training: epoch 184, step 6000, loss 30.422915, time: 3.393
training: epoch 184, step 6200, loss 30.422158, time: 3.393
training: epoch 184, step 6400, loss 30.437202, time: 3.392
training: epoch 184, step 6600, loss 30.460309, time: 3.394
training: epoch 184, step 6800, loss 30.489015, time: 3.397
training: epoch 184, step 7000, loss 30.537655, time: 3.389
training: epoch 184, step 7200, loss 30.536419, time: 3.393
training: epoch 184, step 7400, loss 30.547960, time: 3.395
training: epoch 184, step 7600, loss 30.595681, time: 3.396
training: epoch 184, step 7800, loss 30.620758, time: 3.389
training: epoch 184, step 7849, loss 30.611585, time: 0.831
validate: epoch 184, loss 35.218586, charcter error 6.318 time: 4.017
training: epoch 185, step 200, loss 31.038013, time: 3.346
training: epoch 185, step 400, loss 31.207851, time: 3.392
training: epoch 185, step 600, loss 31.183685, time: 3.400
training: epoch 185, step 800, loss 30.912374, time: 3.400
training: epoch 185, step 1000, loss 31.005140, time: 3.398
training: epoch 185, step 1200, loss 30.882672, time: 3.393
training: epoch 185, step 1400, loss 30.935431, time: 3.399
training: epoch 185, step 1600, loss 30.883197, time: 3.406
training: epoch 185, step 1800, loss 30.853328, time: 3.403
training: epoch 185, step 2000, loss 30.877316, time: 3.398
training: epoch 185, step 2200, loss 30.820940, time: 3.397
training: epoch 185, step 2400, loss 30.838284, time: 3.406
training: epoch 185, step 2600, loss 30.736428, time: 3.397
training: epoch 185, step 2800, loss 30.783663, time: 3.398
training: epoch 185, step 3000, loss 30.733960, time: 3.391
training: epoch 185, step 3200, loss 30.758444, time: 3.402
training: epoch 185, step 3400, loss 30.734776, time: 3.408
training: epoch 185, step 3600, loss 30.756834, time: 3.403
training: epoch 185, step 3800, loss 30.707597, time: 3.406
training: epoch 185, step 4000, loss 30.684952, time: 3.398
training: epoch 185, step 4200, loss 30.676926, time: 3.399
training: epoch 185, step 4400, loss 30.680459, time: 3.396
training: epoch 185, step 4600, loss 30.685108, time: 3.394
training: epoch 185, step 4800, loss 30.684764, time: 3.395
training: epoch 185, step 5000, loss 30.676962, time: 3.402
training: epoch 185, step 5200, loss 30.723288, time: 3.398
training: epoch 185, step 5400, loss 30.702520, time: 3.399
training: epoch 185, step 5600, loss 30.691338, time: 3.398
training: epoch 185, step 5800, loss 30.678225, time: 3.407
training: epoch 185, step 6000, loss 30.649365, time: 3.408
training: epoch 185, step 6200, loss 30.651325, time: 3.397
training: epoch 185, step 6400, loss 30.669567, time: 3.396
training: epoch 185, step 6600, loss 30.668680, time: 3.403
training: epoch 185, step 6800, loss 30.661172, time: 3.403
training: epoch 185, step 7000, loss 30.652734, time: 3.404
training: epoch 185, step 7200, loss 30.656712, time: 3.402
training: epoch 185, step 7400, loss 30.653769, time: 3.404
training: epoch 185, step 7600, loss 30.643382, time: 3.394
training: epoch 185, step 7800, loss 30.633435, time: 3.394
training: epoch 185, step 7849, loss 30.633832, time: 0.832
validate: epoch 185, loss 35.149511, charcter error 6.286 time: 4.035
training: epoch 186, step 200, loss 30.171566, time: 3.346
training: epoch 186, step 400, loss 30.024604, time: 3.385
training: epoch 186, step 600, loss 30.000339, time: 3.400
training: epoch 186, step 800, loss 30.052710, time: 3.394
training: epoch 186, step 1000, loss 30.246459, time: 3.408
training: epoch 186, step 1200, loss 30.210610, time: 3.413
training: epoch 186, step 1400, loss 30.188101, time: 3.415
training: epoch 186, step 1600, loss 30.089635, time: 3.413
training: epoch 186, step 1800, loss 30.333852, time: 3.411
training: epoch 186, step 2000, loss 30.489638, time: 3.415
training: epoch 186, step 2200, loss 30.485725, time: 3.416
training: epoch 186, step 2400, loss 30.447386, time: 3.414
training: epoch 186, step 2600, loss 30.470632, time: 3.409
training: epoch 186, step 2800, loss 30.428273, time: 3.411
training: epoch 186, step 3000, loss 30.357792, time: 3.410
training: epoch 186, step 3200, loss 30.400707, time: 3.408
training: epoch 186, step 3400, loss 30.351559, time: 3.411
training: epoch 186, step 3600, loss 30.343886, time: 3.413
training: epoch 186, step 3800, loss 30.311274, time: 3.410
training: epoch 186, step 4000, loss 30.338956, time: 3.408
training: epoch 186, step 4200, loss 30.392586, time: 3.415
training: epoch 186, step 4400, loss 30.367414, time: 3.413
training: epoch 186, step 4600, loss 30.387950, time: 3.410
training: epoch 186, step 4800, loss 30.395086, time: 3.420
training: epoch 186, step 5000, loss 30.407621, time: 3.413
training: epoch 186, step 5200, loss 30.411222, time: 3.414
training: epoch 186, step 5400, loss 30.454410, time: 3.417
training: epoch 186, step 5600, loss 30.467639, time: 3.413
training: epoch 186, step 5800, loss 30.440446, time: 3.413
training: epoch 186, step 6000, loss 30.456085, time: 3.415
training: epoch 186, step 6200, loss 30.466435, time: 3.413
training: epoch 186, step 6400, loss 30.457672, time: 3.413
training: epoch 186, step 6600, loss 30.495532, time: 3.415
training: epoch 186, step 6800, loss 30.497105, time: 3.413
training: epoch 186, step 7000, loss 30.494708, time: 3.413
training: epoch 186, step 7200, loss 30.483132, time: 3.416
training: epoch 186, step 7400, loss 30.505091, time: 3.413
training: epoch 186, step 7600, loss 30.543734, time: 3.415
training: epoch 186, step 7800, loss 30.575732, time: 3.415
training: epoch 186, step 7849, loss 30.576896, time: 0.837
validate: epoch 186, loss 35.213410, charcter error 6.293 time: 4.031
training: epoch 187, step 200, loss 30.241900, time: 3.368
training: epoch 187, step 400, loss 30.101183, time: 3.414
training: epoch 187, step 600, loss 30.093673, time: 3.413
training: epoch 187, step 800, loss 30.110618, time: 3.413
training: epoch 187, step 1000, loss 30.249402, time: 3.413
training: epoch 187, step 1200, loss 30.441115, time: 3.417
training: epoch 187, step 1400, loss 30.446845, time: 3.416
training: epoch 187, step 1600, loss 30.484662, time: 3.413
training: epoch 187, step 1800, loss 30.491489, time: 3.417
training: epoch 187, step 2000, loss 30.470082, time: 3.420
training: epoch 187, step 2200, loss 30.471922, time: 3.416
training: epoch 187, step 2400, loss 30.432339, time: 3.417
training: epoch 187, step 2600, loss 30.441438, time: 3.421
training: epoch 187, step 2800, loss 30.485593, time: 3.414
training: epoch 187, step 3000, loss 30.555708, time: 3.413
training: epoch 187, step 3200, loss 30.641613, time: 3.418
training: epoch 187, step 3400, loss 30.651306, time: 3.415
training: epoch 187, step 3600, loss 30.677441, time: 3.413
training: epoch 187, step 3800, loss 30.641873, time: 3.413
training: epoch 187, step 4000, loss 30.627792, time: 3.426
training: epoch 187, step 4200, loss 30.630003, time: 3.413
training: epoch 187, step 4400, loss 30.606849, time: 3.413
training: epoch 187, step 4600, loss 30.598650, time: 3.422
training: epoch 187, step 4800, loss 30.572731, time: 3.422
training: epoch 187, step 5000, loss 30.561890, time: 3.414
training: epoch 187, step 5200, loss 30.563994, time: 3.414
training: epoch 187, step 5400, loss 30.556686, time: 3.419
training: epoch 187, step 5600, loss 30.558391, time: 3.414
training: epoch 187, step 5800, loss 30.556552, time: 3.415
training: epoch 187, step 6000, loss 30.548351, time: 3.413
training: epoch 187, step 6200, loss 30.568371, time: 3.420
training: epoch 187, step 6400, loss 30.584897, time: 3.413
training: epoch 187, step 6600, loss 30.602106, time: 3.413
training: epoch 187, step 6800, loss 30.609939, time: 3.413
training: epoch 187, step 7000, loss 30.632165, time: 3.413
training: epoch 187, step 7200, loss 30.614020, time: 3.417
training: epoch 187, step 7400, loss 30.614489, time: 3.416
training: epoch 187, step 7600, loss 30.601212, time: 3.413
training: epoch 187, step 7800, loss 30.591986, time: 3.413
training: epoch 187, step 7849, loss 30.586567, time: 0.836
validate: epoch 187, loss 35.197408, charcter error 6.298 time: 4.027